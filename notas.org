#+author: Pablo Aguado
#+title: Notas del curso Machine Learning de Andrew Ng en Coursera
#+description: Mis notas.

#+STARTUP: indent content align entitiespretty


* Info

- https://www.coursera.org/learn/machine-learning
- [[https://www.coursera.org/learn/machine-learning/discussions/all/threads/v2YppY8FEeWIeBJxvl1elQ][Important notes for new ML students]]
  - Hay más /test cases/ en los Recursos del curso.
  - *Hay que usar Octave > 4.0.0*
  - [[https://learner.coursera.help/hc/en-us/articles/209818863-Coursera-Honor-Code][Cousera Honor Code]]

* Ideas

Ideas mías a lo largo del curso.

1. Probar [[https://github.com/google-research/google-research/blob/master/automl_zero/README.md][AutoML-Zero]].
2. Buscar clusters en espacios transformados y muy transformados. Ej: Fourier, Fourier de Fourier, Cepstrum...


* Semana 1

Intro, regresión lineal, repaso de Álgebra.


- [[https://www.coursera.org/learn/machine-learning/discussions/weeks/1/threads/hAp4LT1SEeaL_xIEq4QdBw][FAQ de la semana 1]]

** Introduction
*** Video: Welcome

*** Video: What is Machine Learning

- Los algoritmos más importantes son el aprendizaje supervisado y el aprendizaje no supervisado. Es esta además la clasificación más general de algoritmos.
  - Otros son el aprendizaje por refuerzo y los sistemas de recomendación.
- Hay que aprender las herramientas, pero *es muy importante saber cómo y cuándo usarlas*.
- Sea una máquina que debe hacer una tarea T, con un desempeño P y que la exponemos a experiencias (instancias) E de esa tarea T. Se dice que la computadora aprende si su desempeño P en la tarea T /aumenta proporcionalmente a la cantidad de experiencias E/.
- Otra definición de aprendizaje automático es la capacidad (de la computadora) de aprender a resolver problemas para los que no fue programada. ~

*** Reading: What is Machine Learning?

*** Video: Supervised Learning

- En el aprendizaje supervisado, le mostramos al programa ejemplos de entradas y sus correspondientes salidas/respuestas correctas. Ya sabemos cómo son las respuestas corectas; tenemos la idea de que hay una relación entre las entradas y las salidas. Dado un conjunto de entradas y salidas, intentamos obtener un modelo que permita predecir/inferir las salidas a nuevos datos de entrada.
- Los problemas de aprendizaje supervisado se clasifican en problemas de regresión y de clasificación:
  - Problema de *regresión* si el conjunto imagen es continuo. La salida es una variable numérica.
  - Problema de *clasificación* si el conjunto imagen es discreto. La salida es una variable categórica.
- Los algoritmos de Máquinas de Vector Soporte permiten /*infinitos*/ valores de entrada.

****** TODO Leer https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression

****** TODO Leer https://datascience.stackexchange.com/questions/25298/how-to-know-when-to-treat-a-problem-as-a-classification-task-or-a-regression-tas

*** Video: Unsupervised Learning

- En el aprendizaje no supervisado, le damos datos al programa con la intención de encontrar estructuras subyacentes, patrones.
- Un ejemplo típico es el /clustering/ o agrupamiento de datos.
- En el ejemplo de sonido Cocktail Party, según [[https://www.coursera.org/learn/machine-learning/discussions/weeks/1/threads/hAp4LT1SEeaL_xIEq4QdBw][FAQ de la semana 1]], lo que usan es /Principal Component Analysis, PCA, a mathematical trick that takes two sets of correlated data, and returns two new sets of data that are not correlated./ No lo había visto así antes, creo...

** Model and cost function

Vemos la regresión lineal como primer algoritmo de aprendizaje supervisado.

*** Video: Model representation

Un poco de nomenclatura:

- $m$: cantidad de ejemplos de entrenamiento.
- $\vec{x}$: entradas / descriptores / /features/
- $\vec{y}$: salidas. $\hat{\vec{y}}$ son las salidas estimadas.
- $h_\theta$: función de hipótesis, de estimación. Tiene parámetros $\vec{\theta}$. Entonces tenemos que \( \hat{y}^{(i)} = h_\theta(x^{(i)}) = h(x,\theta) \)
- $x^{(i)}$: entrada $i$-ésima del vector de entradas, con índices empezando en 1.
  - $(x^{}^{}^{(i)},y^{}^{}^{(i)})$ es un ejemplo de entrenamiento.
- Para regresión lineal de una variable tenemos entonces 
\[ \hat{y}^{(i)} = h_\theta(x^{(i)}) = \theta_0 + \theta_1 * x^{(i)} \]

*** Reading: Model representation

- $X$: el espacio de los valores de entrada.
- $Y$: el espacio de los valores de salida.
- El objetivo del aprendizaje supervisado es encontrar una función $h: X \rightarrow Y$ que sea buena prediciendo salidas a partir de entradas.
 
*** Video: Cost function

Formalizamos el problema del aprendizaje como la minimización de una función de costo $J(\vec{\theta})$. La función de costo habitual y recomendada para problemas de regresión lineal es el *error cuadrático medio* ([[https://en.wikipedia.org/wiki/Mean_squared_error][/Mean Squared Error/]] o /Mean Squared Deviation/).

Para un predictor como lo es $h_\theta$, el MSE se define como
\[ MSE = \frac{1}{N} (\sum_{1}^{N}Y_i - \hat{Y}_i )^2\]

En nuestro caso vamos a definir a la función de costo para este problema de regresión lineal univariable como

\[ J(\theta_0 , \theta_1) = \frac{1}{2m} \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} )^2  \]
\[ J(\theta_0 , \theta_1) =  \frac{1}{2m} \sum_{i=1}^m( \theta_0 + \theta_1 * x^{(i)} - y^{(i)} )^2 \]

- El factor $1/2$ es para ahorrar cálculos, puesto que en redes neuronales al hacer /backpropagation/ o /gradient descent/ hay que derivar esta función de error y entonces con este $1/2$ simplificamos el $2$ de la derivada del cuadrado.

La optimización es entonces encontrar los parámetros $\theta$ que minimizan la función de costo:
\[ \underset{\theta_0 , \theta_1}{\text{min}}  J(\theta_0 , \theta_1)\]

*** Reading: Cost function

*** Video: Cost function intuition I

*** Reading: Cost function intuition I

*** Video: Cost function intuition II

*** Reading: Cost function intuition II

De [[https://es.wikipedia.org/wiki/Isol%C3%ADnea][isolíneas / curvas de nivel]].


** Parameter learning

*** Video: Gradient descent

El descenso por el gradiente es un algoritmo de optimización que vamos a usar (entre otras cosas) para minimizar la función de costo.

Hacer \[ \vec{\theta}[n+1] := \vec{\theta}[n] - \alpha \frac{\delta J(\vec{\theta})}{\delta\theta}  \]

Hasta que \[  \vec{\theta}[n+1] - \vec{\theta}[n] < \epsilon \]

- Nomenclatura: usamos $:=$ como operador de asignación.
- $\alpha$ es la tasa de aprendizaje o /learning rate/ del algoritmo.

Para calcular la derivada hacemos derivadas parciales. Actualizamos los parámetros simultáneamente en cada paso. Si actualizamos de a uno estamos haciendo otro algoritmo, que probablemente también converja pero es distinto.

*** Reading: Gradient descent

*** Video: Gradient descent intuition

- Si $\alpha$ es muy grande, el algoritmo puede oscilar o incluso diverger.
- Si $\alpha$ es muy chica, puede tardar mucho en converger.
- Con $\alpha$ fija, los "pasos" que da el algoritmo son cada vez más chicos a medida que la función de costo se aproxima a un mínimo local.

*** Reading: Gradient descent intuition

*** Video: Gradient descent for linear regression

Dice Andrew cerca del minuto 4:40:

#+begin_quote
But, it turns out that that the cost function for
linear regression is always going to be a bow shaped function like this.
The technical term for this is that this is called a convex function.
#+end_quote

¿Por qué?

- La función de costo $J(\vec{\theta})$ es el error cuadrático medio (MSE).
- El MSE es cuadrático respecto a los parámetros siempre y cuando estos sean lineales, de grado 1. *La función de hipótesis debe ser lineal respecto a los parámetros para que la función de costo sea cuadrática*.
  - Sea por ejemplo \[ h(x,y) =  a.x^2 + b.y^2 - c.x^2 y^2 \]. Esta función tiene más de un mínimo.

[[file:imgs/001-01-nolineal.gif]]

  - Su MSE quedaría algo como \[ x^4 + 2 x^2 y^2 - 2 x^4 y^2 + y^4 - 2 x^2 y^4 + x^4 y^4  \] (sólo [[https://www.wolframalpha.com/input/?i=%28x%5E2+%2B+y%5E2+-+x%5E2y%5E2%29%5E2][la elevé al cuadrado]])

[[file:imgs/001-02-nolineal-cuadrado.gif]]

-----------------

Hay otras formas de estimar los parámetros (regresores). Una de ellas es el método de los mínimos cuadrados ([[https://en.wikipedia.org/wiki/Ordinary_least_squares][/Ordinary Least Squares]]/). El descenso por el gradiente es más fácil de computar que OLS, en el caso de datasets grandes.

En realidad todo lo que vimos es descenso por el gradiente por lotes, o */batch gradient descent/*, que es cuando la función de costo se optimiza usando todas las entradas disponibles. Esto es costoso.



****** TODO Leer más de [[https://en.wikipedia.org/wiki/Linear_regression][regresión lineal]]



**** Regresión lineal



*** Reading: Gradient descent for linear regression

** Linear Algebra review

* Semana 2

* Semana 3

* Semana 4
