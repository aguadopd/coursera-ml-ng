<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2020-05-27 miÃ© 22:43 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Notas del curso Machine Learning de Andrew Ng en Coursera</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Pablo Aguado" />
<meta name="description" content="Mis notas."
 />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Notas del curso Machine Learning de Andrew Ng en Coursera</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org6b46073">1. Info</a></li>
<li><a href="#org6460034">2. Ideas</a>
<ul>
<li><a href="#orge6fa82c">2.1. Enlaces</a></li>
</ul>
</li>
<li><a href="#orgfac42e4">3. Semana 1</a>
<ul>
<li><a href="#org818b3ba">3.1. Introduction</a>
<ul>
<li><a href="#org9a1f52a">3.1.1. Video: Welcome</a></li>
<li><a href="#org25c8b66">3.1.2. Video: What is Machine Learning</a></li>
<li><a href="#orgc27371e">3.1.3. Reading: What is Machine Learning?</a></li>
<li><a href="#orgbc40ee3">3.1.4. Video: Supervised Learning</a></li>
<li><a href="#orgd4fff1f">3.1.5. Video: Unsupervised Learning</a></li>
</ul>
</li>
<li><a href="#org1c763e4">3.2. Model and cost function</a>
<ul>
<li><a href="#orgfad501a">3.2.1. Video: Model representation</a></li>
<li><a href="#org1efd2e7">3.2.2. Reading: Model representation</a></li>
<li><a href="#orgc8783f8">3.2.3. Video: Cost function</a></li>
<li><a href="#org1c8cbb0">3.2.4. Reading: Cost function</a></li>
<li><a href="#org3bc2d13">3.2.5. Video: Cost function intuition I</a></li>
<li><a href="#org1047348">3.2.6. Reading: Cost function intuition I</a></li>
<li><a href="#org84553b9">3.2.7. Video: Cost function intuition II</a></li>
<li><a href="#orgd7fc1d7">3.2.8. Reading: Cost function intuition II</a></li>
</ul>
</li>
<li><a href="#orga09c680">3.3. Parameter learning</a>
<ul>
<li><a href="#org7e160d4">3.3.1. Video: Gradient descent</a></li>
<li><a href="#orgce8029c">3.3.2. Reading: Gradient descent</a></li>
<li><a href="#org9613d23">3.3.3. Video: Gradient descent intuition</a></li>
<li><a href="#orge769493">3.3.4. Reading: Gradient descent intuition</a></li>
<li><a href="#org0bde613">3.3.5. Video: Gradient descent for linear regression</a></li>
<li><a href="#orgacbc2f4">3.3.6. Reading: Gradient descent for linear regression</a></li>
</ul>
</li>
<li><a href="#org81f0f33">3.4. Linear Algebra review</a>
<ul>
<li><a href="#orgd94fd3f">3.4.1. Video: Matrix vector multiplication</a></li>
<li><a href="#orgbe22c08">3.4.2. Video: Matrix matrix multiplication</a></li>
<li><a href="#org7569932">3.4.3. Video: Inverse and transpose</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge3390a5">4. Semana 2</a>
<ul>
<li><a href="#org679e75c">4.1. Environment setup instructions</a></li>
<li><a href="#orgb8eebb4">4.2. Multivariate linear regression</a>
<ul>
<li><a href="#org26b13c6">4.2.1. Video: Multivariate linear regression</a></li>
<li><a href="#org97a975c">4.2.2. Reading: multiple features</a></li>
<li><a href="#org8eb1064">4.2.3. Video: Gradient descent for multiple features</a></li>
<li><a href="#orga263964">4.2.4. Reading: Gradient descent for multiple features</a></li>
<li><a href="#org7ed21f6">4.2.5. Video: Gradient descent in practice I - Feature scaling</a></li>
<li><a href="#orgf793a1d">4.2.6. Reading: Gradient descent in practice I - Feature scaling</a></li>
<li><a href="#org68572af">4.2.7. Video: Gradient descent in practice II - Learning rate</a></li>
<li><a href="#orgd9eb9c2">4.2.8. Reading: Gradient descent in practice II - Learning rate</a></li>
<li><a href="#org4552c44">4.2.9. Video: Features and polynomial regression</a></li>
<li><a href="#org110d4fe">4.2.10. Reading: Features and polynomial regression</a></li>
</ul>
</li>
<li><a href="#orgf9618e0">4.3. Computing parameters analitically</a>
<ul>
<li><a href="#org0b30f7b">4.3.1. Video: Normal equation</a></li>
<li><a href="#org262d9aa">4.3.2. Reading: Normal equation</a></li>
<li><a href="#org33a7014">4.3.3. Video: Normal equation noninvertibility</a></li>
<li><a href="#org5237118">4.3.4. Reading: Normal equation noninvertibility</a></li>
</ul>
</li>
<li><a href="#org161fb92">4.4. Submitting programming assignments</a></li>
<li><a href="#orga9d7624">4.5. Review</a></li>
<li><a href="#org3c6a88e">4.6. Octave/Matlab tutorial</a></li>
<li><a href="#org640dfea">4.7. Review</a>
<ul>
<li><a href="#orgc2a60d4">4.7.1. Programming assignment 1: linear regression</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgbcde6a2">5. Semana 3</a>
<ul>
<li><a href="#orgc9e6775">5.1. Classification and representation</a>
<ul>
<li><a href="#org0087473">5.1.1. Classification</a></li>
<li><a href="#org32cd098">5.1.2. Hypothesis representation</a></li>
<li><a href="#org4d283af">5.1.3. Decision boundary</a></li>
</ul>
</li>
<li><a href="#org572f93e">5.2. Logistic regression model</a>
<ul>
<li><a href="#org1b4cd15">5.2.1. Cost function</a></li>
<li><a href="#org3c462cb">5.2.2. Simplified cost function and gradient descent</a></li>
<li><a href="#orgd697528">5.2.3. Advanced optimization</a></li>
</ul>
</li>
<li><a href="#org1a3cca7">5.3. Multiclass classification</a>
<ul>
<li><a href="#org47bae88">5.3.1. Multiclass classification: one vs all</a></li>
</ul>
</li>
<li><a href="#orgbc2e9f5">5.4. Solving the problem of overfitting</a>
<ul>
<li><a href="#org091891b">5.4.1. The problem of overfitting</a></li>
<li><a href="#org6d3f387">5.4.2. Cost function</a></li>
<li><a href="#orgbe740ec">5.4.3. Regularized linear regression</a></li>
<li><a href="#orga2d872a">5.4.4. Regularized logistic regression</a></li>
</ul>
</li>
<li><a href="#org25a1562">5.5. Review</a>
<ul>
<li><a href="#orgd26e682">5.5.1. Quiz: Regularization</a></li>
<li><a href="#orga9205d9">5.5.2. Programming assignment: logistic regression</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge749bd3">6. Semana 4</a>
<ul>
<li><a href="#orgcbd0f4a">6.1. Motivations</a>
<ul>
<li><a href="#orgab3f764">6.1.1. Non-linear hypotheses</a></li>
<li><a href="#org5d86b8d">6.1.2. Neurons and the brain</a></li>
</ul>
</li>
<li><a href="#orgd595f01">6.2. Neural networks</a>
<ul>
<li><a href="#org0fed566">6.2.1. Model representation I</a></li>
<li><a href="#orgac1da62">6.2.2. Model representation II</a></li>
</ul>
</li>
<li><a href="#org8c0109e">6.3. Applications</a>
<ul>
<li><a href="#org0050235">6.3.1. Examples and intuitions I</a></li>
<li><a href="#org986da8f">6.3.2. Examples and intuitions II</a></li>
<li><a href="#org3c9ffd6">6.3.3. Multiclass classification</a></li>
</ul>
</li>
<li><a href="#orgd8c0e55">6.4. Review</a>
<ul>
<li><a href="#org859fb74">6.4.1. Quiz: Neural networks: representation</a></li>
<li><a href="#orga585301">6.4.2. Programming assignment: multi-class classificatin and neural networks</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org496b1f6">7. Semana 5</a>
<ul>
<li><a href="#org61722f1">7.1. Cost function and backpropagation</a>
<ul>
<li><a href="#org0c6d257">7.1.1. Cost function</a></li>
<li><a href="#orgcb137ed">7.1.2. Backpropagation algorithm</a></li>
<li><a href="#org7e9bf57">7.1.3. Backpropagation intuition</a></li>
</ul>
</li>
<li><a href="#org049ca9d">7.2. Backpropagation in practice</a>
<ul>
<li><a href="#org9263c15">7.2.1. Implementation note: unrolling parameters</a></li>
<li><a href="#org2579f0d">7.2.2. Gradient checking</a></li>
<li><a href="#org2e91635">7.2.3. Random initialization</a></li>
<li><a href="#org7ece90e">7.2.4. Putting it together</a></li>
</ul>
</li>
<li><a href="#org136d323">7.3. Applications of neural networks</a>
<ul>
<li><a href="#orgb311726">7.3.1. Autonomous driving</a></li>
</ul>
</li>
<li><a href="#org8610a77">7.4. Review</a>
<ul>
<li><a href="#orgd8fcdd9">7.4.1. Quiz: Neural networks: learning</a></li>
<li><a href="#org4200daf">7.4.2. Programming assignment: neural network learning</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgbf2cf34">8. Semana 6</a>
<ul>
<li><a href="#orgb10c038">8.1. Evaluating a learning algorithm</a>
<ul>
<li><a href="#orgc223c92">8.1.1. Deciding what to try next</a></li>
<li><a href="#org22e10ad">8.1.2. Evaluating a hypothesis</a></li>
<li><a href="#orga5432e0">8.1.3. Model selection and train/validation/test sets</a></li>
</ul>
</li>
<li><a href="#org32fd80a">8.2. Bias vs variance</a>
<ul>
<li><a href="#orgc5a5813">8.2.1. Diagnosing bias vs variance</a></li>
<li><a href="#org2d8df98">8.2.2. Regularization and bias/variance</a></li>
<li><a href="#orgef2b313">8.2.3. Learning curves</a></li>
<li><a href="#orgb77e221">8.2.4. Deciding what to do next revisited</a></li>
</ul>
</li>
<li><a href="#orgf0045ec">8.3. Review</a>
<ul>
<li><a href="#org7679efd">8.3.1. Quiz: advice for applying machine learning</a></li>
<li><a href="#orgdd50455">8.3.2. Programming assignment: regularized linear regression and bias/variance</a></li>
</ul>
</li>
<li><a href="#orge3732d5">8.4. Building a spam classifier</a>
<ul>
<li><a href="#orga105ce9">8.4.1. Prioritizing what to work on</a></li>
<li><a href="#org8b908ac">8.4.2. Error analysis</a></li>
</ul>
</li>
<li><a href="#org431b8d4">8.5. Handling skewed data</a>
<ul>
<li><a href="#org0f90152">8.5.1. Error metrics for skewed classes</a></li>
<li><a href="#org4a20065">8.5.2. Trading off precision and recall</a></li>
</ul>
</li>
<li><a href="#orga2dc170">8.6. Using large datasets</a>
<ul>
<li><a href="#org896ffb7">8.6.1. Data for machine learning</a></li>
</ul>
</li>
<li><a href="#org6f8aac5">8.7. Review</a>
<ul>
<li><a href="#org04ec7a3">8.7.1. Quiz: machine learning system design</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgc0cdcad">9. Semana 7</a>
<ul>
<li><a href="#orgbb9512e">9.1. Large margin classification</a>
<ul>
<li><a href="#org7526418">9.1.1. Optimization objective</a></li>
<li><a href="#org68506cc">9.1.2. Large margin intuition</a></li>
<li><a href="#org5bc82bd">9.1.3. Mathematics behind large margin classification</a></li>
</ul>
</li>
<li><a href="#orgbd55267">9.2. Kernels</a>
<ul>
<li><a href="#orgc3c8683">9.2.1. Kernels I</a></li>
<li><a href="#orge1ea950">9.2.2. Kernels II</a></li>
</ul>
</li>
<li><a href="#orgcdd4443">9.3. SVMs in practice</a>
<ul>
<li><a href="#orgc764302">9.3.1. Using an SVM</a></li>
</ul>
</li>
<li><a href="#orgb25f6cf">9.4. Review</a>
<ul>
<li><a href="#org75f0d27">9.4.1. Quiz: support vector machines</a></li>
<li><a href="#orgfb4a2d6">9.4.2. Programming assignment SVMs</a></li>
</ul>
</li>
<li><a href="#org76fc964">9.5. Otras cosas</a>
<ul>
<li><a href="#org84c670d">9.5.1. https://www.youtube.com/watch?v=3liCbRZPrZA SVM with polynomial kernel visualization</a></li>
<li><a href="#orgd4ace66">9.5.2. https://ranvir.xyz/blog/svm-support-vector-machines-in-machine-learning/</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org88fd031">10. Semana 8: Unsupervised learning</a>
<ul>
<li><a href="#org04dd254">10.1. Clustering</a>
<ul>
<li><a href="#org731ba36">10.1.1. Unsupervised learning: introduction</a></li>
<li><a href="#org53a9d8b">10.1.2. K-means algorithm</a></li>
<li><a href="#org7cf27bf">10.1.3. Optimization objective</a></li>
<li><a href="#org7140df5">10.1.4. Random initialization</a></li>
<li><a href="#org2e77757">10.1.5. Choosing the number of clusters</a></li>
</ul>
</li>
<li><a href="#org195f42b">10.2. Review</a>
<ul>
<li><a href="#org6c5e15d">10.2.1. Quiz: Unsuperised learning</a></li>
</ul>
</li>
<li><a href="#org67dba36">10.3. Dimensionality reduction</a>
<ul>
<li><a href="#orgf3a26c1">10.3.1. Motivation</a></li>
<li><a href="#org72089d7">10.3.2. Principal component analysis</a></li>
<li><a href="#org04565fd">10.3.3. Appliying PCA</a></li>
<li><a href="#orgc387e07">10.3.4. Review</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org2cd401c">11. Semana 9: Anomaly detection &amp; Recommender systems</a>
<ul>
<li><a href="#org0efb50a">11.1. Anomaly detection</a>
<ul>
<li><a href="#org909db7b">11.1.1. Density estimation</a></li>
<li><a href="#orge655b13">11.1.2. Building an anomaly detection system</a></li>
<li><a href="#org6f1ed60">11.1.3. Multivariate gaussian distribution</a></li>
<li><a href="#orgef590fc">11.1.4. Review</a></li>
</ul>
</li>
<li><a href="#org59e37a1">11.2. Recommender systems</a>
<ul>
<li><a href="#orgc515c35">11.2.1. Predicting movie ratings</a></li>
<li><a href="#org65f9fe1">11.2.2. Collaborative filtering</a></li>
<li><a href="#org9be2c6d">11.2.3. Low rank matrix factorization</a></li>
<li><a href="#orgb0905ea">11.2.4. Review</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>


<div id="outline-container-org6b46073" class="outline-2">
<h2 id="org6b46073"><span class="section-number-2">1</span> Info</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li><a href="https://www.coursera.org/learn/machine-learning">https://www.coursera.org/learn/machine-learning</a></li>
<li><a href="https://www.coursera.org/learn/machine-learning/discussions/all/threads/v2YppY8FEeWIeBJxvl1elQ">Important notes for new ML students</a>
<ul class="org-ul">
<li>Hay mÃ¡s <i>test cases</i> en los Recursos del curso.</li>
<li><b>Hay que usar Octave &gt; 4.0.0</b></li>
<li><a href="https://learner.coursera.help/hc/en-us/articles/209818863-Coursera-Honor-Code">Cousera Honor Code</a></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org6460034" class="outline-2">
<h2 id="org6460034"><span class="section-number-2">2</span> Ideas</h2>
<div class="outline-text-2" id="text-2">
<p>
Ideas mÃ­as a lo largo del curso.
</p>

<ol class="org-ol">
<li>Probar <a href="https://github.com/google-research/google-research/blob/master/automl_zero/README.md">AutoML-Zero</a>.</li>
<li>Buscar clusters en espacios transformados y muy transformados. Ej: Fourier, Fourier de Fourier, Cepstrum&#x2026;</li>
</ol>
</div>

<div id="outline-container-orge6fa82c" class="outline-3">
<h3 id="orge6fa82c"><span class="section-number-3">2.1</span> Enlaces</h3>
<div class="outline-text-3" id="text-2-1">
<ol class="org-ol">
<li><a href="http://www.deeplearningbook.org/">http://www.deeplearningbook.org/</a></li>
<li><a href="http://ufldl.stanford.edu/tutorial/">http://ufldl.stanford.edu/tutorial/</a>  Deep Learning Tutorial</li>
<li><a href="https://developers.google.com/machine-learning/crash-course">https://developers.google.com/machine-learning/crash-course</a></li>
<li><a href="https://deeplearning.mit.edu/">https://deeplearning.mit.edu/</a></li>
<li><a href="http://cs229.stanford.edu">http://cs229.stanford.edu</a></li>
</ol>
</div>
</div>
</div>


<div id="outline-container-orgfac42e4" class="outline-2">
<h2 id="orgfac42e4"><span class="section-number-2">3</span> Semana 1</h2>
<div class="outline-text-2" id="text-3">
<p>
Intro, regresiÃ³n lineal, repaso de Ãlgebra.
</p>


<ul class="org-ul">
<li><a href="https://www.coursera.org/learn/machine-learning/discussions/weeks/1/threads/hAp4LT1SEeaL_xIEq4QdBw">FAQ de la semana 1</a></li>
</ul>
</div>

<div id="outline-container-org818b3ba" class="outline-3">
<h3 id="org818b3ba"><span class="section-number-3">3.1</span> Introduction</h3>
<div class="outline-text-3" id="text-3-1">
</div>
<div id="outline-container-org9a1f52a" class="outline-4">
<h4 id="org9a1f52a"><span class="section-number-4">3.1.1</span> Video: Welcome</h4>
</div>

<div id="outline-container-org25c8b66" class="outline-4">
<h4 id="org25c8b66"><span class="section-number-4">3.1.2</span> Video: What is Machine Learning</h4>
<div class="outline-text-4" id="text-3-1-2">
<ul class="org-ul">
<li>Los algoritmos mÃ¡s importantes son el aprendizaje supervisado y el aprendizaje no supervisado. Es esta ademÃ¡s la clasificaciÃ³n mÃ¡s general de algoritmos.
<ul class="org-ul">
<li>Otros son el aprendizaje por refuerzo y los sistemas de recomendaciÃ³n.</li>
</ul></li>
<li>Hay que aprender las herramientas, pero <b>es muy importante saber cÃ³mo y cuÃ¡ndo usarlas</b>.</li>
<li>Sea una mÃ¡quina que debe hacer una tarea T, con un desempeÃ±o P y que la exponemos a experiencias (instancias) E de esa tarea T. Se dice que la computadora aprende si su desempeÃ±o P en la tarea T <i>aumenta proporcionalmente a la cantidad de experiencias E</i>.</li>
<li>Otra definiciÃ³n de aprendizaje automÃ¡tico es la capacidad (de la computadora) de aprender a resolver problemas para los que no fue programada. ~</li>
</ul>
</div>
</div>

<div id="outline-container-orgc27371e" class="outline-4">
<h4 id="orgc27371e"><span class="section-number-4">3.1.3</span> Reading: What is Machine Learning?</h4>
</div>

<div id="outline-container-orgbc40ee3" class="outline-4">
<h4 id="orgbc40ee3"><span class="section-number-4">3.1.4</span> Video: Supervised Learning</h4>
<div class="outline-text-4" id="text-3-1-4">
<ul class="org-ul">
<li>En el aprendizaje supervisado, le mostramos al programa ejemplos de entradas y sus correspondientes salidas/respuestas correctas. Ya sabemos cÃ³mo son las respuestas corectas; tenemos la idea de que hay una relaciÃ³n entre las entradas y las salidas. Dado un conjunto de entradas y salidas, intentamos obtener un modelo que permita predecir/inferir las salidas a nuevos datos de entrada.</li>
<li>Los problemas de aprendizaje supervisado se clasifican en problemas de regresiÃ³n y de clasificaciÃ³n:
<ul class="org-ul">
<li>Problema de <b>regresiÃ³n</b> si el conjunto imagen es continuo. La salida es una variable numÃ©rica.</li>
<li>Problema de <b>clasificaciÃ³n</b> si el conjunto imagen es discreto. La salida es una variable categÃ³rica.</li>
</ul></li>
<li>Los algoritmos de MÃ¡quinas de Vector Soporte permiten <i><b>infinitos</b></i> valores de entrada.</li>
</ul>
</div>

<ol class="org-ol">
<li><a id="orgccf2857"></a><span class="todo TODO">TODO</span> Leer <a href="https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression">https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression</a><br /></li>

<li><a id="org2e5faa0"></a><span class="todo TODO">TODO</span> Leer <a href="https://datascience.stackexchange.com/questions/25298/how-to-know-when-to-treat-a-problem-as-a-classification-task-or-a-regression-tas">https://datascience.stackexchange.com/questions/25298/how-to-know-when-to-treat-a-problem-as-a-classification-task-or-a-regression-tas</a><br /></li>
</ol>
</div>

<div id="outline-container-orgd4fff1f" class="outline-4">
<h4 id="orgd4fff1f"><span class="section-number-4">3.1.5</span> Video: Unsupervised Learning</h4>
<div class="outline-text-4" id="text-3-1-5">
<ul class="org-ul">
<li>En el aprendizaje no supervisado, le damos datos al programa con la intenciÃ³n de encontrar estructuras subyacentes, patrones.</li>
<li>Un ejemplo tÃ­pico es el <i>clustering</i> o agrupamiento de datos.</li>
<li>En el ejemplo de sonido Cocktail Party, segÃºn <a href="https://www.coursera.org/learn/machine-learning/discussions/weeks/1/threads/hAp4LT1SEeaL_xIEq4QdBw">FAQ de la semana 1</a>, lo que usan es <i>Principal Component Analysis, PCA, a mathematical trick that takes two sets of correlated data, and returns two new sets of data that are not correlated.</i> No lo habÃ­a visto asÃ­ antes, creo&#x2026;</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org1c763e4" class="outline-3">
<h3 id="org1c763e4"><span class="section-number-3">3.2</span> Model and cost function</h3>
<div class="outline-text-3" id="text-3-2">
<p>
Vemos la regresiÃ³n lineal como primer algoritmo de aprendizaje supervisado.
</p>
</div>

<div id="outline-container-orgfad501a" class="outline-4">
<h4 id="orgfad501a"><span class="section-number-4">3.2.1</span> Video: Model representation</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
Un poco de nomenclatura:
</p>

<ul class="org-ul">
<li>\(m\): cantidad de ejemplos de entrenamiento.</li>
<li>\(\vec{x}\): entradas / descriptores / <i>features</i></li>
<li>\(\vec{y}\): salidas. \(\hat{\vec{y}}\) son las salidas estimadas.</li>
<li>\(h_\theta\): funciÃ³n de hipÃ³tesis, de estimaciÃ³n. Tiene parÃ¡metros \(\vec{\theta}\). Entonces tenemos que \( \hat{y}^{(i)} = h_\theta(x^{(i)}) = h(x,\theta) \)</li>
<li>\(x^{(i)}\): entrada $i$-Ã©sima del vector de entradas, con Ã­ndices empezando en 1.
<ul class="org-ul">
<li>\((x^{(i)},y^{(i)})\) es un ejemplo de entrenamiento.</li>
</ul></li>
<li>Para regresiÃ³n lineal de una variable tenemos entonces</li>
</ul>
<p>
\[ \hat{y}^{(i)} = h_\theta(x^{(i)}) = \theta_0 + \theta_1 * x^{(i)} \]
</p>
</div>
</div>

<div id="outline-container-org1efd2e7" class="outline-4">
<h4 id="org1efd2e7"><span class="section-number-4">3.2.2</span> Reading: Model representation</h4>
<div class="outline-text-4" id="text-3-2-2">
<ul class="org-ul">
<li>\(X\): el espacio de los valores de entrada.</li>
<li>\(Y\): el espacio de los valores de salida.</li>
<li>El objetivo del aprendizaje supervisado es encontrar una funciÃ³n \(h: X \rightarrow Y\) que sea buena prediciendo salidas a partir de entradas.</li>
</ul>
</div>
</div>

<div id="outline-container-orgc8783f8" class="outline-4">
<h4 id="orgc8783f8"><span class="section-number-4">3.2.3</span> Video: Cost function</h4>
<div class="outline-text-4" id="text-3-2-3">
<p>
Formalizamos el problema del aprendizaje como la minimizaciÃ³n de una funciÃ³n de costo \(J(\vec{\theta})\). La funciÃ³n de costo habitual y recomendada para problemas de regresiÃ³n lineal es el <b>error cuadrÃ¡tico medio</b> (<a href="https://en.wikipedia.org/wiki/Mean_squared_error"><i>Mean Squared Error</i></a> o <i>Mean Squared Deviation</i>).
</p>

<p>
Para un predictor como lo es \(h_\theta\), el MSE se define como
\[ MSE = \frac{1}{N} (\sum_{1}^{N}Y_i - \hat{Y}_i )^2\]
</p>

<p>
En nuestro caso vamos a definir a la funciÃ³n de costo para este problema de regresiÃ³n lineal univariable como
</p>

<p>
\[ J(\theta_0 , \theta_1) = \frac{1}{2m} \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} )^2  \]
\[ J(\theta_0 , \theta_1) =  \frac{1}{2m} \sum_{i=1}^m( \theta_0 + \theta_1 * x^{(i)} - y^{(i)} )^2 \]
</p>

<ul class="org-ul">
<li>El factor \(1/2\) es para ahorrar cÃ¡lculos, puesto que en redes neuronales al hacer <i>backpropagation</i> o <i>gradient descent</i> hay que derivar esta funciÃ³n de error y entonces con este \(1/2\) simplificamos el \(2\) de la derivada del cuadrado.</li>
</ul>

<p>
La optimizaciÃ³n es entonces encontrar los parÃ¡metros \(\theta\) que minimizan la funciÃ³n de costo:
\[ \underset{\theta_0 , \theta_1}{\text{min}}  J(\theta_0 , \theta_1)\]
</p>

<hr />

<p>
<i>En las notas del curso encontramos la forma matricial, que luego usamos para hacer descenso por el gradiente de forma matricial. Lo pongo acÃ¡ por completitud</i>.
</p>

<p>
MSE: \[ J(\theta) = \frac{1}{2m} (X\times\theta-Y)^T(X\times\theta-Y)  \]
</p>

<p>
El producto implica la sumatoria y el cuadrado elemento a elemento.
</p>

<hr />
</div>
</div>

<div id="outline-container-org1c8cbb0" class="outline-4">
<h4 id="org1c8cbb0"><span class="section-number-4">3.2.4</span> Reading: Cost function</h4>
</div>

<div id="outline-container-org3bc2d13" class="outline-4">
<h4 id="org3bc2d13"><span class="section-number-4">3.2.5</span> Video: Cost function intuition I</h4>
</div>

<div id="outline-container-org1047348" class="outline-4">
<h4 id="org1047348"><span class="section-number-4">3.2.6</span> Reading: Cost function intuition I</h4>
</div>

<div id="outline-container-org84553b9" class="outline-4">
<h4 id="org84553b9"><span class="section-number-4">3.2.7</span> Video: Cost function intuition II</h4>
</div>

<div id="outline-container-orgd7fc1d7" class="outline-4">
<h4 id="orgd7fc1d7"><span class="section-number-4">3.2.8</span> Reading: Cost function intuition II</h4>
<div class="outline-text-4" id="text-3-2-8">
<p>
De <a href="https://es.wikipedia.org/wiki/Isol%C3%ADnea">isolÃ­neas / curvas de nivel</a>.
</p>
</div>
</div>
</div>


<div id="outline-container-orga09c680" class="outline-3">
<h3 id="orga09c680"><span class="section-number-3">3.3</span> Parameter learning</h3>
<div class="outline-text-3" id="text-3-3">
</div>
<div id="outline-container-org7e160d4" class="outline-4">
<h4 id="org7e160d4"><span class="section-number-4">3.3.1</span> Video: Gradient descent</h4>
<div class="outline-text-4" id="text-3-3-1">
<p>
El descenso por el gradiente es un algoritmo de optimizaciÃ³n que vamos a usar (entre otras cosas) para minimizar la funciÃ³n de costo.
</p>

<p>
Hacer \[ \vec{\theta}[n+1] := \vec{\theta}[n] - \alpha \frac{\partial J(\vec{\theta})}{\partial\theta}  \]
</p>

<p>
(expresado de otra manera)
</p>

<p>
\[ {\theta}_j[n+1] := {\theta}_j[n] - \alpha \frac{\partial J(\vec{\theta})}{\partial\theta}  \]
</p>

<p>
Hasta la convergencia de \(\vec{\theta}\), equivalente a la convergencia de \(J(\vec{\theta})\):
</p>

<p>
\[  \vec{\theta}[n] - \vec{\theta}[n-1] < \vec{\epsilon} \]
\[ J(\vec{\theta}[n]) - J(\vec{\theta}[n-1])  < \epsilon  \]
</p>

<ul class="org-ul">
<li>Nomenclatura: usamos \(:=\) como operador de asignaciÃ³n.</li>
<li>\(\alpha\) es la tasa de aprendizaje o <i>learning rate</i> del algoritmo.</li>
</ul>

<p>
Para calcular la derivada hacemos derivadas parciales. Actualizamos los parÃ¡metros simultÃ¡neamente en cada paso. Si actualizamos de a uno y recalculamos estamos haciendo otro algoritmo, que probablemente tambiÃ©n converja pero es distinto.
</p>

<p>
Cuando la funciÃ³n de costo es el error cuadrÃ¡tico medio (<i>MSE</i>), la fÃ³rmula de actualizaciÃ³n queda:
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n] - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)}  \]
</p>

<ul class="org-ul">
<li>El primer termino de la sumatoria es la magnitud y direcciÃ³n del error.</li>
<li>El segundo tÃ©rmino de la sumatoria es la sensibilidad de J respecto al parÃ¡metro, y resulta ser igual a la magnitud del descriptor asociado a ese parÃ¡metro.</li>
</ul>

<hr />

<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=WnqQrPNYz5Q">Un video de <i>gradient descent</i> sugerido en las notas del curso</a>.</li>
</ul>
</div>
</div>

<div id="outline-container-orgce8029c" class="outline-4">
<h4 id="orgce8029c"><span class="section-number-4">3.3.2</span> Reading: Gradient descent</h4>
</div>

<div id="outline-container-org9613d23" class="outline-4">
<h4 id="org9613d23"><span class="section-number-4">3.3.3</span> Video: Gradient descent intuition</h4>
<div class="outline-text-4" id="text-3-3-3">
<ul class="org-ul">
<li>Si \(\alpha\) es muy grande, el algoritmo puede oscilar o incluso diverger.</li>
<li>Si \(\alpha\) es muy chica, puede tardar mucho en converger.</li>
<li>Con \(\alpha\) fija, los "pasos" que da el algoritmo son cada vez mÃ¡s chicos a medida que la funciÃ³n de costo se aproxima a un mÃ­nimo local.</li>
</ul>
</div>
</div>

<div id="outline-container-orge769493" class="outline-4">
<h4 id="orge769493"><span class="section-number-4">3.3.4</span> Reading: Gradient descent intuition</h4>
</div>

<div id="outline-container-org0bde613" class="outline-4">
<h4 id="org0bde613"><span class="section-number-4">3.3.5</span> Video: Gradient descent for linear regression</h4>
<div class="outline-text-4" id="text-3-3-5">
<p>
Dice Andrew cerca del minuto 4:40:
</p>

<blockquote>
<p>
But, it turns out that that the cost function for
linear regression is always going to be a bow shaped function like this.
The technical term for this is that this is called a convex function.
</p>
</blockquote>

<p>
Â¿Por quÃ©?
</p>

<ul class="org-ul">
<li>La funciÃ³n de costo \(J(\vec{\theta})\) es el error cuadrÃ¡tico medio (MSE).</li>
<li>El MSE es cuadrÃ¡tico respecto a los parÃ¡metros siempre y cuando estos sean lineales, de grado 1. <b>La funciÃ³n de hipÃ³tesis debe ser lineal respecto a los parÃ¡metros para que la funciÃ³n de costo sea cuadrÃ¡tica</b>.
<ul class="org-ul">
<li>Sea por ejemplo \[ h(x,y) =  a.x^2 + b.y^2 - c.x^2 y^2 \]. Esta funciÃ³n tiene mÃ¡s de un mÃ­nimo.</li>
</ul></li>
</ul>


<div class="figure">
<p><img src="imgs/001-01-nolineal.gif" alt="001-01-nolineal.gif" />
</p>
</div>

<ul class="org-ul">
<li>Su MSE quedarÃ­a algo como \[ x^4 + 2 x^2 y^2 - 2 x^4 y^2 + y^4 - 2 x^2 y^4 + x^4 y^4  \] (sÃ³lo <a href="https://www.wolframalpha.com/input/?i=%28x%5E2+%2B+y%5E2+-+x%5E2y%5E2%29%5E2">la elevÃ© al cuadrado</a>)</li>
</ul>


<div class="figure">
<p><img src="imgs/001-02-nolineal-cuadrado.gif" alt="001-02-nolineal-cuadrado.gif" />
</p>
</div>

<hr />

<p>
Hay otras formas de estimar los parÃ¡metros (regresores). Una de ellas es el mÃ©todo de los mÃ­nimos cuadrados (<a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">/Ordinary Least Squares</a>/). El descenso por el gradiente es mÃ¡s fÃ¡cil de computar que OLS, en el caso de datasets grandes.
</p>

<p>
En realidad todo lo que vimos es descenso por el gradiente por lotes, o <b><i>batch gradient descent</i></b>, que es cuando la funciÃ³n de costo se optimiza usando todas las entradas disponibles. Esto es costoso.
</p>
</div>



<ol class="org-ol">
<li><a id="org7339f46"></a><span class="todo TODO">TODO</span> Leer mÃ¡s de <a href="https://en.wikipedia.org/wiki/Linear_regression">regresiÃ³n lineal</a><br /></li>
</ol>



<li><a id="orge68266d"></a>RegresiÃ³n lineal<br /></li>
</ol>
</div>



<div id="outline-container-orgacbc2f4" class="outline-4">
<h4 id="orgacbc2f4"><span class="section-number-4">3.3.6</span> Reading: Gradient descent for linear regression</h4>
</div>
</div>

<div id="outline-container-org81f0f33" class="outline-3">
<h3 id="org81f0f33"><span class="section-number-3">3.4</span> Linear Algebra review</h3>
<div class="outline-text-3" id="text-3-4">
</div>
<div id="outline-container-orgd94fd3f" class="outline-4">
<h4 id="orgd94fd3f"><span class="section-number-4">3.4.1</span> Video: Matrix vector multiplication</h4>
<div class="outline-text-4" id="text-3-4-1">
<ul class="org-ul">
<li>MÃ¡s adelante vamos a ver por quÃ© es mejor vectorizar calculos en lugar de iterar.</li>
<li>Hace un truco interesante que es incluir a la ordenada al origen dentro del vector de parÃ¡metros &#x2014;en realidad estÃ¡ bien, es un parÃ¡metr calculado&#x2014;, y luego introduce una columna de \(1\)s en la matriz de entradas.
<ul class="org-ul">
<li>La alternativa es sumar la columna aparte. \(A*X + B\)</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgbe22c08" class="outline-4">
<h4 id="orgbe22c08"><span class="section-number-4">3.4.2</span> Video: Matrix matrix multiplication</h4>
<div class="outline-text-4" id="text-3-4-2">
<ul class="org-ul">
<li>AcÃ¡ hace el mismo truco pero para hacer varias predicciones a la vez: usa varios modelos y varias entradas.</li>
</ul>
</div>
</div>

<div id="outline-container-org7569932" class="outline-4">
<h4 id="org7569932"><span class="section-number-4">3.4.3</span> Video: Inverse and transpose</h4>
<div class="outline-text-4" id="text-3-4-3">
<p>
Interesante:
</p>
<blockquote>
<p>
But the intuition if you want is that you can think of matrices as not have an inverse that is somehow too close to zero in some sense.
</p>
</blockquote>

<ul class="org-ul">
<li>Las matrices que no tienen inversa son matrices <i>singulares</i> o <i>degeneradas</i>.
<ul class="org-ul">
<li>Asumo que se refiere a matrices cuadradas, que podrÃ­an tener inversa.</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-orge3390a5" class="outline-2">
<h2 id="orge3390a5"><span class="section-number-2">4</span> Semana 2</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org679e75c" class="outline-3">
<h3 id="org679e75c"><span class="section-number-3">4.1</span> Environment setup instructions</h3>
</div>

<div id="outline-container-orgb8eebb4" class="outline-3">
<h3 id="orgb8eebb4"><span class="section-number-3">4.2</span> Multivariate linear regression</h3>
<div class="outline-text-3" id="text-4-2">
</div>
<div id="outline-container-org26b13c6" class="outline-4">
<h4 id="org26b13c6"><span class="section-number-4">4.2.1</span> Video: Multivariate linear regression</h4>
<div class="outline-text-4" id="text-4-2-1">
<p>
En la regresiÃ³n lineal multivariable o regresiÃ³n lineal mÃºltiple, tenemos varios valores de entrada o descriptores. Para tener una notaciÃ³n mÃ¡s compacta y conveniente, vamos a definir:
</p>
<ul class="org-ul">
<li>\(\theta_0=1\) ;</li>
<li>\(n\) es la cantidad de entradas, descriptores;</li>
<li>vamos a usar \(\vec{\theta}\) con Ã­ndice \(0\);</li>
<li>y \(\vec{\theta}_j^{(i)}\) es el elemento j-Ã©simo del ejemplo i-Ã©simo.</li>
</ul>

<p>
Entonces \(\vec{\theta}\) tiene \(n+1\) elementos y  \[ \vec{\theta} = 1 + \theta_1 + \theta_2 + \dots + \theta_n  \]
</p>


<p>
Y luego \[ \vec{h_\theta}(\vec{x}) = \vec{\theta}^T \cdot \vec{x}  = \vec{x}^T \cdot \vec{\theta}  \]
</p>

<ul class="org-ul">
<li>IntuiciÃ³n para el ejemplo de estimar el precio de un inmueble: \(\theta_0\) es el precio base.</li>
</ul>

<hr />

<p>
<i>En <a href="#org0b30f7b">4.3.1</a> se introduce notaciÃ³n matricial que luego en el ejercicio 1 usamos para expresar todo de forma vectorizada. Dejo todo acÃ¡ para mÃ¡s completitud</i>.
</p>

<p>
\[ \hat{Y}(&theta;,X) = X &theta;  ]\
</p>

<hr />
</div>
</div>

<div id="outline-container-org97a975c" class="outline-4">
<h4 id="org97a975c"><span class="section-number-4">4.2.2</span> Reading: multiple features</h4>
</div>

<div id="outline-container-org8eb1064" class="outline-4">
<h4 id="org8eb1064"><span class="section-number-4">4.2.3</span> Video: Gradient descent for multiple features</h4>
<div class="outline-text-4" id="text-4-2-3">
<p>
La regla de actualizaciÃ³n era:
</p>

<p>
\[ \vec{\theta}[n+1] := \vec{\theta}[n] - \alpha \frac{\partial J(\vec{\theta})}{\partial\theta}  \]
</p>

<p>
Y para cuando la funciÃ³n de costo es el error cuadrÃ¡tico medio (MSE), queda (para actualizaciÃ³n con <b>todos los \(m\) ejemplos</b>):
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n] - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)}  \]
</p>

<ul class="org-ul">
<li>Puedo ver el factor de avance luego de \(\alpha\) como el aporte al error medio que hizo el descriptor \(x_j\) .
<ul class="org-ul">
<li>El producto vectorial y la resta son el error medio para ese vector de entrada.</li>
<li>El factor \(x_j\) es el aporte de ese elemento, en esa direcciÃ³n.
<ul class="org-ul">
<li>La direcciÃ³n final es la suma vectorial de los elementos.</li>
</ul></li>
</ul></li>
</ul>

<hr />

<p>
<i>La versiÃ³n vectorizada/matricial del algoritmo estÃ¡ en las notas del curso y despuÃ©s la usamos en el ejercicio de programaciÃ³n 1. La dejo acÃ¡ por completitud</i>.
</p>

<p>
\[ \theta_{n \times 1}[i+1] = \theta_{n \times 1}[i] - \frac{\alpha}{m} X_{m \times n}^T (X_{m \times n} \theta_{n \times 1} - Y_{m \times 1} )_{m \times 1} \]
\[ \theta_{}[i+1] = \theta[i] - \frac{\alpha}{m} X^T (X \theta - Y) \]
</p>

<hr />
</div>

<ol class="org-ol">
<li><a id="orgb844e62"></a><span class="todo TODO">TODO</span> EL ERROR ES MAYPR CUANDO HAY CORRELACIÃN ENTRE DESCRIPTORES Y PARÃMETROS.<br /></li>
</ol>
</div>

<div id="outline-container-orga263964" class="outline-4">
<h4 id="orga263964"><span class="section-number-4">4.2.4</span> Reading: Gradient descent for multiple features</h4>
</div>

<div id="outline-container-org7ed21f6" class="outline-4">
<h4 id="org7ed21f6"><span class="section-number-4">4.2.5</span> Video: Gradient descent in practice I - Feature scaling</h4>
<div class="outline-text-4" id="text-4-2-5">
<ul class="org-ul">
<li>Al parecer, el algoritmo de descenso por el gradiente converge <b>bastante mÃ¡s rÃ¡pidamente</b> si los descriptores estÃ¡n en el mismo orden de magnitud.
<ul class="org-ul">
<li>Andrew propone que estÃ©n <i>mÃ¡s o menos</i> en el rango \(-3 < x_j < 3\) y duda si \(-\frac{1}{3} < x < \frac{1}{3}\)</li>
</ul></li>
<li>Para esto se suele normalizar cada descriptor respecto al rango de sÃ­ mismo en la muestra (los m ejemplos de entrada) o respecto a la desviaciÃ³n estÃ¡ndar. Esto se llama <b><i>feature scaling</i></b>.</li>
<li>Otra prÃ¡ctica habitual es centrar en cero los valores, para lo cual se resta la media de la muestra. Esto se llama <b><i>mean normalization</i></b>.</li>
</ul>
</div>

<ol class="org-ol">
<li><a id="orgd3eec07"></a>MÃ¡s de feature scaling y mean normalization<br />
<div class="outline-text-5" id="text-4-2-5-1">
<p>
De la ecuaciÃ³n de actualizaciÃ³n de los parÃ¡metros de la ecuaciÃ³n de hipÃ³tesis
infiero que el vector se mueve <span class="underline">mÃ¡s rÃ¡pidamente</span> en direcciÃ³n de los parÃ¡metros
mÃ¡s grandes. Sin embargo en <a href="#orgf793a1d">4.2.6</a> dice:
</p>

<blockquote>
<p>
This is because Î¸ will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.
</p>
</blockquote>
</div>

<ol class="org-ol">
<li><a id="org1366fdd"></a><span class="done DONE">DONE</span> Averiguar mÃ¡s de esto. Â¿Por quÃ© se hace? Â¿Tienen que ser de la misma magnitud o ser chicos?<br />
<div class="outline-text-7" id="text-4-2-5-1-0-1">
<ul class="org-ul">
<li>Ver <a href="https://www.robertoreif.com/blog/2017/12/21/importance-of-feature-scaling-in-data-modeling-part-2">https://www.robertoreif.com/blog/2017/12/21/importance-of-feature-scaling-in-data-modeling-part-2</a></li>
<li>Ver <a href="https://math.stackexchange.com/questions/2341704/feature-scalings-effect-on-gradient-descent">https://math.stackexchange.com/questions/2341704/feature-scalings-effect-on-gradient-descent</a></li>
</ul>

<p>
Estaba entendiendo mal las curvas de nivel. El eje corto de las elipses es el asociado a los descriptores mÃ¡s grandes, con mÃ¡s rango. Son curvas de nivel de \(J(\theta)\), no de \(J(x)\).  Ahora si estoy de acuerdo.
</p>

<p>
En regresiÃ³n lineal (quizÃ¡s puedo generalizarlo a cualquiera) <b>los parÃ¡metros tienen rangos "inversos" a los de los descriptores que multiplican</b>. Si un descriptor tiene un rango grande, entonces su parÃ¡metro asociado va a tener un rango chico.
</p>

<p>
<span class="underline">Se podrÃ­a solucionar tambiÃ©n con learning rates diferenciados: mÃ¡s grandes para los descriptores de mÃ¡s rango, mÃ¡s chicos para los de menos rango.</span>
</p>

<p>
Â¡Lo que dice en <a href="#orgf793a1d">4.2.6</a> estÃ¡ mal expresado entonces!
</p>
</div>
</li>

<li><a id="org4309aa0"></a><span class="todo TODO">TODO</span> Corregir <a href="https://math.stackexchange.com/questions/2341704/feature-scalings-effect-on-gradient-descent">https://math.stackexchange.com/questions/2341704/feature-scalings-effect-on-gradient-descent</a><br /></li>
</ol>
</li>
</ol>
</div>

<div id="outline-container-orgf793a1d" class="outline-4">
<h4 id="orgf793a1d"><span class="section-number-4">4.2.6</span> Reading: Gradient descent in practice I - Feature scaling</h4>
</div>


<div id="outline-container-org68572af" class="outline-4">
<h4 id="org68572af"><span class="section-number-4">4.2.7</span> Video: Gradient descent in practice II - Learning rate</h4>
<div class="outline-text-4" id="text-4-2-7">
<ul class="org-ul">
<li>Si la funciÃ³n de costo \(J(\vec{\theta})\) diverge u oscila, entonces mi tasa de aprendizaje \(\alpha\) es muy grande. Si es muy chica, converge lentamente.</li>
<li>Puedo verlo graficando la funciÃ³n de costo.</li>
<li>Elegir el valor de \(\alpha\) es, a priori, por prueba y error. <b><i>Â¿HabrÃ¡ heurÃ­sticas para determinar un buen valor inicial?</i></b></li>
<li>La condiciÃ³n de convergencia tambiÃ©n suele depender del problema. Andrew habla de valores absolutos&#x2026; <b><i>Â¿por quÃ© no usar un \(\epsilon\) relativo?</i></b></li>
</ul>
</div>
</div>

<div id="outline-container-orgd9eb9c2" class="outline-4">
<h4 id="orgd9eb9c2"><span class="section-number-4">4.2.8</span> Reading: Gradient descent in practice II - Learning rate</h4>
</div>


<div id="outline-container-org4552c44" class="outline-4">
<h4 id="org4552c44"><span class="section-number-4">4.2.9</span> Video: Features and polynomial regression</h4>
</div>

<div id="outline-container-org110d4fe" class="outline-4">
<h4 id="org110d4fe"><span class="section-number-4">4.2.10</span> Reading: Features and polynomial regression</h4>
<div class="outline-text-4" id="text-4-2-10">
<ul class="org-ul">
<li>La regresiÃ³n lineal es ajustar un modelo lineal, de grado 1, una combinaciÃ³n lineal entre las entradas y parÃ¡metros.</li>
<li>Podemos ajustar modelos no lineales como hipÃ³tesis si codificamos estas no linealidades dentro de los descriptores. Por ejemplo, para el caso de la estimaciÃ³n de precios de casas, un posible descriptor podrÃ­a ser el cuadrado del Ã¡rea, y ahÃ­ estamos incluyendo algo cuadrÃ¡tico en el modelo.</li>
<li>Al incluir las no linealidades en los descriptores, pero todavÃ­a usando los parÃ¡metros como multiplicadores de orden 1, podemos seguir usando el descenso por el gradiente para optimizar.</li>
<li>Andrew habla tambiÃ©n de usar relaciones entre entradas bÃ¡sicas para construir otras entradas. Por ejemplo, el producto de dos descriptores hace un nuevo descriptor que codifica otra relaciÃ³n.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgf9618e0" class="outline-3">
<h3 id="orgf9618e0"><span class="section-number-3">4.3</span> Computing parameters analitically</h3>
<div class="outline-text-3" id="text-4-3">
</div>
<div id="outline-container-org0b30f7b" class="outline-4">
<h4 id="org0b30f7b"><span class="section-number-4">4.3.1</span> Video: Normal equation</h4>
<div class="outline-text-4" id="text-4-3-1">
<ul class="org-ul">
<li>Otra forma de optimizar la regresiÃ³n lineal es resolverla analÃ­ticamente con el mÃ©todo de los <a href="https://en.wikipedia.org/wiki/Least_squares">mÃ­nimos cuadrados</a> <a href="https://en.wikipedia.org/wiki/Linear_least_squares">lineales</a> / ecuaciÃ³n normal. Esto da la soluciÃ³n Ã³ptima (que existe porque hemos dicho que para regresiÃ³n lineal es un espacio de bÃºsqueda cÃ³nvexo con un solo mÃ­nimo).</li>
</ul>

<p>
\[  \vec{\theta} = ( X^T \times X )^{-1} \times X^T \times \vec{y}   \]
</p>

<p>
\[ X = \left[  x^{(i)}  \right]  \]
</p>

<ul class="org-ul">
<li>A \(X\) la llamamos <b><i>matriz de diseÃ±o</i></b>. Cada fila es un ejemplo, y tiene tamaÃ±o $m &times; n+1 $</li>

<li>La complejidad de invertir una matriz es \(O(n^3)\) y esto se pone lento para \(n > 10^5\). La complejidad del descenso por el gradiente, en cambio, es de \(O(k \cdot n^2)\).</li>

<li>\(( X^T \times X )^{-1} \times X^T = X^{+}\) es la <span class="underline"><a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">pseudoinversa</a></span> de \(X\), y el mÃ©todo de mÃ­nimos cuadrados no es mÃ¡s que una soluciÃ³n (Ã³ptima en el sentido del error cuadrÃ¡tico) de un sistema de ecuaciones sobredeterminado.

<ul class="org-ul">
<li>La pseudoinversa se puede calcular con <i>Singular Value Decomposition</i> o DescomposiciÃ³n QR, por ejemplo.</li>

<li>La regresiÃ³n por mÃ­nimos cuadrados asume muchas cosas que no necesariamente siempre se cumplen. Ver la <a href="https://en.wikipedia.org/wiki/Robust_regression">regresiÃ³n robusta</a> como alternativa.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org262d9aa" class="outline-4">
<h4 id="org262d9aa"><span class="section-number-4">4.3.2</span> Reading: Normal equation</h4>
</div>

<div id="outline-container-org33a7014" class="outline-4">
<h4 id="org33a7014"><span class="section-number-4">4.3.3</span> Video: Normal equation noninvertibility</h4>
<div class="outline-text-4" id="text-4-3-3">
<p>
Si \(( X^T \times X )\) no es invertible, entonces puede haber 2 problemas:
</p>

<ol class="org-ol">
<li>El sistema esta subdeterminado. Faltan ejemplos, \(m < n\) / tenemos muchos descriptores.
<ul class="org-ul">
<li>DespuÃ©s vamos a ver que se soluciona con <i>regularizaciÃ³n</i>.</li>
</ul></li>
<li>Algunos descriptores estÃ¡n muy correlacionados / son linealmente dependientes.</li>
</ol>

<p>
Si no es invertible naturalmente (es singular o degenerada) igual se puede invertir con la pseudoinversa. Igual esto no serÃ­a problema si hubiÃ©semos usado la pseudoinversa desde un principio en lugar de estar haciÃ©ndolo manualmente. Y, nuevamente, seguro hay mÃ©todos mÃ¡s robustos (aunque no hay que dejar de hacer anÃ¡lisis de la informaciÃ³n con la que contamos).
</p>
</div>
</div>

<div id="outline-container-org5237118" class="outline-4">
<h4 id="org5237118"><span class="section-number-4">4.3.4</span> Reading: Normal equation noninvertibility</h4>
</div>
</div>


<div id="outline-container-org161fb92" class="outline-3">
<h3 id="org161fb92"><span class="section-number-3">4.4</span> Submitting programming assignments</h3>
</div>

<div id="outline-container-orga9d7624" class="outline-3">
<h3 id="orga9d7624"><span class="section-number-3">4.5</span> Review</h3>
</div>

<div id="outline-container-org3c6a88e" class="outline-3">
<h3 id="org3c6a88e"><span class="section-number-3">4.6</span> Octave/Matlab tutorial</h3>
<div class="outline-text-3" id="text-4-6">
<div class="org-src-container">
<pre class="src src-octave"><span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Para ver una matriz/vector como p&#237;xeles con color</span>
A <span style="color: #4f97d7;">=</span> magic<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">9</span><span style="color: #4f97d7;">)</span>
figure
imagesc<span style="color: #4f97d7;">(</span>A<span style="color: #4f97d7;">)</span>
colorbar
colormap gray
</pre>
</div>
</div>
</div>


<div id="outline-container-org640dfea" class="outline-3">
<h3 id="org640dfea"><span class="section-number-3">4.7</span> Review</h3>
<div class="outline-text-3" id="text-4-7">
</div>
<div id="outline-container-orgc2a60d4" class="outline-4">
<h4 id="orgc2a60d4"><span class="section-number-4">4.7.1</span> Programming assignment 1: linear regression</h4>
<div class="outline-text-4" id="text-4-7-1">
<ul class="org-ul">
<li>Mi gradient descent convergÃ­a pero no al mismo resultado exacto, y mÃ¡s rÃ¡pida o lentamente. Me faltaba el factor \(1/m\).</li>
<li>ArmÃ© una versiÃ³n vectorizada del gradient descent pero es distinta a la propuesta:</li>
</ul>

<p>
La mÃ­a:
</p>

<ul class="org-ul">
<li>usÃ© \(n\) como la longitud de \(\theta\), incluyendo los \(1\)s.</li>
</ul>

<div class="org-src-container">
<pre class="src src-octave">M <span style="color: #4f97d7;">=</span> length<span style="color: #4f97d7;">(</span>y<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span> <span style="color: #2aa1ae; background-color: #292e34;">% number of training examples</span>
N <span style="color: #4f97d7;">=</span> length<span style="color: #4f97d7;">(</span>theta<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
error <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span>X <span style="color: #4f97d7;">*</span> theta<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">-</span> y<span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% Mx1</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">ponderated_error = repmat(error, [1, N]) .* X;  % MxN</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">ponderated_error = error * ones(1,n) * X  % MxN, equivale al broadcasting</span>
ponderated_error <span style="color: #4f97d7;">=</span> error <span style="color: #4f97d7;">.*</span> X<span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% Broadcasting. MxN</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">gradient = sum(ponderated_error,1);  % 1xN</span>
gradient <span style="color: #4f97d7;">=</span> ones<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">,</span>M<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> ponderated_error<span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% 1xN, equivalente a la sumatoria</span>
theta <span style="color: #4f97d7;">=</span> theta <span style="color: #4f97d7;">-</span> <span style="color: #4f97d7;">(</span>alpha<span style="color: #4f97d7;">/</span>M<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> gradient<span style="color: #4f97d7;">';</span>  <span style="color: #2aa1ae; background-color: #292e34;">% Nx1</span>
</pre>
</div>

<p>
\[ \theta_{n \times 1}[i+1] = \theta_{n \times 1}[i] - \frac{\alpha}{m} \left[ 1_{1 \times m} \left( X_{m \times n} \theta_{n \times 1} - Y_{m \times 1} \right)_{m \times 1} 1_{1 \times n} X_{m \times n} \right]^T  \]
</p>

<p>
La original es mÃ¡s compacta:
</p>

<p>
\[ \theta_{n \times 1}[i+1] = \theta_{n \times 1}[i] - \frac{\alpha}{m} X_{m \times n}^T (X_{m \times n} \theta_{n \times 1} - Y_{m \times 1} )_{m \times 1} \]
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgbcde6a2" class="outline-2">
<h2 id="orgbcde6a2"><span class="section-number-2">5</span> Semana 3</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-orgc9e6775" class="outline-3">
<h3 id="orgc9e6775"><span class="section-number-3">5.1</span> Classification and representation</h3>
<div class="outline-text-3" id="text-5-1">
</div>
<div id="outline-container-org0087473" class="outline-4">
<h4 id="org0087473"><span class="section-number-4">5.1.1</span> Classification</h4>
<div class="outline-text-4" id="text-5-1-1">
<p>
Vamos a ver la <b>regresiÃ³n logÃ­stica</b> que es un algoritmo de clasificaciÃ³n (aunque su nombre diga <i>regresiÃ³n</i>).
</p>

<p>
La regresiÃ³n lineal no es un buen mÃ©todo para la clasificaciÃ³n en variables discretas. AcÃ¡ necesitamos algo mÃ¡s no lineal. Una opciÃ³n es usar regresiÃ³n lineal + un umbral arbitrario de separaciÃ³n, pero aÃºn no es suficiente.
</p>

<p>
Vamos a ver clasificaciÃ³n binaria. Definimos como \(0\) y \(1\) a las clases. TambiÃ©n usamos <b>etiqueta</b> para denominar a la salida \(h_\theta(x)\).
</p>
</div>
</div>

<div id="outline-container-org32cd098" class="outline-4">
<h4 id="org32cd098"><span class="section-number-4">5.1.2</span> Hypothesis representation</h4>
<div class="outline-text-4" id="text-5-1-2">
<p>
En clasificaciÃ³n binaria, los resultados observados sÃ³lo pueden tomar los valores \(0\) y \(1\), y por tanto nuestra funciÃ³n de hipÃ³tesis deberÃ­a tambiÃ©n sÃ³lo tomar esos valores.
</p>

<p>
Para empezar elegimos una funciÃ³n que estÃ© acotada a ese rango. Una opciÃ³n es la <b>funciÃ³n logÃ­stica</b> o <b>sigmoidea</b>:
</p>

<p>
\[ h(z) = \frac{1}{1+e^z} \]
</p>

<p>
\[ h(\theta,x) = h_\theta(x) = \frac{1}{1+e^{\theta^T  x}}\]
</p>

<ul class="org-ul">
<li>Mapea los reales al intervalo \([0, 1]\).</li>
</ul>

<p>
Podemos interpretar los resultados como la probabilidad de que la hipÃ³tesis tome un valor, dada determinada entrada.
</p>

<ul class="org-ul">
<li>La suma de las probabilidades debe ser \(1\).</li>
</ul>
</div>


<ol class="org-ol">
<li><a id="orgf4d8da0"></a>La funciÃ³n logÃ­stica o sigmoidea<br />
<div class="outline-text-5" id="text-5-1-2-1">
<ul class="org-ul">
<li>Se parece a la funciÃ³n cumulativa o funciÃ³n de distribuciÃ³n acumulada de una distribuciÃ³n normal/gaussiana.
<ul class="org-ul">
<li>Pero esta tiene una funciÃ³n explÃ­cita, mientras que la FDA de la gaussiana no tiene forma cerrada.</li>
<li>La funciÃ³n de densidad de probabilidad asociada "Se parece a la distribuciÃ³n normal en su forma, pero tiene colas mÃ¡s pesadas (y, por lo tanto, menor curtosis)". <a href="https://es.wikipedia.org/wiki/Distribuci%C3%B3n_log%C3%ADstica">Wikipedia: DistribuciÃ³n logÃ­stica</a></li>
</ul></li>
<li>Puedo pensar que la FDP de la distribuciÃ³n logÃ­stica me indica la cantidad de informaciÃ³n que me da el valor de un descriptor. En el pico es donde mÃ¡s aporta; luego mientras mÃ¡s me alejo del centro, mÃ¡s claro es que es de una clase o de la otra.</li>
<li>Es una aproximaciÃ³n suave de la funciÃ³n escalÃ³n.</li>
</ul>


<div class="figure">
<p><img src="imgs/002-320px-Logistic-curve.svg.png" alt="002-320px-Logistic-curve.svg.png" />
</p>
</div>

<p>
\[ f(x) = \frac{L}{1+e^{-k(x-x_0)}}  \]
</p>

<ul class="org-ul">
<li>\(L\) es el valor mÃ¡ximo.</li>
<li>\(k\) es la tasa de crecimiento o pendiente de la curva.</li>
<li>\(x_0\) es el centro</li>
</ul>
</div>
</li>
</ol>
</div>

<div id="outline-container-org4d283af" class="outline-4">
<h4 id="org4d283af"><span class="section-number-4">5.1.3</span> Decision boundary</h4>
<div class="outline-text-4" id="text-5-1-3">
<p>
La clasificaciÃ³n es discreta; para hacerla discreta necesitamos agregar un umbral a nuestra funciÃ³n de hipÃ³tesis. <i>No entiendo por quÃ© pone el umbral como si fuese una cosa aparte de la funciÃ³n de hipÃ³tesis</i>. Entonces, para la regresiÃ³n logÃ­stica hacemos:
</p>

<p>
\[ y = 0 \quad \text{si} \quad h(z) = h(z(\theta, x)) = h(\theta^T x) \lt 0,5 \]
\[ y = 0 \quad \text{si} \quad h(z) = h(z(\theta, x)) = h(\theta^T x) \geq 0,5 \]
</p>

<p>
Lo que equivale a
</p>

<p>
\[ y = 0 \quad \text{si} \quad  \theta^T x < 0,5 \]
\[ y = 1 \quad \text{si} \quad \theta^T x \ge 0,5 \]
</p>

<p>
La funciÃ³n de entrada a la sigmoidea, \(z(\theta,x)\) define el umbral de decisiÃ³n. Al igual que vimos para regresiÃ³n lineal, esta funciÃ³n no tiene por quÃ© ser lineal con respecto a los descriptores (<i>Â¿mas sÃ­ lineal respecto a los parÃ¡metros?</i>), y es la que va a separar las clases en su espacio. Por ejemplo, para dos variables podrÃ­a ser un elipsoide: \( z(\theta,x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1^2 + \theta_4 x_2^2 \).
</p>
</div>
</div>
</div>

<div id="outline-container-org572f93e" class="outline-3">
<h3 id="org572f93e"><span class="section-number-3">5.2</span> Logistic regression model</h3>
<div class="outline-text-3" id="text-5-2">
</div>
<div id="outline-container-org1b4cd15" class="outline-4">
<h4 id="org1b4cd15"><span class="section-number-4">5.2.1</span> Cost function</h4>
<div class="outline-text-4" id="text-5-2-1">
<p>
Sea la funciÃ³n de costo \(J\) la media de una funciÃ³n de error:
</p>

<p>
\[ J(\theta) = \frac{1}{m} \sum_1^m  error(\hat{y}, y) \]
</p>

<p>
Si usamos el error cuadrÃ¡tico medio como funciÃ³n de error para optimizar con el descenso por el gradiente, vamos a tener que derivar una funciÃ³n no lineal. Esto es porque la funciÃ³n logÃ­stica/sigmoidea \(h(z)\) no es lineal con respecto a los parÃ¡metros &theta;, y por tanto el error cuadrÃ¡tico medio no es una funciÃ³n convexa; esto implica que tiene (Â¿o puede tener?) mÃ¡s de un mÃ­nimo.
</p>

<p>
Lo que hacemos entonces es proponer otra funciÃ³n de error que sea convexa y diferenciable. Por supuesto, tiene que penalizar las predicciones/hipÃ³tesis errÃ³neas. La que se propone es
</p>

<p>
\[ error(h_\theta(x)) = error(h(\theta,x) = \quad -\log(h_\theta(x)) \quad \text{si} \quad y = 1   \]
\[ error(h_\theta(x)) = error(h(\theta,x) = \quad -\log(1-h_\theta(x)) \quad \text{si} \quad y = 0   \]
</p>


<div class="figure">
<p><img src="./imgs/003-01-logcost1.png" alt="003-01-logcost1.png" />
</p>
</div>




<div class="figure">
<p><img src="./imgs/003-02-logcost2.png" alt="003-02-logcost2.png" />
</p>
</div>

<ul class="org-ul">
<li>NÃ³tese que tienden a infinito en \(0\) y \(1\) respectivamente.</li>
<li>Usamos el <b>logaritmo natural</b>, base \(e\).</li>
</ul>

<hr />

<p>
En la secciÃ³n siguiente Andrew dice que esta funciÃ³n de costo (en realidad su forma simplificada) se puede derivar estadÃ­sticamente a partir del principio de estimaciÃ³n de mÃ¡xima verisimilitud.
</p>
</div>
</div>

<div id="outline-container-org3c462cb" class="outline-4">
<h4 id="org3c462cb"><span class="section-number-4">5.2.2</span> Simplified cost function and gradient descent</h4>
<div class="outline-text-4" id="text-5-2-2">
</div>
<ol class="org-ol">
<li><a id="org543c7b5"></a>Forma simplificada<br />
<div class="outline-text-5" id="text-5-2-2-1">
<p>
TenÃ­amos a la funciÃ³n de error para la regresiÃ³n logÃ­stica como:
</p>

<p>
\[ error(h_\theta(x)) = error(h(\theta,x)) = \quad -\log(h_\theta(x)) \quad \text{si} \quad y = 1   \]
\[ error(h_\theta(x)) = error(h(\theta,x)) = \quad -\log(1-h_\theta(x)) \quad \text{si} \quad y = 0   \]
</p>

<p>
La forma simplificada es:
</p>

<p>
\[ error(h(\theta,x)) = y (-\log(h_\theta(x))) + (1-y) (-\log(1-h_\theta(x)))   \]
</p>

<p>
\[ error(h(\theta,x)) = -y \log(\hat{y}) - (1-y) \log(\hat{y})  \]
</p>

<p>
Esta funciÃ³n es convexa (si \(h\) es la sigmoidea, al menos).
</p>

<p>
Luego la funciÃ³n de costo queda:
</p>

<p>
\[  J(h_\theta(x)) = J(h(\theta,x)) =  \frac{1}{m} \sum_{i=1}^m \left[ -y^{(i)} \log(h_\theta(x^{(i)})) - (1-y^{(i)}) \log(1-h_\theta(x^{(i)}))  \right]  \]
</p>

<p>
La forma vectorizada/matricial es:
</p>

<p>
\[ J(h(\theta,X)) = \frac{1}{m} \left[ - Y^T \log(h(X\theta)) - (1-Y)^T \log(1-h(X\theta)) \right]  \]
</p>
</div>
</li>

<li><a id="org0c142cd"></a>Descenso por el gradiente<br />
<div class="outline-text-5" id="text-5-2-2-2">
<p>
Resulta que la derivada \(\delta J(\theta,x)/\delta \theta\), es la misma que la que obtuvimos usando el error cuadrÃ¡tico medio (<i>MSE</i>) como funciÃ³n de costo para regresiÃ³n lineal, y entonces la formula de actualizaciÃ³n de parÃ¡metros es la misma:
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n] - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)}  \]
</p>

<p>
En forma vectorizada/matricial:
</p>

<p>
\[ \theta_{}[i+1] = \theta[i] - \frac{\alpha}{m} X^T (h(X \theta) - Y) \]
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-orgd697528" class="outline-4">
<h4 id="orgd697528"><span class="section-number-4">5.2.3</span> Advanced optimization</h4>
<div class="outline-text-4" id="text-5-2-3">
<p>
Hay algoritmos generales de optimizaciÃ³n mejores (pero mÃ¡s complejos) que el descenso por el gradiente. Andrew nombra:
</p>
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">Gradientes conjugados</a></li>
<li>BFGS (<a href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm"><i>BroydenâFletcherâGoldfarbâShanno algorithm</i></a>)</li>
<li>L-BFGS (<a href="https://en.wikipedia.org/wiki/Limited-memory_BFGS"><i>Limited memory BFGS</i></a>)</li>
</ul>

<p>
En Octave tenemos la funciÃ³n <code>fminunc</code> (de <i>function minimize unconstrained</i>) que nos permite optimizar usando una funciÃ³n de costo arbitraria. Le tenemos que proveer esa funciÃ³n de costo, que calcula la funciÃ³n de costo y el gradiente en cada iteraciÃ³n. En el ejemplo de Andrew, la funciÃ³n de costo calcula el gradiente de forma analÃ­tica, pero asumo que podrÃ­as tambiÃ©n tener una memoria y usar diferencias.
</p>
</div>
</div>
</div>

<div id="outline-container-org1a3cca7" class="outline-3">
<h3 id="org1a3cca7"><span class="section-number-3">5.3</span> Multiclass classification</h3>
<div class="outline-text-3" id="text-5-3">
</div>
<div id="outline-container-org47bae88" class="outline-4">
<h4 id="org47bae88"><span class="section-number-4">5.3.1</span> Multiclass classification: one vs all</h4>
<div class="outline-text-4" id="text-5-3-1">
<p>
Si tenemos \(n\) salidas discretas posibles, podemos modelar el problema con \(n\) clasificadores binarios, que toman una salida como caso positivo y el resto como negativo.
</p>

<p>
Una vez que clasificamos con todos los clasificadores, elegimos la salida definitiva como aquella que haya tenido la mayor confianza; y entonces tenemos que ver la probabilidad predicha antes de discretizarla.
</p>

<p>
NÃ³tese que esto tambiÃ©n se cumple en los binarios cuando \(n=2\): podemos verlo como que ambos clasificadores definen la misma frontera de decisiÃ³n.
</p>
</div>
</div>
</div>

<div id="outline-container-orgbc2e9f5" class="outline-3">
<h3 id="orgbc2e9f5"><span class="section-number-3">5.4</span> Solving the problem of overfitting</h3>
<div class="outline-text-3" id="text-5-4">
</div>
<div id="outline-container-org091891b" class="outline-4">
<h4 id="org091891b"><span class="section-number-4">5.4.1</span> The problem of overfitting</h4>
<div class="outline-text-4" id="text-5-4-1">
<p>
Empezamos a evaluar la bondad de ajuste de nuestros modelos.
</p>

<ul class="org-ul">
<li>Un modelo subajustado (<i>underfitted</i>) o de alto sesgo (<i>high bias</i>) tiene mucho error para los datos con los que se entrenÃ³, y por ende muy probablemente tenga mucho error con entradas nuevas. El modelo no captura las caracterÃ­sticas del espacio del problema.
<ul class="org-ul">
<li>El sesgo se asocia con prejuicio. El modelo prejuzga incorrectamente cÃ³mo deberÃ­an ser las entradas.</li>
</ul></li>
<li>Un modelo sobreajustado (<i>overfitted</i>) predice <i>demasiado</i> correctamente los datos con los que se ajustÃ³, pero no predice correctamente entradas que sean un poco distintas; <b>no generaliza</b>. TambiÃ©n se habla de que es un modelo con alta varianza (<i>high variance</i>), porque el espacio de funciones de hipÃ³tesis (de la complejidad propuesta) que predicen bien es muy grande; hay muchos grados de libertad.</li>
</ul>

<p>
En los ejemplos mostrados, el ajuste se incrementa con el grado de las funciones de hipÃ³tesis, para regresiÃ³n lineal. Entonces complejizar las funciones de hipÃ³tesis implica agregar mÃ¡s descriptores &#x2014;reales o sintÃ©ticos&#x2014;.
</p>
</div>

<ol class="org-ol">
<li><a id="orgc19a0ea"></a>Opciones para reducir el sobreajuste<br />
<div class="outline-text-5" id="text-5-4-1-1">
<p>
Las principales formas de reducir el sobreajuste:
</p>

<ol class="org-ol">
<li>Reducir la cantidad de descriptores.
<ul class="org-ul">
<li>Manualmente o con mÃ©todos automÃ¡ticos de selecciÃ³n de modelo.</li>
<li>Perdemos informaciÃ³n codificada en los descriptores que eliminamos.</li>
</ul></li>
<li>Usar <b>regularizaciÃ³n</b>.
<ul class="org-ul">
<li>Mantenemos todos los descriptores pero los ponderamos.</li>
</ul></li>
</ol>
</div>
</li>
</ol>
</div>

<div id="outline-container-org6d3f387" class="outline-4">
<h4 id="org6d3f387"><span class="section-number-4">5.4.2</span> Cost function</h4>
<div class="outline-text-4" id="text-5-4-2">
<p>
Introducimos un parÃ¡metro de regularizaciÃ³n \(\lambda\) en la funciÃ³n de costo, que pondera la suma de los cuadrados de los parÃ¡metros \(\theta\).
</p>

<ul class="org-ul">
<li><i>Creo que este tipo de regularizaciÃ³n tiene un nombre</i>.</li>
<li><i>Usamos el cuadrado para que no se cancelen entre sÃ­ y porque es derivable supongo</i>.</li>
</ul>

<p>
Por ejemplo, para <i>MSE</i>:
</p>

<p>
\[ J(\theta,x,h(x),\lambda) =  \frac{1}{2m} \left( \sum_{i=1}^{m} \left[ h(\theta,x^{(i)}) - y^{(i)} \right]^2 + \lambda \sum_{j=1}^{n} \theta_j^2 \right)  \]
</p>

<ul class="org-ul">
<li>Se suele omitir la ordenada al origen, tÃ©rmino de sesgo o <b>intercepto</b> \(\theta_0\) porque no afecta mucho a los resultados.
<ul class="org-ul">
<li><i>Me parece que debe haber una razÃ³n mÃ¡s interesante, porque esta decisiÃ³n hace que tengamos que calcular las funciones de costo de forma separada para \(\theta_0\)</i>.
<ul class="org-ul">
<li>En verdad es incorrecto pretender que el intercepto sea pequeÃ±o. Ver abajo en <a href="#org1c34648">5.4.2.0.0.1</a>.</li>
</ul></li>
</ul></li>
</ul>


<p>
Lo que buscamos es tener parÃ¡metros pequeÃ±os, lo que hace que la funciÃ³n de hipÃ³tesis sea suave, simple.
</p>

<p>
MÃ¡s adelante vamos a ver formas de determinar el valor del parÃ¡metro de regularizaciÃ³n \(\lambda\) para que funcione. Si es muy grande, hay subajuste, y si es muy chico seguimos con sobreajuste.
</p>
</div>

<ol class="org-ol">
<li><a id="org1c34648"></a><span class="done DONE">DONE</span> Buscar por quÃ© no usamos \(\theta_0\)<br />
<div class="outline-text-7" id="text-5-4-2-0-0-1">
<p>
El intercepto es nuestro factor de prejuicio que es independente de los descriptores. Es nuestra respuesta por defecto cuando no tenemos informaciÃ³n, y no tiene por quÃ© ser un valor chico. Por tanto no lo introducimos en el algoritmo de regularizaciÃ³n.
</p>

<p>
Recordemos que el intercepto es una variable independiente, la ordenada al origen. Lo introducimos dentro del vector de parÃ¡metros solo por conveniencia, para simplificar los cÃ¡lculos.
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-orgbe740ec" class="outline-4">
<h4 id="orgbe740ec"><span class="section-number-4">5.4.3</span> Regularized linear regression</h4>
<div class="outline-text-4" id="text-5-4-3">
<p>
La funciÃ³n de costo usando error cuadrÃ¡tico medio y regresiÃ³n lineal nos queda
</p>

<p>
\[ J(\theta,x,h(x),\lambda) =  \frac{1}{2m} \left( \sum_{i=1}^{m} \left[ h(\theta,x^{(i)}) - y^{(i)} \right]^2 + \lambda \sum_{j=1}^{n} \theta_j^2 \right)  \]
</p>

<p>
NÃ³tese que \(j\) empieza en \(1\). La regla de actualizaciÃ³n derivada es:
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n] - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)} \quad \text{si} \quad j=0 \]
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n] - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)} + \frac{\lambda}{m} \theta_j \quad \text{si} \quad j>0 \]
</p>

<p>
Factorizando \(\theta_j\) de esta Ãºltima ecuaciÃ³n nos queda
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n](1 - \frac{\alpha\lambda}{m}) - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)}  \quad \text{si} \quad j>0 \]
</p>

<p>
El factor \((1 - \frac{\alpha\lambda}{m})\) nos indica que en todas las actualizaciones se comienza reduciendo el valor anterior de los parÃ¡metros.
</p>
</div>

<ol class="org-ol">
<li><a id="orgd126b3e"></a>Forma matricial/vectorizada<br />
<div class="outline-text-5" id="text-5-4-3-1">
<p>
La forma matricial/vectorizada queda
</p>

<p>
\[ J(\theta, X, \lambda) = \frac{1}{2m} \sum (X\theta - Y)^2 + \frac{\lambda}{2m} \theta(1:n)^T \theta(1:n) \]
</p>


<p>
La actualizaciÃ³n necesita 2 etapas: la primera es el cÃ¡lculo normal sin regularizaciÃ³n, y de aquÃ­ guardamos \(\theta_0\); en la segunda sumamos el termino de regularizaciÃ³n; y finalmente reemplazamos con el \(\theta_0\) encontrado anteriormente.
</p>

<p>
\[ \theta[i+1]^{(a)} := \theta[i] - \frac{\alpha}{m} X^T (h(X \theta) - Y) \]
\[ \theta_0[i+1]^{} := \theta[i+1]^{(a)}(0) \]
\[ \theta[i+1]^{} := \theta[i+1]^{(a)} + \frac{\lambda}{2m} \theta[i] \]
\[ \theta[i+1](0) := \theta_0[i+1]  \]
</p>


<hr />
</div>
</li>

<li><a id="org00b1b4d"></a>La ecuaciÃ³n normal con regularizaciÃ³n<br />
<div class="outline-text-5" id="text-5-4-3-2">
<p>
La ecuaciÃ³n normal era
</p>

<p>
\[  \theta = [ ( X^T \times X)^{-1} \times X^T ] \times Y  \]
</p>

<p>
Agregamos un tÃ©rmino de regularizaciÃ³n:
</p>

<p>
\[  \theta = [ ( X^T \times X \times \lambda L)^{-1} \times X^T ] \times Y  \]
</p>

<p>
Donde L es una matriz diagonal cuyo primer elemento de la diagonal principal es \(0\) e indica que no queremos que la regularizaciÃ³n afecte al parÃ¡metro &theta;<sub>0</sub> .
</p>

<p>
Este termino de regularizaciÃ³n <b>hace que esa matriz sea invertible aunque se trate de un sistema subdeterminado</b> (siempre que \(\lambda>0\)).
</p>
<ul class="org-ul">
<li>En las <a href="https://www.coursera.org/learn/machine-learning/discussions/weeks/3/threads/poUNvD1-EeakuhJbRt69hQ">preguntas frecuentes de la semana 3</a> dicen que <a href="http://web.mit.edu/zoya/www/linearRegression.pdf">acÃ¡ hay un "boceto de demonstraciÃ³n"</a>.</li>
</ul>
</div>
</li>
</ol>
</div>

<div id="outline-container-orga2d872a" class="outline-4">
<h4 id="orga2d872a"><span class="section-number-4">5.4.4</span> Regularized logistic regression</h4>
<div class="outline-text-4" id="text-5-4-4">
<p>
La funciÃ³n de costo de la regresiÃ³n logÃ­stica con regularizaciÃ³n queda:
</p>

<p>
\[  J(h_\theta(x), \lambda) = J(h(\theta,x)) = \frac{1}{m} \sum_{i=1}^m \left[-y^{(i)} \log(h_\theta(x^{(i)})) - (1-y^{(i)}) \log(1-h_\theta(x^{(i)}))  \right] + \frac{\lambda}{2m} \sum_{j=1}^n \theta_j^2 \]
</p>

<p>
La forma vectorizada/matricial:
</p>

<p>
\[ J(h(\theta,X), \lambda) = \frac{1}{m} \left[ -Y^T \log(h(X\theta)) - (1-Y)^T \log(1-h(X\theta)) \right] + \frac{\lambda}{2m} \theta(1:n)^T \theta(1:n) \]
</p>

<p>
La regla de actualizaciÃ³n es igual que para regresiÃ³n lineal con <i>MSE</i>, calculando por separado \(\theta_0\).
</p>
</div>
</div>
</div>





<div id="outline-container-org25a1562" class="outline-3">
<h3 id="org25a1562"><span class="section-number-3">5.5</span> Review</h3>
<div class="outline-text-3" id="text-5-5">
</div>
<div id="outline-container-orgd26e682" class="outline-4">
<h4 id="orgd26e682"><span class="section-number-4">5.5.1</span> Quiz: Regularization</h4>
<div class="outline-text-4" id="text-5-5-1">
<ul class="org-ul">
<li>Agregar nuevos descriptores nos da una hipÃ³tesis igual o mejor a la que tenemos antes de agregarlos, en los datos de entrenamiento/modelado.
<ul class="org-ul">
<li>Asumo que asume convergencia.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orga9205d9" class="outline-4">
<h4 id="orga9205d9"><span class="section-number-4">5.5.2</span> Programming assignment: logistic regression</h4>
<div class="outline-text-4" id="text-5-5-2">
<ul class="org-ul">
<li>CorregÃ­ algunas funciones vectorizadas de mis notas.</li>
<li>El logaritmo es logaritmo natural, no base 10. Por tanto deberÃ­a escribir \(ln\) en lugar de \(log\), aunque en Octave la funciÃ³n es <code>log</code>.</li>
<li><i>Cross entropy</i></li>
<li>Usamos <i>feature mapping</i> para crear nuevos descriptores a partir de los 2 que tenÃ­amos. Los nuevos son todas las combinaciones lineales posibles de descriptores, hasta cierto grado.</li>
</ul>

<div class="org-src-container">
<pre class="src src-octave"><span style="color: #4f97d7; font-weight: bold;">function</span> out <span style="color: #4f97d7;">=</span> <span style="color: #bc6ec5; font-weight: bold;">mapFeature</span><span style="color: #4f97d7;">(</span>X1<span style="color: #4f97d7;">,</span> X2<span style="color: #4f97d7;">)</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">MAPFEATURE Feature mapping function to polynomial features</span>
<span style="color: #2aa1ae; background-color: #292e34;">%</span>
<span style="color: #2aa1ae; background-color: #292e34;">%   </span><span style="color: #2aa1ae; background-color: #292e34;">MAPFEATURE(X1, X2) maps the two input features</span>
<span style="color: #2aa1ae; background-color: #292e34;">%   </span><span style="color: #2aa1ae; background-color: #292e34;">to quadratic features used in the regularization exercise.</span>
<span style="color: #2aa1ae; background-color: #292e34;">%</span>
<span style="color: #2aa1ae; background-color: #292e34;">%   </span><span style="color: #2aa1ae; background-color: #292e34;">Returns a new feature array with more features, comprising of </span>
<span style="color: #2aa1ae; background-color: #292e34;">%   </span><span style="color: #2aa1ae; background-color: #292e34;">X1, X2, X1.^2, X2.^2, X1*X2, X1*X2.^2, etc..</span>
<span style="color: #2aa1ae; background-color: #292e34;">%</span>
<span style="color: #2aa1ae; background-color: #292e34;">%   </span><span style="color: #2aa1ae; background-color: #292e34;">Inputs X1, X2 must be the same size</span>
<span style="color: #2aa1ae; background-color: #292e34;">%</span>

  degree <span style="color: #4f97d7;">=</span> <span style="color: #a45bad;">6</span><span style="color: #4f97d7;">;</span>
  out <span style="color: #4f97d7;">=</span> ones<span style="color: #4f97d7;">(</span>size<span style="color: #bc6ec5;">(</span>X1<span style="color: #2d9574;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">1</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
  <span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7;">=</span> <span style="color: #a45bad;">1</span><span style="color: #4f97d7;">:</span>degree
    <span style="color: #4f97d7; font-weight: bold;">for</span> j <span style="color: #4f97d7;">=</span> <span style="color: #a45bad;">0</span><span style="color: #4f97d7;">:</span>i
      out<span style="color: #4f97d7;">(</span><span style="color: #4f97d7;">:,</span> end<span style="color: #4f97d7;">+</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span>X1<span style="color: #4f97d7;">.^</span><span style="color: #bc6ec5;">(</span>i<span style="color: #4f97d7;">-</span>j<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">.*</span><span style="color: #4f97d7;">(</span>X2<span style="color: #4f97d7;">.^</span>j<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
    <span style="color: #4f97d7; font-weight: bold;">end</span>
  <span style="color: #4f97d7; font-weight: bold;">end</span>

<span style="color: #4f97d7; font-weight: bold;">end</span>

<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">---------</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Add Polynomial Features</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Note that mapFeature also adds a column of ones for us, so the intercept</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">term is handled</span>
X <span style="color: #4f97d7;">=</span> mapFeature<span style="color: #4f97d7;">(</span>X<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">,</span> X<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">2</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>

</pre>
</div>

<ul class="org-ul">
<li>\(\theta_0\): manejÃ© los distintos gradientes asÃ­:</li>
</ul>

<div class="org-src-container">
<pre class="src src-octave">grad <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> X<span style="color: #4f97d7;">'*</span><span style="color: #4f97d7;">(</span>sigmoid<span style="color: #bc6ec5;">(</span>X<span style="color: #4f97d7;">*</span>theta<span style="color: #bc6ec5;">)</span> <span style="color: #4f97d7;">-</span> y<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
grad0 <span style="color: #4f97d7;">=</span> grad<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
grad <span style="color: #4f97d7;">=</span> grad <span style="color: #4f97d7;">+</span> <span style="color: #4f97d7;">(</span>lambda<span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">.*</span>theta<span style="color: #4f97d7;">;</span>
grad<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">=</span> grad0<span style="color: #4f97d7;">;</span>
</pre>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-orge749bd3" class="outline-2">
<h2 id="orge749bd3"><span class="section-number-2">6</span> Semana 4</h2>
<div class="outline-text-2" id="text-6">
<p>
Empezamos a ver redes neuronales.
</p>
</div>

<div id="outline-container-orgcbd0f4a" class="outline-3">
<h3 id="orgcbd0f4a"><span class="section-number-3">6.1</span> Motivations</h3>
<div class="outline-text-3" id="text-6-1">
</div>
<div id="outline-container-orgab3f764" class="outline-4">
<h4 id="orgab3f764"><span class="section-number-4">6.1.1</span> Non-linear hypotheses</h4>
<div class="outline-text-4" id="text-6-1-1">
<p>
Las redes neuronales son de los clasificadores mÃ¡s avanzados y usados hoy en dÃ­a.
</p>

<p>
Para problemas poco lineales, la regresiÃ³n logÃ­stica empieza a necesitar muchos descriptores. Demasiados. Sea por ejemplo un problema con dos descriptores \(x_1\) y \(x_2\). Si queremos mÃ¡s expresividad de clasificaciÃ³n y aÃ±adimos como descriptores sintÃ©ticos todos los productos de segundo orden, tenemos \(x_1^2 , x_2^2, x_1 x_2\), y tendrÃ­amos un total de 5 descriptores. Este total crece como \(O(\frac{n^2}{2})\). Los de tercer orden crecen como \(O(n^3)\).
</p>

<p>
Hay muchos problemas que de entrada ya estÃ¡n definidos por muchos descriptores. Un ejemplo: las imÃ¡genes digitales. Por ejemplo, una imagen de 100&times;100px requerirÃ­a aproximadamente 50 millones de descriptores de segundo grado.
</p>
</div>
</div>


<div id="outline-container-org5d86b8d" class="outline-4">
<h4 id="org5d86b8d"><span class="section-number-4">6.1.2</span> Neurons and the brain</h4>
<div class="outline-text-4" id="text-6-1-2">
<ul class="org-ul">
<li><i>The "one learning algorithm" hypotesis</i>: el cerebro tiene el mismo algoritmo de aprendizaje siempre, y se adapta a cualquier entrada.</li>
</ul>
</div>

<ol class="org-ol">
<li><a id="org929591b"></a><span class="todo TODO">TODO</span> <a href="https://www.lesswrong.com/posts/9Yc7Pp7szcjPgPsjf/the-brain-as-a-universal-learning-machine">https://www.lesswrong.com/posts/9Yc7Pp7szcjPgPsjf/the-brain-as-a-universal-learning-machine</a><br /></li>

<li><a id="org48d8f6c"></a><span class="todo TODO">TODO</span> <a href="https://www.youtube.com/watch?v=AY4ajbu_G3k">https://www.youtube.com/watch?v=AY4ajbu_G3k</a><br /></li>

<li><a id="org93a2d9d"></a><span class="todo TODO">TODO</span> <a href="https://www.youtube.com/watch?v=NKpuX_yzdYs">https://www.youtube.com/watch?v=NKpuX_yzdYs</a><br /></li>

<li><a id="org7e4687c"></a><span class="todo TODO">TODO</span> <a href="https://www.youtube.com/watch?v=zIwLWfaAg-8">https://www.youtube.com/watch?v=zIwLWfaAg-8</a><br /></li>

<li><a id="org3f165ba"></a><span class="todo TODO">TODO</span> <a href="https://www.wired.com/2013/05/neuro-artificial-intelligence/">https://www.wired.com/2013/05/neuro-artificial-intelligence/</a><br /></li>
</ol>
</div>
</div>

<div id="outline-container-orgd595f01" class="outline-3">
<h3 id="orgd595f01"><span class="section-number-3">6.2</span> Neural networks</h3>
<div class="outline-text-3" id="text-6-2">
</div>
<div id="outline-container-org0fed566" class="outline-4">
<h4 id="org0fed566"><span class="section-number-4">6.2.1</span> Model representation I</h4>
<div class="outline-text-4" id="text-6-2-1">
<p>
EstÃ¡ largo de escribir asÃ­ que copio la imagen:
</p>


<div class="figure">
<p><img src="./imgs/004-neural-network-model.png" alt="004-neural-network-model.png" />
</p>
</div>

<p>
Algo de nomenclatura y convenciones:
</p>

<ul class="org-ul">
<li>Es equivalente hablar de una <b>unidad</b>, una <b>neurona</b>, la salida de una neurona o la <b>activaciÃ³n</b> de una neurona. Siempre hablamos del resultado de la funciÃ³n de activaciÃ³n ante ciertas entradas y parÃ¡metros o pesos: \(g(\theta,x)\). La neurona en sÃ­ no tiene significado en el modelo, aunque lo tiene en el diagrama.
<ul class="org-ul">
<li>La unidad 1 de la capa 2 es \(a_1^{(2)}\).</li>
<li>Se suele omitir la unidad de sesgo de cada capa, \(a_0^{(j)}\), porque vale siempre 1. Esta es la que se multiplica por \(\theta_0\). <i>DISCREPO</i>.</li>
</ul></li>
<li>\(h_{\Theta}^{}(\vec{x}^{})\) es la salida final de la red neuronal, en funciÃ³n de las entradas.</li>
<li>La funciÃ³n de activaciÃ³n tÃ­pica es la funciÃ³n logÃ­stica/sigmoidea.</li>
<li>A los parÃ¡metros de la funciÃ³n tambiÃ©n les decimos <b>pesos</b>.
<ul class="org-ul">
<li>&Theta;<sup>(j)</sup> es la matriz de pesos que relaciona la capa \(j\) con la siguiente \(j+1\). Si una capa \(j\) tiene \(s_j\) unidades y la siguiente es \(j+1\) con \(s_{j+1}\) unidades, la dimensiÃ³n de \(\Theta^{(j)}\) serÃ¡ \((s_{j+1})\times(s_j+1)\) (entradas &times; (salidas + entradas independientes)); el \(+1\) es por la unidad de sesgo.</li>
</ul></li>
<li>En los diagramas se funden axones y dendritas de capas conectadas, adyacentes. Entonces los Ãºnicos axones son los de la capa de salida.</li>
<li>A las capas que no son de salida o entrada se les suele llamar <b>capas ocultas</b>.</li>
</ul>
</div>
</div>

<div id="outline-container-orgac1da62" class="outline-4">
<h4 id="orgac1da62"><span class="section-number-4">6.2.2</span> Model representation II</h4>
<div class="outline-text-4" id="text-6-2-2">
<p>
Este modelo bÃ¡sico de red neuronal es un conjunto de funciones logÃ­sticas encadenadas. La forma de conectar las neuronas (arquitectura) le va a permitir aprender funciones no lineales complejas.
</p>

<p>
En forma vectorizada y asumiendo la misma funciÃ³n de activaciÃ³n \(g^{(j)}\) para todas las neuronas:
</p>

<p>
\[ h_{\Theta}^{}(\vec{x}^{}) = h(g, \vec{x}, \Theta) \]
\[ \vec{a}^{(j) }= g_{}^{}(\vec{z}^{(j)}) = g(\Theta^{(j-1)} \vec{a}^{(j-1)})  \]
</p>
</div>
</div>
</div>

<div id="outline-container-org8c0109e" class="outline-3">
<h3 id="org8c0109e"><span class="section-number-3">6.3</span> Applications</h3>
<div class="outline-text-3" id="text-6-3">
</div>
<div id="outline-container-org0050235" class="outline-4">
<h4 id="org0050235"><span class="section-number-4">6.3.1</span> Examples and intuitions I</h4>
<div class="outline-text-4" id="text-6-3-1">
<p>
Con una neurona de 3 entradas puedo calcular las funciones AND y OR.
</p>
</div>
</div>

<div id="outline-container-org986da8f" class="outline-4">
<h4 id="org986da8f"><span class="section-number-4">6.3.2</span> Examples and intuitions II</h4>
<div class="outline-text-4" id="text-6-3-2">
<p>
Ejemplo de XNOR.
</p>
</div>
</div>

<div id="outline-container-org3c9ffd6" class="outline-4">
<h4 id="org3c9ffd6"><span class="section-number-4">6.3.3</span> Multiclass classification</h4>
<div class="outline-text-4" id="text-6-3-3">
<p>
Para clasificaciÃ³n multiclase solo tenemos que tener tantas salidas como clases. Luego, codificamos la salida como un vector "<i>one hot</i>", donde todos los elementos son \(0\) menos el de la salida correcta, que es \(1\).
</p>

<p>
Las salidas de la red \(\vec{\hat{y}} = h_\Theta(\vec{x})\) no son una distribuciÃ³n de probabilidad, no necesariamente suman 1. Son la salida de distintas sigmoideas, y cada una representa la confianza que tiene ese clasificador.
</p>
</div>
</div>
</div>

<div id="outline-container-orgd8c0e55" class="outline-3">
<h3 id="orgd8c0e55"><span class="section-number-3">6.4</span> Review</h3>
<div class="outline-text-3" id="text-6-4">
</div>
<div id="outline-container-org859fb74" class="outline-4">
<h4 id="org859fb74"><span class="section-number-4">6.4.1</span> Quiz: Neural networks: representation</h4>
</div>

<div id="outline-container-orga585301" class="outline-4">
<h4 id="orga585301"><span class="section-number-4">6.4.2</span> Programming assignment: multi-class classificatin and neural networks</h4>
</div>
</div>
</div>

<div id="outline-container-org496b1f6" class="outline-2">
<h2 id="org496b1f6"><span class="section-number-2">7</span> Semana 5</h2>
<div class="outline-text-2" id="text-7">
<p>
Vamos a ver el algoritmo de retropropagaciÃ³n o propagaciÃ³n hacia atrÃ¡s (<i>backpropagation</i>) para el aprendizaje de redes neuronales.
</p>
</div>

<div id="outline-container-org61722f1" class="outline-3">
<h3 id="org61722f1"><span class="section-number-3">7.1</span> Cost function and backpropagation</h3>
<div class="outline-text-3" id="text-7-1">
</div>
<div id="outline-container-org0c6d257" class="outline-4">
<h4 id="org0c6d257"><span class="section-number-4">7.1.1</span> Cost function</h4>
<div class="outline-text-4" id="text-7-1-1">
<p>
Para optimizar un conjunto de parÃ¡metros \(\Theta\) necesitamos primero definir una funciÃ³n de costo a minimizar.
</p>

<p>
Algunas definiciones:
</p>

<ul class="org-ul">
<li>\(K\) es la cantidad de salidas de la red.
<ul class="org-ul">
<li>Usamos \(k\) para indizarlas.</li>
</ul></li>
<li>\(L\) es la cantidad de capas de nuestra red.
<ul class="org-ul">
<li>Usamos \(l\) para indizarlas.</li>
</ul></li>
<li>\(s_l\) es la cantidad de neuronas/unidades de la capa \(l\), <b>sin contar la unidad de sesgo \(a_0^{(l)}\)</b>.</li>
</ul>

<p>
La funciÃ³n de costo es una extensiÃ³n de la regularizada que usÃ¡bamos para regresiÃ³n logÃ­stica.
</p>

<ul class="org-ul">
<li>Sumamos los errores de todas las salidas.</li>
<li>Regularizamos todos los parÃ¡metros \(\theta\) de las matrices \(\Theta\), excepto aquellos que relacionan unidades de sesgo. Estos son corresponden a <del>la primera fila y</del> la primera columna de cada \(\Theta\).</li>
</ul>

<p>
\[  J(\Theta, \lambda) = \frac{1}{m} \sum_{k=1}^K \sum_{i=1}^m \left[-y_k^{(i)} \log(h_\Theta(x^{(i)})_k) - (1-y_k^{(i)}) \log(1-h_\Theta(x^{(i)})_k)  \right] + \frac{\lambda}{2m} \sum_{l=1}^L \sum_{v=0}^{s_{l+1}} \sum_{j=1}^{s_l} (\Theta_{v,j}^{(l)})^2 \]
</p>

<ul class="org-ul">
<li><i>Yo voy a usar \(v\) donde Ã©l usa OTRA \(i\)</i>.</li>
</ul>
</div>
</div>


<div id="outline-container-orgcb137ed" class="outline-4">
<h4 id="orgcb137ed"><span class="section-number-4">7.1.2</span> Backpropagation algorithm</h4>
<div class="outline-text-4" id="text-7-1-2">
<p>
Esto estÃ¡ complicado asÃ­ que nos lo dan sin demostraciones.
</p>

<p>
El algoritmo de retropropagaciÃ³n o propagaciÃ³n hacia atrÃ¡s sirve para calcular el gradiente de la funciÃ³n de costo en funciÃ³n de los parÃ¡metros. Luego usamos este gradiente <b>en algÃºn algoritmo de optimizaciÃ³n</b> como el descenso por el gradiente, para encontrar los parÃ¡metros que minimizan la funciÃ³n de costo.
</p>

<p>
\[  \frac{\partial J(\Theta)}{\partial \Theta_{v,j}^{(l)} } = D_{v,j}^{(l)}  \]
</p>

<p>
\[ D_{v,j}^{(l)} = \frac{1}{m} \Delta_{v,j}^{(l)} + \lambda \Theta_{v,j}^{(l)} \quad \text{si} \quad j=0  \]
</p>

<p>
\[ D_{v,j}^{(l)} = \frac{1}{m} \Delta_{v,j}^{(l)} \quad \text{si} \quad j\ne0  \]
</p>

<p>
\(\Delta_{v,j}^{(l)}\) son matrices en las que vamos acumulando los errores de cada unidad de cada capa, para cada ejemplo de entrada. El proceso es:
</p>

<ol class="org-ol">
<li>Para cada ejemplo \(x{(i)}\):
<ol class="org-ol">
<li>Calculamos las salidas de la red, propagando hacia adelante.</li>
<li>Calculamos los errores, propagando hacia atrÃ¡s.</li>
</ol></li>
</ol>

<p>
\[  \Delta_{v,j}^{(l)} [n+1] := \Delta_{v,j}^{(l)} [n] + \vec{a}_j^{(l)} \vec{\delta}_{v}^{(l+1)} \]
</p>

<p>
De forma vectorizada/matricial:
</p>

<p>
\[ \Delta^{(l)}[n+1] := \Delta^{(l)}[n] + \delta^{(l+1)} (a^{(l)})^T   \]
</p>


<p>
\(\vec{\delta}^{(l)}\) es un vector de los errores para cada capa. Si no entiendo mal, es la derivada de \(g\) en el punto determinado por sus entradas, multiplicado por el avance del error retropropagado.
</p>

<p>
\[  \vec{\delta}^{(l=L)} :=  \vec{a}^{(l)} - \vec{y}^{}  \]
</p>

<p>
\[  \vec{\delta}^{( 1 \lt l \lt L )} := (\Theta^{(l)})^T \vec{\delta}^{(l+1)} * \vec{g'}(z^{(l)})  \]
</p>

<p>
\[ \vec{g'} (z^{(l)}) = \vec{a}^{(l)} .* (\vec{1} - \vec{a}^{(l)} )  \]
</p>
</div>
</div>





<div id="outline-container-org7e9bf57" class="outline-4">
<h4 id="org7e9bf57"><span class="section-number-4">7.1.3</span> Backpropagation intuition</h4>
<div class="outline-text-4" id="text-7-1-3">
<p>
Los tÃ©rminos \(\delta\) son los "errores" de predicciÃ³n de cada unidad. MÃ¡s tÃ©cnicamente:
</p>

<p>
\[  \delta_j^{(l)} = \frac{\partial costo(h_\Theta, x^{(i)})}{\partial z_j^{(l)}}   \]
</p>

<p>
AsÃ­ como cada \(z^{(l)}\) es una suma pesada de las entradas a esa unidad, cada \(\delta^{(l)}\) es una suma pesada de las entradas a esa unidad, recorriendo el grafo al revÃ©s, desde las salidas a hacia las entradas.
</p>
</div>
</div>
</div>

<div id="outline-container-org049ca9d" class="outline-3">
<h3 id="org049ca9d"><span class="section-number-3">7.2</span> Backpropagation in practice</h3>
<div class="outline-text-3" id="text-7-2">
</div>
<div id="outline-container-org9263c15" class="outline-4">
<h4 id="org9263c15"><span class="section-number-4">7.2.1</span> Implementation note: unrolling parameters</h4>
<div class="outline-text-4" id="text-7-2-1">
<p>
Muchos algoritmos de optimizaciÃ³n esperan vectores. Para trabajar con nuestras matrices \(\Theta\) de parÃ¡metros y \(D\) de gradientes, lo que hacemos es juntar todos los elementos y expresarlos como vector. Luego las reconstruimos en donde sea necesario.
</p>

<p>
En Octave:
</p>

<div class="org-src-container">
<pre class="src src-octave">Theta1 <span style="color: #4f97d7;">=</span> rand<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">4</span><span style="color: #4f97d7;">,</span><span style="color: #a45bad;">3</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% 4x3</span>
Theta2 <span style="color: #4f97d7;">=</span> rand<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">,</span><span style="color: #a45bad;">4</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% 2x4</span>
ThetaVec <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">[</span>Theta1<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">;</span> Theta2<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">]</span><span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% 20x1</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">[J, DVec]  = costFunction(ThetaVec, X, Y)  % Adentro reconstruimos ThetaVec</span>
ThetaVecOptimized <span style="color: #4f97d7;">=</span> fminunc<span style="color: #4f97d7;">(</span><span style="color: #4f97d7;">...</span><span style="color: #4f97d7;">)</span>
Theta1 <span style="color: #4f97d7;">=</span> reshape<span style="color: #4f97d7;">(</span>ThetaVecOptimized<span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">:</span><span style="color: #a45bad;">11</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">,</span> <span style="color: #a45bad;">4</span><span style="color: #4f97d7;">,</span><span style="color: #a45bad;">3</span><span style="color: #4f97d7;">)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org2579f0d" class="outline-4">
<h4 id="org2579f0d"><span class="section-number-4">7.2.2</span> Gradient checking</h4>
<div class="outline-text-4" id="text-7-2-2">
<p>
Para verificar que nuestro algoritmo de retropropagaciÃ³n estÃ© funcionando bien, podemos comparar los gradientes \(D\) calculados con unos calculados manualmente usando una aproximaciÃ³n de la derivada en el punto. Andrew sugiere usar una aproximaciÃ³n de doble lado:
</p>

<p>
\[  \frac{\partial J(\Theta)}{\partial \Theta}   \approx  \frac{J(\Theta + \epsilon) - J(\Theta - \epsilon)}{2 \epsilon}\]
</p>

<p>
Calculamos esto para cada uno de los parÃ¡metros \(\theta\) del vector desenrollado a partir de las matrices \(\Theta\). Calculamos para cada parÃ¡metro, manteniendo el resto fijos; es la derivada parcial.
</p>

<p>
<b>Â¡NÃ³tese que podrÃ­amos optimizar con esto!</b> El problema es que es computacionalmente mucho mÃ¡s costoso que el algoritmo de retropropagaciÃ³n. Implica recalcular la funciÃ³n de costo 2 veces para cada parÃ¡metro de las matrices. Por lo tanto, solo lo deberÃ­amos usar para depurar nuestro cÃ³digo, pero luego desactivarlo.
</p>
</div>
</div>

<div id="outline-container-org2e91635" class="outline-4">
<h4 id="org2e91635"><span class="section-number-4">7.2.3</span> Random initialization</h4>
<div class="outline-text-4" id="text-7-2-3">
<p>
Si inicializamos los parÃ¡metros \(\theta\) de las matrices \(\Theta\) todos con el mismo valor, en cada iteraciÃ³n de propagaciÃ³n hacia adelante terminamos con las mismas activaciones en cada unidad de una misma capa; y en cada iteraciÃ³n de propagaciÃ³n hacia atrÃ¡s terminamos con los mismos errores \(\delta\). Esto implica que todas las unidades de una capa terminan calculando los mismos descriptores. Esto se llama el <b>problema de los caminos simÃ©tricos</b>. <i>Supongo que se da porque todas las unidades estÃ¡n conectadas de la misma manera, quizÃ¡s no serÃ­a necesario si las unidades se conectaran de forma distinta</i>.
</p>

<p>
La forma de solucionar el problema es romper la simetrÃ­a (<i>simmetry breaking</i>). Para esto debemos inicializar los parÃ¡metros con valores distintos. Andrew propone inicializarlos con valores aleatorios (distribuciÃ³n uniforme) en un intervalo \([-\epsilon, \epsilon]\) para un valor \(\epsilon\) pequeÃ±o cualquiera (propone un \(\epsilon<1\)).
</p>
</div>
</div>

<div id="outline-container-org7ece90e" class="outline-4">
<h4 id="org7ece90e"><span class="section-number-4">7.2.4</span> Putting it together</h4>
<div class="outline-text-4" id="text-7-2-4">
<ul class="org-ul">
<li>La arquitectura es el patrÃ³n de conexiÃ³n entre las neuronas.
<ul class="org-ul">
<li>Lo mÃ¡s bÃ¡sico es tener una capa oculta (pero no dice de cuÃ¡ntas unidades).</li>
<li>Una buena heurÃ­stica es tener tantas capas ocultas como unidades de entrada.</li>
</ul></li>
<li>Recordamos que el algoritmo de retropropagaciÃ³n es un algoritmo para calcular el gradiente de la funciÃ³n de costo respecto a la variaciÃ³n de los parÃ¡metros; la optimizaciÃ³n se hace con un algoritmo genÃ©rico de optimizaciÃ³n, como el descenso por el gradiente.</li>
<li>\(J(\Theta)\) no es un espacio convexo en las redes neuronales. Esto implica que quizÃ¡s no alcanzamos el mÃ­nimo global, pero dice Andrew que esto no suele ser un problema en la realidad.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org136d323" class="outline-3">
<h3 id="org136d323"><span class="section-number-3">7.3</span> Applications of neural networks</h3>
<div class="outline-text-3" id="text-7-3">
</div>
<div id="outline-container-orgb311726" class="outline-4">
<h4 id="orgb311726"><span class="section-number-4">7.3.1</span> Autonomous driving</h4>
<div class="outline-text-4" id="text-7-3-1">
<p>
Jeep automanejado en 1992.
</p>
</div>
</div>
</div>

<div id="outline-container-org8610a77" class="outline-3">
<h3 id="org8610a77"><span class="section-number-3">7.4</span> Review</h3>
<div class="outline-text-3" id="text-7-4">
</div>
<div id="outline-container-orgd8fcdd9" class="outline-4">
<h4 id="orgd8fcdd9"><span class="section-number-4">7.4.1</span> Quiz: Neural networks: learning</h4>
</div>

<div id="outline-container-org4200daf" class="outline-4">
<h4 id="org4200daf"><span class="section-number-4">7.4.2</span> Programming assignment: neural network learning</h4>
<div class="outline-text-4" id="text-7-4-2">
<ul class="org-ul">
<li>UsÃ© una forma vectorizada de la funciÃ³n de costo, segÃºn algunas pistas que encontrÃ© en las notas del curso. En ellas usÃ© la <i>traza</i> de una matriz, para trabajar con muchas salidas.</li>
</ul>

<div class="org-src-container">
<pre class="src src-octave"><span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">C&#225;lculo de la funci&#243;n de costo</span>
y_onehot <span style="color: #4f97d7;">=</span> zeros<span style="color: #4f97d7;">(</span>num_labels<span style="color: #4f97d7;">,</span> m<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% s3xm</span>
<span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7;">=</span> <span style="color: #a45bad;">1</span><span style="color: #4f97d7;">:</span>m  <span style="color: #2aa1ae; background-color: #292e34;">% cada columna</span>
  y_onehot<span style="color: #4f97d7;">(</span>y<span style="color: #bc6ec5;">(</span>i<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">,</span>i<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">=</span> <span style="color: #a45bad;">1</span><span style="color: #4f97d7;">;</span>
<span style="color: #4f97d7; font-weight: bold;">endfor</span>

<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">C&#225;lculo totalmente vectorizado:</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Uso la traza (suma de la diagonal principal), pero tambi&#233;n podr&#237;a ser la suma de</span>
<span style="color: #2aa1ae; background-color: #292e34;">%  </span><span style="color: #2aa1ae; background-color: #292e34;">todos los elementos del producto elemento a elemento.</span>
J <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> <span style="color: #4f97d7;">(</span>trace<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">-</span>y_onehot <span style="color: #4f97d7;">*</span> log<span style="color: #2d9574;">(</span>a3<span style="color: #4f97d7;">'</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span> <span style="color: #4f97d7;">-</span> trace<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">(</span><span style="color: #a45bad;">1</span>.<span style="color: #4f97d7;">-</span>y_onehot<span style="color: #2d9574;">)</span> <span style="color: #4f97d7;">*</span> log<span style="color: #2d9574;">(</span><span style="color: #a45bad;">1</span>.<span style="color: #4f97d7;">-</span>a3<span style="color: #4f97d7;">'</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span> <span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>

<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Agrego regularizaci&#243;n</span>
J <span style="color: #4f97d7;">=</span> J <span style="color: #4f97d7;">+</span> <span style="color: #4f97d7;">(</span>lambda<span style="color: #4f97d7;">/</span><span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">*</span>m<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> <span style="color: #4f97d7;">(</span>sum<span style="color: #bc6ec5;">(</span>sum<span style="color: #2d9574;">(</span>Theta1<span style="color: #67b11d;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">:</span>end<span style="color: #67b11d;">)</span><span style="color: #4f97d7;">.^</span><span style="color: #a45bad;">2</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span> <span style="color: #4f97d7;">+</span>  sum<span style="color: #bc6ec5;">(</span>sum<span style="color: #2d9574;">(</span>Theta2<span style="color: #67b11d;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">:</span>end<span style="color: #67b11d;">)</span><span style="color: #4f97d7;">.^</span><span style="color: #a45bad;">2</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
</pre>
</div>

<p>
Sin regularizaciÃ³n:
</p>

<p>
\[ J = \frac{1}{m} \times \left( tr( Y \times -log(\hat{Y}) ) - tr(  (1-Y) \times -log(1-\hat{Y})  ) \right)  \]
</p>

<p>
\[ J = \frac{1}{m} \times \left(  \sum \left[ Y \odot -log(\hat{Y})  \right] - \sum \left[ (1-Y) \odot -log(1 - \hat{Y})  \right] \right)   \]
</p>

<ul class="org-ul">
<li>One hot.</li>
<li>ImplementÃ© una forma vectorizada de la retropropagaciÃ³n, basada en lo que encontrÃ© <a href="https://medium.com/secure-and-private-ai-math-blogging-competition/https-medium-com-fadymorris-understanding-vectorized-implementation-of-neural-networks-dae4115ca185">acÃ¡</a>.</li>
</ul>

<div class="org-src-container">
<pre class="src src-octave"><span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Retropropagaci&#243;n</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">https://medium.com/secure-and-private-ai-math-blogging-competition/https-medium-com-fadymorris-understanding-vectorized-implementation-of-neural-networks-dae4115ca185</span>
delta3 <span style="color: #4f97d7;">=</span> a3 <span style="color: #4f97d7;">-</span> y_onehot<span style="color: #4f97d7;">;</span>
delta2 <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span>Theta2<span style="color: #4f97d7;">'</span> <span style="color: #4f97d7;">*</span> delta3<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">.*</span> sigmoidGradient<span style="color: #4f97d7;">(</span><span style="color: #bc6ec5;">[</span>ones<span style="color: #2d9574;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">,</span>size<span style="color: #67b11d;">(</span>z2<span style="color: #4f97d7;">,</span><span style="color: #a45bad;">2</span><span style="color: #67b11d;">)</span><span style="color: #2d9574;">)</span><span style="color: #4f97d7;">;</span>z2<span style="color: #bc6ec5;">]</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
Delta2 <span style="color: #4f97d7;">=</span> delta3 <span style="color: #4f97d7;">*</span> a2<span style="color: #4f97d7;">';</span>
Delta1 <span style="color: #4f97d7;">=</span> delta2<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">:</span>end<span style="color: #4f97d7;">,</span> <span style="color: #4f97d7;">:</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> a1<span style="color: #4f97d7;">';</span>
D2 <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> Delta2 <span style="color: #4f97d7;">+</span> <span style="color: #4f97d7;">(</span>lambda<span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> <span style="color: #4f97d7;">[</span>zeros<span style="color: #bc6ec5;">(</span>size<span style="color: #2d9574;">(</span>Theta2<span style="color: #4f97d7;">,</span><span style="color: #a45bad;">1</span><span style="color: #2d9574;">)</span><span style="color: #4f97d7;">,</span><span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span> <span style="color: #4f97d7;">,</span> Theta2<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">:</span>end<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">]</span><span style="color: #4f97d7;">;</span>
D1 <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> Delta1 <span style="color: #4f97d7;">+</span> <span style="color: #4f97d7;">(</span>lambda<span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> <span style="color: #4f97d7;">[</span>zeros<span style="color: #bc6ec5;">(</span>size<span style="color: #2d9574;">(</span>Theta1<span style="color: #4f97d7;">,</span><span style="color: #a45bad;">1</span><span style="color: #2d9574;">)</span><span style="color: #4f97d7;">,</span><span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">,</span> Theta1<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">:</span>end<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">]</span><span style="color: #4f97d7;">;</span>
</pre>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-orgbf2cf34" class="outline-2">
<h2 id="orgbf2cf34"><span class="section-number-2">8</span> Semana 6</h2>
<div class="outline-text-2" id="text-8">
<p>
En esta semana vamos a ver cÃ³mo evaluar nuestros modelos.
</p>

<ul class="org-ul">
<li>Advice for applying machine learning</li>
<li>Machine learning system design</li>
</ul>

<blockquote>
<p>
To optimize a machine learning algorithm, youâll need to first understand where the biggest improvements can be made. [&#x2026;]
</p>

<p>
When you're applying machine learning to real problems, a solid grasp of this week's content will easily save you a large amount of work.
</p>
</blockquote>
</div>

<div id="outline-container-orgb10c038" class="outline-3">
<h3 id="orgb10c038"><span class="section-number-3">8.1</span> Evaluating a learning algorithm</h3>
<div class="outline-text-3" id="text-8-1">
</div>
<div id="outline-container-orgc223c92" class="outline-4">
<h4 id="orgc223c92"><span class="section-number-4">8.1.1</span> Deciding what to try next</h4>
<div class="outline-text-4" id="text-8-1-1">
<p>
Algunas cosas que podemos cambiar para intentar mejorar nuestros algoritmos si no estamos satisfechos con los resultados:
</p>
<ul class="org-ul">
<li>Obtener mÃ¡s ejemplos</li>
<li>Generar mÃ¡s descriptores / proponer un modelo mÃ¡s complejo.
<ul class="org-ul">
<li>SintÃ©ticos (modelos mÃ¡s complejos, descriptores polinomiales)</li>
<li>Reales</li>
</ul></li>
<li>Usar menos descriptores / proponer un modelo mÃ¡s simple.</li>
<li>Variar el factor de regularizaciÃ³n \(\lambda\).</li>
<li>Aumentar las iteraciones buscando la convergencia.</li>
</ul>

<p>
Algunas de esas decisiones pueden ser muy costosas o largas. Vamos a ver herramientas de diagnÃ³stico que nos pueden dar pista sobre quÃ© es mejor probar.
</p>
</div>
</div>

<div id="outline-container-org22e10ad" class="outline-4">
<h4 id="org22e10ad"><span class="section-number-4">8.1.2</span> Evaluating a hypothesis</h4>
<div class="outline-text-4" id="text-8-1-2">
<p>
Dividimos el conjunto de datos en 2 subconjuntos de muestras aleatorias:
</p>

<ol class="org-ol">
<li>Conjunto de entrenamiento. Sobre estos datos optimizamos nuestros parÃ¡metros.</li>
<li>Conjunto de evaluaciÃ³n/prueba. Sobre estos datos evaluamos el desempeÃ±o de nuestro modelo.</li>
</ol>

<p>
Para evaluar el desempeÃ±o Andrew propone:
</p>

<ul class="org-ul">
<li>En regresiÃ³n:
<ul class="org-ul">
<li>MSE</li>
</ul></li>
<li>En clasificaciÃ³n:
<ul class="org-ul">
<li>La misma funciÃ³n de costo que usamos para optimizar.</li>
<li>Error medio de predicciÃ³n / error de clasificaciÃ³n 0/1. Es el error usando las salidas <i>one-hot</i>.</li>
</ul></li>
</ul>

<p>
Tanto en la funciÃ³n de costo \(J_{validation}\) como en la \(J_{test}\) <span class="underline">no incluÃ­mos los tÃ©rminos de regularizaciÃ³n</span>.
</p>
</div>
</div>


<div id="outline-container-orga5432e0" class="outline-4">
<h4 id="orga5432e0"><span class="section-number-4">8.1.3</span> Model selection and train/validation/test sets</h4>
<div class="outline-text-4" id="text-8-1-3">
<p>
Andrew propone usar usar un tercer subconjunto, intermedio, sobre el cuÃ¡l podemos evaluar <b>hiperparÃ¡metros</b> o parÃ¡metros de mÃ¡s alto nivel. Entonces:
</p>

<ol class="org-ol">
<li>Conjunto de entrenamiento
<ul class="org-ul">
<li>60%</li>
<li>AquÃ­ ajustamos los parÃ¡metros bÃ¡sicos de nuestro modelo, \(\theta\).</li>
</ul></li>
<li>Conjunto de validaciÃ³n (cruzada)
<ul class="org-ul">
<li>20%</li>
<li>AcÃ¡ ajustamos parÃ¡metros que definen la estructura de nuestro modelo. Por ejemplo, el grado del polinomio de ajuste. O sea que ajustamos los \(\theta\) de modelos con distintos grados \(d\) y elegimos un \(d\) segÃºn su desempeÃ±o en este conjunto.</li>
</ul></li>
<li>Conjunto de evaluaciÃ³n
<ul class="org-ul">
<li>20%</li>
<li>AcÃ¡ estimamos el desempeÃ±o real de nuestro modelo.</li>
</ul></li>
</ol>
</div>

<ol class="org-ol">
<li><a id="org086589a"></a>DiscusiÃ³n<br />
<div class="outline-text-5" id="text-8-1-3-1">
<p>
No me queda claro por quÃ© no podrÃ­amos ajustar parÃ¡metros e hiperparÃ¡metros en simultÃ¡neo. Â¿Y con quÃ© criterio distinguimos los unos de los otros?
</p>

<ul class="org-ul">
<li>Otro hiperparÃ¡metro podrÃ­a ser un umbral de clasificaciÃ³n.</li>
</ul>
</div>
</li>
</ol>
</div>
</div>


<div id="outline-container-org32fd80a" class="outline-3">
<h3 id="org32fd80a"><span class="section-number-3">8.2</span> Bias vs variance</h3>
<div class="outline-text-3" id="text-8-2">
</div>
<div id="outline-container-orgc5a5813" class="outline-4">
<h4 id="orgc5a5813"><span class="section-number-4">8.2.1</span> Diagnosing bias vs variance</h4>
<div class="outline-text-4" id="text-8-2-1">
<p>
Cuando tenemos mucho error en el conjunto de validaciÃ³n, hay una forma de saber si es error de sesgo alto o error de varianza alta:
</p>
<ul class="org-ul">
<li>Si \(J_{train} \approx J_{val}\) y ambos son altos, entonces el modelo tiene sesgo alto y estÃ¡ subajustando.</li>
<li>Si \(J_{val} \gg J_{train}\) (suponiendo que estamos minimizando el error), entonces el modelo tiene varianza alta y estÃ¡ sobreajustando.</li>
</ul>


<div class="figure">
<p><img src="./imgs/005-high-bias-vs-high-variance.png" alt="005-high-bias-vs-high-variance.png" />
</p>
</div>
</div>
</div>


<div id="outline-container-org2d8df98" class="outline-4">
<h4 id="org2d8df98"><span class="section-number-4">8.2.2</span> Regularization and bias/variance</h4>
<div class="outline-text-4" id="text-8-2-2">
<p>
El comportamiento de las funciones de costo respecto a \(\lambda\) es espejado al que se observa segÃºn el grado del polinomio; esto es, \(J_train\) crece proporcionalmente a \(\lambda\).
</p>

<p>
Andrew propone elegir un conjunto de valores posibles de \(\lambda\) y evaluarlos para cada uno de los posibles valores de \(d\).
</p>

<p>
Algo interesante comentado en <a href="https://www.coursera.org/learn/machine-learning/discussions/weeks/6/threads/P3Cp9j_ZEeaDRA5SxbW7qQ">las preguntas frecuentes de la semana 6</a>, respecto a hacerlo de forma secuencial:
</p>

<blockquote>
<p>
Q5) What does Prof Ng mean when he says we're "fitting another parameter 'd' to the CV set"?
</p>

<p>
We use the CV set to make adjustments to the model. Prof Ng is referring to adjusting both the regularization and the polynomial degree.
</p>

<p>
But there is a problem.
</p>

<p>
Each subset of data can only be used for one purpose. If you have one CV set and use it to adjust the regularization, then you cannot continue using the same CV set to select the best polynomial degree. This would result in overfitting the CV set.
</p>

<p>
One solution is to further split the data set so you have two CV sets, and use one to adjust the regularization, and the second to select the best polynomial degree. But this increases the amount of labeled data that is needed.
</p>

<p>
A second solution is possible. You can create all possible combinations of the parameters 'd' and lambda, and evaluate each combination using only one validation set. You then select the combination that gives the lowest validation set error. Only one CV set is needed.
</p>
</blockquote>
</div>
</div>

<div id="outline-container-orgef2b313" class="outline-4">
<h4 id="orgef2b313"><span class="section-number-4">8.2.3</span> Learning curves</h4>
<div class="outline-text-4" id="text-8-2-3">
<p>
Las grÃ¡ficas de aprendizaje muestran la variaciÃ³n de los errores de entrenamiento y validaciÃ³n ante el cambio de cantidad de muestras de entrenamiento, para una complejidad de modelo fija.
</p>

<p>
Cuando nuestro modelo sufre de alto sesgo, vemos que \(J_{train}\) y \(J_{CV}\) pronto se estancan en un valor. El modelo no puede explicar mÃ¡s variaciÃ³n.
</p>


<div class="figure">
<p><img src="./imgs/006-1-learning-curves.png" alt="006-1-learning-curves.png" />
</p>
</div>

<p>
Para un modelo con alta varianza, las curvas varÃ­an lentamente y tienden a converger, pero van a necesitar de muchos ejemplos para poder encontrar la generalizaciÃ³n.
</p>


<div class="figure">
<p><img src="./imgs/006-2-learning-curves.png" alt="006-2-learning-curves.png" />
</p>
</div>

<p>
EstarÃ­a bueno tener una grÃ¡fica de como varÃ­an esas curvas al cambiar la complejidad del modelo&#x2026;
</p>
</div>
</div>

<div id="outline-container-orgb77e221" class="outline-4">
<h4 id="orgb77e221"><span class="section-number-4">8.2.4</span> Deciding what to do next revisited</h4>
<div class="outline-text-4" id="text-8-2-4">
<hr />

<p>
La regularizaciÃ³n sirve para forzar la exploraciÃ³n de todo el espacio de parÃ¡metros, y bajo la suposiciÃ³n de que los descriptores estÃ¡n normalizados. La regularizaciÃ³n intenta que todos los descriptores afecten en la decisiÃ³n, y esto puede ser mentira. Me parece que serÃ­a mejor atacar el problema con la complejidad del modelo, no con regularizaciÃ³n.
</p>
</div>
</div>
</div>

<div id="outline-container-orgf0045ec" class="outline-3">
<h3 id="orgf0045ec"><span class="section-number-3">8.3</span> Review</h3>
<div class="outline-text-3" id="text-8-3">
</div>
<div id="outline-container-org7679efd" class="outline-4">
<h4 id="org7679efd"><span class="section-number-4">8.3.1</span> Quiz: advice for applying machine learning</h4>
</div>

<div id="outline-container-orgdd50455" class="outline-4">
<h4 id="orgdd50455"><span class="section-number-4">8.3.2</span> Programming assignment: regularized linear regression and bias/variance</h4>
</div>
</div>

<div id="outline-container-orge3732d5" class="outline-3">
<h3 id="orge3732d5"><span class="section-number-3">8.4</span> Building a spam classifier</h3>
<div class="outline-text-3" id="text-8-4">
</div>
<div id="outline-container-orga105ce9" class="outline-4">
<h4 id="orga105ce9"><span class="section-number-4">8.4.1</span> Prioritizing what to work on</h4>
</div>

<div id="outline-container-org8b908ac" class="outline-4">
<h4 id="org8b908ac"><span class="section-number-4">8.4.2</span> Error analysis</h4>
<div class="outline-text-4" id="text-8-4-2">
<ul class="org-ul">
<li>Hacer una implementaciÃ³n rÃ¡pida de un clasificador y sus pruebas, para tener informaciÃ³n de en quÃ© paso gastar tiempo a continuaciÃ³n. Esto es importante.</li>
<li>Podemos construir curvas de aprendizaje para ver si necesitamos mÃ¡s o menos ejemplos, modelos mÃ¡s complejos, etcÃ©tera.</li>
<li>Podemos analizar manualmente los casos mal clasificados (o con mucho error en caso de regresiÃ³n, supongo), para intentar observar patrones.</li>
<li>Siempre es bueno tener una Ãºnica mÃ©trica de evaluaciÃ³n. Esta nos va a permitir discernir si una estrategia es buena o no.</li>
<li>Es muy recomendable evaluar las cosas en los conjuntos de validaciÃ³n cruzada, no en el conjunto de evaluaciÃ³n. Nunca ajustamos nada en el conjunto de evaluaciÃ³n.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org431b8d4" class="outline-3">
<h3 id="org431b8d4"><span class="section-number-3">8.5</span> Handling skewed data</h3>
<div class="outline-text-3" id="text-8-5">
</div>
<div id="outline-container-org0f90152" class="outline-4">
<h4 id="org0f90152"><span class="section-number-4">8.5.1</span> Error metrics for skewed classes</h4>
<div class="outline-text-4" id="text-8-5-1">
<p>
En clasificaciÃ³n (Â¿binaria?) en la distribuciÃ³n de las clases estÃ¡ muy sesgada (una de las clases es muy rara, tiene poca frecuencia), no es apropiado usar la precisiÃ³n como mÃ©trica. AquÃ­ corresponde analizar la precisiÃ³n y la exhaustividad (<i>recall</i>).
</p>


<div class="figure">
<p><img src="./imgs/007- precisionrecall.svg.png" alt="007- precisionrecall.svg.png" />
</p>
</div>

<p>
Podemos variar el comportamiento del modelo al modificar el umbral de decisiÃ³n a la salida (esto es un hiperparÃ¡metro, y lo evaluamos en el conjunto de validaciÃ³n).
</p>
</div>
</div>

<div id="outline-container-org4a20065" class="outline-4">
<h4 id="org4a20065"><span class="section-number-4">8.5.2</span> Trading off precision and recall</h4>
<div class="outline-text-4" id="text-8-5-2">
<p>
Una mÃ©trica que incluye la precisiÃ³n y la exhaustividad es el Valor F (<i>F score</i>), que se define como la media armÃ³nica (ponderada) de la precisiÃ³n y exhaustividad.
</p>

<p>
\[ F_\beta = (1 + \beta^2) \frac{precision \cdot recall}{(\beta^2 \cdot precision) + recall}  \]
</p>

<p>
\(\beta\) es cuÃ¡ntas veces es la exhaustividad mÃ¡s importante que la precisiÃ³n. Normalmente se usa \(\beta = 1\), obteniendo la mÃ©trica \(F_1\) que pondera de igual manera la precisiÃ³n y la exhaustividad.
</p>

<p>
\[ F_\beta \in [0, 1] \]
</p>
</div>
</div>
</div>


<div id="outline-container-orga2dc170" class="outline-3">
<h3 id="orga2dc170"><span class="section-number-3">8.6</span> Using large datasets</h3>
<div class="outline-text-3" id="text-8-6">
</div>
<div id="outline-container-org896ffb7" class="outline-4">
<h4 id="org896ffb7"><span class="section-number-4">8.6.1</span> Data for machine learning</h4>
<div class="outline-text-4" id="text-8-6-1">
<p>
Si tenemos
</p>

<ul class="org-ul">
<li>un conjunto de descriptores suficientemente expresivo como para determinar correctamente la salida a partir de ellos (si un humano experto puede hacerlo a partir de esas entradas, el sistema tambiÃ©n podrÃ¡);</li>
<li>un modelo complejo, de poco sesgo, que no se va a sobreajustar;</li>
</ul>

<p>
entonces la forma de mejorar los resultados es con mÃ¡s y mÃ¡s datos de entrenamiento.
</p>

<p>
En la publicaciÃ³n <a href="https://www.microsoft.com/en-us/research/publication/mitigating-the-paucity-of-data-problem-exploring-the-effect-of-training-corpus-size-on-classifier-performance-for-natural-language-processing/">"Mitigating the Paucity-of-Data Problem: Exploring the Effect of Training Corpus Size on Classifier Performance for Natural Language Processing" de Michele Banko y Eric Brill</a> se prueban varios modelos complejos y se observa que su desempeÃ±o tiende a ser el mismo, y ademÃ¡s crece monotÃ³nicamente con la cantidad de ejemplos de entrenamiento.
</p>
</div>
</div>
</div>

<div id="outline-container-org6f8aac5" class="outline-3">
<h3 id="org6f8aac5"><span class="section-number-3">8.7</span> Review</h3>
<div class="outline-text-3" id="text-8-7">
</div>
<div id="outline-container-org04ec7a3" class="outline-4">
<h4 id="org04ec7a3"><span class="section-number-4">8.7.1</span> Quiz: machine learning system design</h4>
</div>
</div>
</div>

<div id="outline-container-orgc0cdcad" class="outline-2">
<h2 id="orgc0cdcad"><span class="section-number-2">9</span> Semana 7</h2>
<div class="outline-text-2" id="text-9">
<p>
Vamos a ver <i>SVMs</i>: mÃ¡quinas de vector soporte / mÃ¡quinas de soporte vectorial.
</p>
</div>

<div id="outline-container-orgbb9512e" class="outline-3">
<h3 id="orgbb9512e"><span class="section-number-3">9.1</span> Large margin classification</h3>
<div class="outline-text-3" id="text-9-1">
</div>
<div id="outline-container-org7526418" class="outline-4">
<h4 id="org7526418"><span class="section-number-4">9.1.1</span> Optimization objective</h4>
<div class="outline-text-4" id="text-9-1-1">
<p>
Vamos a ver un algoritmo de aprendizaje supervisado mÃ¡s: las mÃ¡quinas de soporte vectorial. Primero definimos una funciÃ³n de costo a optimizar, que es similar a la que usamos para regresiÃ³n logÃ­stica.
</p>

<p>
\[  J(\theta) = C \sum_{i=1}^m \left[ y^{(i)} cost_1(\theta x^{(i)}) + (1-y^{(i)}) cost_0(1 - \theta x^{(i)}) \right]  + \frac{1}{2}  \sum_{v=1}^{n} \theta_v  \]
</p>

<ul class="org-ul">
<li><span class="underline">Este es un caso de clasificaciÃ³n binaria</span>.</li>
<li>\(C\) es equivalente a \(1/\lambda\), y es un factor que sirve para ponderar la optimizaciÃ³n del primer tÃ©rmino sobre el otro.</li>
<li>Las funciones \(cost_0\) y \(cost_1\) son muy similares al menos logaritmo de la funciÃ³n logÃ­stica (lo que estaba ahÃ­ en la funciÃ³n de costo que usamos para regresiÃ³n logÃ­stica). Parecen funciones rampa, con base en \(0\) y crecimiento en \(1\) y \(-1\) respectivamente.</li>
</ul>

<p>
La funciÃ³n de hipÃ³tesis (que todavÃ­a no vemos) no emite probabilidades, sino una salida discreta, que definimos con un umbral en \(0\):
</p>

<p>
\[  h_\theta(x) = 1 \quad si \quad \theta^T x \ge 0   \]
\[  h_\theta(x) = 0 \quad si \quad \theta^T x \lt 0  \]
</p>

<hr />

<p>
Resulta que \(cost_0\) y \(cost_1\) se llaman funciÃ³nes de pÃ©rdida bisagra (<a href="https://en.wikipedia.org/wiki/Hinge_loss"><i>hinge loss</i></a>).
</p>

<p>
\[ l(\hat{y}) = \max(0, 1-t \cdot \hat{y}) \]
</p>

<p>
donde \( y = \pm  1 \) es la salida deseada.
</p>

<p>
Resulta ademÃ¡s que la funciÃ³n de hipÃ³tesis es simplemente una combinaciÃ³n lineal de los descriptores de entrada, definida por los parÃ¡metros y a la que luego se le aplica un umbral en 0. MÃ¡s tarde vamos a remplazar los descriptores, para lograr fronteras no lineales.
</p>
</div>
</div>

<div id="outline-container-org68506cc" class="outline-4">
<h4 id="org68506cc"><span class="section-number-4">9.1.2</span> Large margin intuition</h4>
<div class="outline-text-4" id="text-9-1-2">
<p>
La minimizaciÃ³n nos da parÃ¡metros que definen una frontera Ã³ptima de separaciÃ³n entre clases. La frontera es Ã³ptima en tÃ©rminos de maximizar los mÃ¡rgenes, los espacios entre la frontera y los datos.
</p>

<ul class="org-ul">
<li>A menor C, mÃ¡s regularizaciÃ³n y menos sobreajuste.</li>
</ul>
</div>

<ol class="org-ol">
<li><a id="orgb273234"></a><span class="done DONE">DONE</span> Revisar esto y abajo<br />
<div class="outline-text-7" id="text-9-1-2-0-0-1">
</div>
</li>
</ol>
</div>

<div id="outline-container-org5bc82bd" class="outline-4">
<h4 id="org5bc82bd"><span class="section-number-4">9.1.3</span> Mathematics behind large margin classification</h4>
<div class="outline-text-4" id="text-9-1-3">
<p>
No se entendiÃ³.
</p>

<p>
Ya lo entendÃ­&#x2026; sirve para justificar la explicaciÃ³n del tÃ­tulo anterior.
</p>
</div>
</div>
</div>

<div id="outline-container-orgbd55267" class="outline-3">
<h3 id="orgbd55267"><span class="section-number-3">9.2</span> Kernels</h3>
<div class="outline-text-3" id="text-9-2">
</div>
<div id="outline-container-orgc3c8683" class="outline-4">
<h4 id="orgc3c8683"><span class="section-number-4">9.2.1</span> Kernels I</h4>
</div>



<div id="outline-container-orge1ea950" class="outline-4">
<h4 id="orge1ea950"><span class="section-number-4">9.2.2</span> Kernels II</h4>
<div class="outline-text-4" id="text-9-2-2">
<p>
En estos videos entendÃ­ un poco mÃ¡s y voy a intentar explicar todo acÃ¡.
</p>

<p>
En las <i>SVMs</i> nuestra funciÃ³n de hipÃ³tesis define un hiperplano de decisiÃ³n. La optimizaciÃ³n maximiza el margen entre ese hiperplano y los ejemplos de entrenamiento, a ambos lados del hiperplano.
</p>

<p>
Una forma de hacerlo serÃ­a como lo hicimos en regresiÃ³n lineal: agregando descriptores de mayor orden, a partir de los descriptores iniciales.
</p>

<p>
AcÃ¡ hacemos otra cosa: mapeamos nuestro conjunto de descriptores a otro conjunto de descriptores (no necesariamente del mismo tamaÃ±o). Este nuevo conjunto son distancias definidas por funciones de similitud / funciones de distancia. Â¿Distancia a dÃ³nde? La distancia es en el espacio de descriptores originales, entre las entradas y puntos de referencia (<i>landmarks</i>). Como puntos de referencia usamos <i>cada uno de los ejemplos de entrenamiento</i>.
</p>

<p>
A las funciones de distancia tambiÃ©n se denomina <i>kernels</i> o nÃºcleos. Ahora vimos un <i>kernel</i> gaussiano:
</p>

<p>
\[  f_i = similarity(x, l^{(i)} ) = e^{\frac{||x - l{(i)}||^2}{s\sigma^2}} = exp(\frac{||x - l{(i)}||^2}{s\sigma^2}) \]
</p>

<ul class="org-ul">
<li>Esta es una gaussiana de altura 1, y \(\sigma\) define su "anchura".
<ul class="org-ul">
<li>La similaridad serÃ¡ \(\approx1\) si la entrada estÃ¡ cerca de esa referencia, y \(0\) si estÃ¡ lejos.</li>
</ul></li>
<li>Mientras mÃ¡s grande \(\sigma\), la funciÃ³n es menos discriminativa, mÃ¡s suavizada. Entonces \(\sigma\) actÃºa como otro parÃ¡metro de regularizaciÃ³n.</li>
</ul>

<p>
NÃ³tese que luego deberemos mapear cada entrada al espacio de distancias, y ahÃ­ predecir la clase.
</p>

<p>
<b>Entonces al aplicar el <i>kernel</i> estamos convirtiendo un problema no lineal en uno lineal</b>. TambiÃ©n hacÃ­amos esto al agregar parÃ¡metros no lineales en regresiÃ³n lineal o logÃ­stica.
</p>

<p>
Â¿Por quÃ© no usamos estas funciones de distancia en regresiÃ³n lineal? En realidad si podemos, pero por cierta matemÃ¡tica de la implementaciÃ³n, esto es mucho mÃ¡s rÃ¡pido en las SVMs. <span class="underline">NÃ³tese que el espacio transformado de descriptores es de \(m\) dimensiones, donde \(m\) es el nÃºmero de ejemplos de entrenamiento</span>.
</p>
</div>
</div>
</div>

<div id="outline-container-orgcdd4443" class="outline-3">
<h3 id="orgcdd4443"><span class="section-number-3">9.3</span> SVMs in practice</h3>
<div class="outline-text-3" id="text-9-3">
</div>
<div id="outline-container-orgc764302" class="outline-4">
<h4 id="orgc764302"><span class="section-number-4">9.3.1</span> Using an SVM</h4>
<div class="outline-text-4" id="text-9-3-1">
<p>
Si bien hay mÃ¡s funciones de distancia o <i>kernels</i> normalmente se usan dos:
</p>
<ul class="org-ul">
<li><i>kernel</i> lineal (en realidad, sin <i>kernel</i>) es cuando no usamos funciÃ³n de distancia (lo que hicimos al principio) y \(\hat{y}=1 \quad si \quad h(\theta^T x) \ge 0\). Esto es muy similar en resultados a una regresiÃ³n logÃ­stica.</li>
<li><i>kernel</i> gaussiano.</li>
</ul>

<p>
Las soluciones se encuentran con algoritmos especializados para <i>SVM</i>. Les tenemos que dar la funciÃ³n de distancia y listo.
</p>

<p>
<b>Es importante normalizar los descriptores (hacer <i>feature scaling</i>) antes de calcular nos nuevos descriptores de distancia</b>. Al normalizar hacemos comparables los distintos descriptores, <b>ponderamos su informaciÃ³n de igual manera</b>.
</p>

<p>
La funciÃ³n de costo que optimizamos (definida anteriormente) es convexa, y por tanto siempre encontramos el mÃ­nimo global.
</p>

<p>
Los algoritmos pueden soportar multiclase. Si no, hacemos el clÃ¡sico "uno contra todos".
</p>
<ul class="org-ul">
<li>Para \(K\) clases necesitamos \(K\) clasificadores.</li>
</ul>
</div>

<ol class="org-ol">
<li><a id="org2e01b82"></a>CuÃ¡ndo usar<br />
<div class="outline-text-5" id="text-9-3-1-1">
<p>
Sean
</p>
<ul class="org-ul">
<li>\(n\) el nÃºmero de descriptores/parÃ¡metros.</li>
<li>\(m\) el nÃºmero de ejemplos de entrenamiento.</li>
</ul>


<p>
Entonces
</p>

<ol class="org-ol">
<li>Si \(\frac{n}{m} \ge 10\), el sistema estÃ¡ subdeterminado y es mejor intentar con un modelo simple. Tenemos pocos datos y con un modelo complejo nos arriesgamos a sobreajustar. AquÃ­ podemos usar regresiÃ³n logÃ­stica o <i>SVM</i> con <i>kernel</i> lineal, que es equivalente.</li>

<li>Si \(\frac{m}{n} \ge 10\), el sistema estÃ¡ sobredeterminado. AcÃ¡ deberÃ­amos usar un modelo complejo que permita capturar la influencia de todos los descriptores. AquÃ­ es donde brillan las <i>SVM</i> con <i>kernel</i> gaussiano.

<ul class="org-ul">
<li>Si \(m\) es muy grande (\(\gt10000\)), entonces una <i>SVM</i> con <i>kernel</i> gaussiano tarda mucho en entrenar. Entonces podemos usar regresiÃ³n logÃ­stica o un <i>kernel</i> lineal, junto con la adiciÃ³n de nuevos descriptores sintÃ©ticos. Esto es solo por una limitaciÃ³n de poder de cÃ³mputo.</li>
</ul></li>
</ol>

<p>
Dice Andrew que en ambos casos tambiÃ©n podrÃ­amos usar redes neuronales, pero estas tardan mÃ¡s en entrenar.
</p>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-orgb25f6cf" class="outline-3">
<h3 id="orgb25f6cf"><span class="section-number-3">9.4</span> Review</h3>
<div class="outline-text-3" id="text-9-4">
</div>
<div id="outline-container-org75f0d27" class="outline-4">
<h4 id="org75f0d27"><span class="section-number-4">9.4.1</span> Quiz: support vector machines</h4>
</div>

<div id="outline-container-orgfb4a2d6" class="outline-4">
<h4 id="orgfb4a2d6"><span class="section-number-4">9.4.2</span> Programming assignment SVMs</h4>
<div class="outline-text-4" id="text-9-4-2">
<p>
UsÃ© <code>containers.Map</code> para crear un mapeo, como los diccionarios de Python.
</p>
</div>
</div>
</div>

<div id="outline-container-org76fc964" class="outline-3">
<h3 id="org76fc964"><span class="section-number-3">9.5</span> Otras cosas</h3>
<div class="outline-text-3" id="text-9-5">
</div>
<div id="outline-container-org84c670d" class="outline-4">
<h4 id="org84c670d"><span class="section-number-4">9.5.1</span> <a href="https://www.youtube.com/watch?v=3liCbRZPrZA">https://www.youtube.com/watch?v=3liCbRZPrZA</a> SVM with polynomial kernel visualization</h4>
<div class="outline-text-4" id="text-9-5-1">
<blockquote>
<p>
Technically what is visualized here isn't "the kernel trick". This is the general idea of how nonlinearly projecting some points into a higher-dimensional feature space makes linear classifiers more powerful. You can do this with out SVMs. Just compute the high-dimensional features corresponding to your data, then use logistic regression or whatever. Trouble is, if the higher-dimensional space is really big, this could be expensive. The "kernel trick" is computational trick that SVMs use to compute the inner product between the high-dimensional features corresponding to two points with out explicitly computing the high-dimensional features. (For certain special feature spaces.)
</p>

<p>
But this is definitely a cool visualization of the value of feature spaces! 
</p>
</blockquote>
<p>
<a href="https://news.ycombinator.com/item?id=1299733">https://news.ycombinator.com/item?id=1299733</a>
</p>
</div>
</div>


<div id="outline-container-orgd4ace66" class="outline-4">
<h4 id="orgd4ace66"><span class="section-number-4">9.5.2</span> <a href="https://ranvir.xyz/blog/svm-support-vector-machines-in-machine-learning/">https://ranvir.xyz/blog/svm-support-vector-machines-in-machine-learning/</a></h4>
<div class="outline-text-4" id="text-9-5-2">
<p>
DiscusiÃ³n en <a href="https://news.ycombinator.com/item?id=23035120">https://news.ycombinator.com/item?id=23035120</a>
</p>

<ul class="org-ul">
<li><a href="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers">https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</a></li>
<li><a href="http://www.stat.columbia.edu/~gelman/book/">http://www.stat.columbia.edu/~gelman/book/</a></li>
<li>"Statistical Rethinking" by McElreath</li>
<li>Introduction to Statistical Learning <a href="https://faculty.marshall.usc.edu/gareth-james/ISL/">https://faculty.marshall.usc.edu/gareth-james/ISL/</a></li>
<li>Elements of Statistical Learning <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">https://web.stanford.edu/~hastie/ElemStatLearn/</a></li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-org88fd031" class="outline-2">
<h2 id="org88fd031"><span class="section-number-2">10</span> Semana 8: Unsupervised learning</h2>
<div class="outline-text-2" id="text-10">
<p>
Vamos a ver algo de aprendizaje no supervisado. AcÃ¡ no tenemos entradas y salidas etiquetadas; solo un conjunto de datos de entrada de los cuÃ¡les queremos entender la estructura subyacente.
TambiÃ©n vemos algo de reducciÃ³n de la dimensionalidad del problema.
</p>
</div>

<div id="outline-container-org04dd254" class="outline-3">
<h3 id="org04dd254"><span class="section-number-3">10.1</span> Clustering</h3>
<div class="outline-text-3" id="text-10-1">
</div>
<div id="outline-container-org731ba36" class="outline-4">
<h4 id="org731ba36"><span class="section-number-4">10.1.1</span> Unsupervised learning: introduction</h4>
<div class="outline-text-4" id="text-10-1-1">
<p>
Buscamos ver si hay conjuntos de datos que presentan caracterÃ­sticas similares, con las cuÃ¡les podrÃ­amos agruparlos.
</p>

<p>
TambiÃ©n podemos usar algoritmos de agrupamiento cuando nosotros queremos agrupar los datos en un nÃºmero arbitrario de grupos. Por ejemplo, podrÃ­amos querer tener K segmentos de mercado.
</p>
</div>
</div>

<div id="outline-container-org53a9d8b" class="outline-4">
<h4 id="org53a9d8b"><span class="section-number-4">10.1.2</span> K-means algorithm</h4>
<div class="outline-text-4" id="text-10-1-2">
<p>
<b>AcÃ¡ trabajamos los ejemplos en sus \(n\) dimensiones originales; no agregamos el \(x_0=1\) que nos facilitaba trabajar con los interceptos.</b>
</p>

<p>
Sean:
</p>

<ul class="org-ul">
<li>\(K\): el nÃºmero de grupos que queremos tener, indexado con \(k\).</li>
<li>\(\mu_k\): el centroide / centro de masa del grupo \(k\).</li>
<li>\(c^{(i)}\): el grupo asignado al ejemplo \(i\). Es el grupo que tiene la menor distancia entre su centroide y el ejemplo. Hay varias mÃ©tricas de distancia; la mÃ¡s comÃºn es la euclidea.</li>
<li>\(\mu_{c^{(i)}}\): el centroide del grupo / <i>cluster</i> del ejemplo \(i\).</li>
</ul>


<p>
El algoritmo es:
</p>

<ul class="org-ul">
<li>Hasta la convergencia o llegar a un nÃºmero de interaciones:
<ul class="org-ul">
<li>Etiquetar cada ejemplo \((i)\), asignÃ¡ndole un grupo \(c^{(i)}\).</li>
<li>Recalcular los centroides de cada grupo. El nuevo valor de un centroide \(\mu_k\) serÃ¡ el centro de masa de los ejemplos etiquetados con \(k\) (\(c^{(i)}=k\)).</li>
</ul></li>
</ul>

<p>
Si un grupo \(k\) no tiene ejemplos tras alguna iteraciÃ³n, lo podemos eliminar.
</p>
</div>
</div>


<div id="outline-container-org7cf27bf" class="outline-4">
<h4 id="org7cf27bf"><span class="section-number-4">10.1.3</span> Optimization objective</h4>
<div class="outline-text-4" id="text-10-1-3">
<p>
La funciÃ³n que estamos optimizando es:
</p>

<p>
\[ J(c^{(1)}, \dots, c^{(m)} , \mu_1, \dots, \mu_k ) = \frac{1}{m} \sum_1^m || x^{(i)} - \mu_{c^{(i)}} ||^2 \]
</p>

<p>
Es conocida como <i>distorsiÃ³n</i> del algoritmo <i>K-means</i>.
</p>

<p>
El algoritmo primero optimiza \(c\), manteniendo \(\mu\) constante, y despuÃ©s lo hace a la inversa.
</p>

<p>
<b>No es una funciÃ³n convexa</b>, lo que implica que podemos tener mÃ¡s de un mÃ­nimo.
</p>

<p>
La funciÃ³n de costo <span class="underline">debe</span> disminuir en cada iteraciÃ³n.
</p>
</div>
</div>

<div id="outline-container-org7140df5" class="outline-4">
<h4 id="org7140df5"><span class="section-number-4">10.1.4</span> Random initialization</h4>
<div class="outline-text-4" id="text-10-1-4">
<p>
La configuraciÃ³n Ã³ptima que encontremos al minimizar se ve influenciada por cÃ³mo inicializamos los centroides. La forma recomendada es asignarles la posiciÃ³n de un ejemplo cualquiera (distinto a cada uno).
</p>

<p>
Para buscar la soluciÃ³n global, ejecutamos el algoritmo muchas veces y nos quedamos con aquella soluciÃ³n de menor distorsiÃ³n.
</p>

<ul class="org-ul">
<li>Es importante hacer esto cuando K es chico (Andrew dice 2 a 10), pero no tan necesario cuando estamos buscando muchos grupos.</li>
</ul>
</div>
</div>

<div id="outline-container-org2e77757" class="outline-4">
<h4 id="org2e77757"><span class="section-number-4">10.1.5</span> Choosing the number of clusters</h4>
<div class="outline-text-4" id="text-10-1-5">
<p>
<b>La funciÃ³n de costo debe disminuir a medida que incrementamos K</b>, llegando al mÃ­nimo cuando \(K=m\). Si no ocurre para un cierto \(K\), es que tuvimos un resultado de un mÃ­nimo local no bueno.
</p>

<p>
El nÃºmero se suele elegir a ojo, observando los datos, o estÃ¡ determinado por el problema en el cuÃ¡l vamos a usar nuestro agrupamiento.
</p>

<p>
Una forma de elegir el nÃºmero de grupos es con el "mÃ©todo del codo". Este consiste en graficar la funciÃ³n de costo segÃºn el valor de \(K\), y elegir el vÃ©rtice de la grÃ¡fica descendente. Si no hay vÃ©rtice claramente observable, entonces no nos sirve el mÃ©todo.
</p>
</div>
</div>
</div>

<div id="outline-container-org195f42b" class="outline-3">
<h3 id="org195f42b"><span class="section-number-3">10.2</span> Review</h3>
<div class="outline-text-3" id="text-10-2">
</div>
<div id="outline-container-org6c5e15d" class="outline-4">
<h4 id="org6c5e15d"><span class="section-number-4">10.2.1</span> Quiz: Unsuperised learning</h4>
</div>
</div>

<div id="outline-container-org67dba36" class="outline-3">
<h3 id="org67dba36"><span class="section-number-3">10.3</span> Dimensionality reduction</h3>
<div class="outline-text-3" id="text-10-3">
</div>
<div id="outline-container-orgf3a26c1" class="outline-4">
<h4 id="orgf3a26c1"><span class="section-number-4">10.3.1</span> Motivation</h4>
<div class="outline-text-4" id="text-10-3-1">
</div>
<ol class="org-ol">
<li><a id="org1d70967"></a>Motivation I: Data compression<br />
<div class="outline-text-5" id="text-10-3-1-1">
<p>
Otro tipo de aprendizaje no supervisado se usa para reducir la dimensionalidad de nuestro universo representado. Esto es, representar la misma informaciÃ³n pero con menos descriptores. Esto nos va a permitir tener representaciones mÃ¡s compactas (menos memoria) y sobre todo, acelerar la bÃºsqueda de soluciones.
</p>
</div>
</li>

<li><a id="org6397efb"></a>Motivation II Visualization<br />
<div class="outline-text-5" id="text-10-3-1-2">
<p>
Otro aplicaciÃ³n de la reducciÃ³n de dimensionalidad es para intentar visualizar nuestros datos. La visualizaciÃ³n suele ayudarnos a entender los datos y proponer mejores soluciones.
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-org72089d7" class="outline-4">
<h4 id="org72089d7"><span class="section-number-4">10.3.2</span> Principal component analysis</h4>
<div class="outline-text-4" id="text-10-3-2">
</div>
<ol class="org-ol">
<li><a id="orga67acff"></a>Principal component analysis formulation<br />
<div class="outline-text-5" id="text-10-3-2-1">
<p>
<b>AcÃ¡ trabajamos los ejemplos en sus \(n\) dimensiones originales; no agregamos el \(x_0=1\) que nos facilitaba trabajar con los interceptos.</b>
</p>

<p>
El algoritmo mÃ¡s usado para reducciÃ³n dimensional es el llamado "AnÃ¡lisis de componentes principales" (<i>Principal Component Analysis, PCA</i>). Para el (hiper)espacio de representaciÃ³n de nuestros descriptores, <i>PCA</i> busca determinar el hiperplano que minimice las distancias entre los puntos en el hiperespacio y sus proyecciones (ortogonales) en el hiperplano.
</p>
</div>
</li>

<li><a id="org2c27ecd"></a>Principal component analysis algorithm<br />
<div class="outline-text-5" id="text-10-3-2-2">
<p>
No vamos a ver demostraciones, pero la cosa es mÃ¡s o menos asÃ­.
</p>

<p>
Primero debemos normalizar/escalar los valores de entrada, para que estÃ©n en dimensiones comparables.
</p>

<p>
Luego construimos la matriz de covarianza, que tiene las covarianzas de las dimensiones. // La <a href="https://en.wikipedia.org/wiki/Covariance">covarianza</a> indica dependencia entre dimensiones. Si la covarianza es 0, las dimensiones son independientes.
</p>

<p>
\[ \Sigma = \frac{1}{m} \sum_{i=1}^m x^{(i)} (x^{(i)})^T = \frac{1}{m} X^T X \]
</p>

<p>
Ahora aplicamos la DescomposiciÃ³n en valores singulares (<i>SVD, Singular Value Decomposition</i>), que es una factorizaciÃ³n que nos permite obtener los vectores propios o autovectores de la matriz de covarianza.
</p>

<p>
\[ U_{m \times k}, S, V = svd(\Sigma)  \]
</p>

<p>
Nos importa la matriz \(U\), que tiene autovectores. Cada columna es un autovector, y estos son las dimensiones (Â¿rotadas? distintas.) que Â¿mejor? explican nuestros datos. De esta matriz \(U\) nos vamos a quedar con los primeros \(k\) vectores, que serÃ¡n nuestro nuevo espacio de representaciÃ³n. Construimos entonces una matriz \(U_{reducciÃ³n}\).
</p>

<p>
Para expresar los vectores en las nuevas dimensiones, hacemos
</p>

<p>
\[ z^{(i)} = U_{reducciÃ³n}^T x^{(i)} \]
</p>

<p>
O para todos los ejemplos:
</p>

<p>
\[ Z = X U_{reducciÃ³n} \]
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-org04565fd" class="outline-4">
<h4 id="org04565fd"><span class="section-number-4">10.3.3</span> Appliying PCA</h4>
<div class="outline-text-4" id="text-10-3-3">
</div>
<ol class="org-ol">
<li><a id="orgdc8623b"></a>Reconstruction from compressed representation<br />
<div class="outline-text-5" id="text-10-3-3-1">
<p>
Para volver del espacio \(R^k\) al \(R^n\), usamos la matriz \(U\) asÃ­:
</p>

<p>
\[  x_{aprox}^{(i)} = U_{reducciÃ³n}  x^{(i)} \]
</p>

<p>
O para todos los ejemplos:
</p>

<p>
\[ X_aprox = X U_{reducciÃ³n}^T \]
</p>

<ul class="org-ul">
<li>NÃ³tese que lo que obtenemos es una aproximaciÃ³n de el dato original. Esta aproximaciÃ³n es la proyecciÃ³n del dato original en el hiperplano de menor dimensiÃ³n calculado con <i>PCA</i>, pero expresado en las \(n\) dimensiones originales.
<ul class="org-ul">
<li>Perdemos informaciÃ³n.</li>
</ul></li>
</ul>
</div>
</li>

<li><a id="orga97eac8"></a>Choosing the number of principal components<br />
<div class="outline-text-5" id="text-10-3-3-2">
<p>
Sean
</p>

<ul class="org-ul">
<li>Error medio de proyecciÃ³n: \( E_{p} = \frac{1}{m} \sum_{i=1}^{m} || x^{(i)} - x_{aprox}^{(i)} ||^2 \)</li>
<li>Varianza de los datos: \( V = \frac{1}{m} \sum_{i=1}^{m} ||x^{(i)}||^2  \)</li>
</ul>

<p>
Podemos definir la varianza no explicada / no retenida por nuestro modelo de dimensiones reducidas como
</p>

<p>
\[ V_{ne} = \frac{\frac{1}{m} \sum_{i=1}^{m} || x^{(i)} - x_{aprox}^{(i)} ||^2}{\frac{1}{m} \sum_{i=1}^{m} ||x^{(i)}||^2}  \]
</p>

<p>
\[ V_{ne} = \frac{\sum_{i=1}^{m} || x^{(i)} - x_{aprox}^{(i)} ||^2}{\sum_{i=1}^{m} ||x^{(i)}||^2}  \]
</p>

<ul class="org-ul">
<li>Normalmente buscamos que \(V_{ne}\) sea menor al \(5%\) o \(1%\), pero depende del caso.</li>
<li>En modelos de alta dimensionalidad es frecuente encontrar que muchas dimensiones estÃ¡n correlacionadas y por tanto podemos encontrar un \(k\ll n\).</li>
</ul>

<p>
Para calcular \(V_{ne}\) como lo definimos anteriormente, debemos hacer todo el proceso de <i>PCA</i> para un \(k\) dado, para luego calcular los errores de proyecciÃ³n. Esto es costoso.
</p>

<p>
Una mejor forma de hacerlo es con la matriz \(S\) obtenida al hacer <i>SVD</i>:
</p>

<p>
\[ U_{m \times k}, S, V = svd(\Sigma)  \]
</p>

<p>
Esta tiene (en su diagonal principal) los autovalores \(s_{ii}\) asociados con los autovectores de \(U\), y al igual que estos, estÃ¡n ordenados de mayor a menor importancia o influencia. Podemos hacer entonces:
</p>

<p>
\[ V_{ne} = 1 - \frac{ \sum_{i=1}^k s_{ii} }{ \sum_{i=1}^n s_{ii} } \]
</p>

<p>
y fÃ¡cilmente definimos el \(k\) que queremos.
</p>
</div>
</li>


<li><a id="orgc4c8635"></a>Advice for appliying PCA<br />
<div class="outline-text-5" id="text-10-3-3-3">
<p>
Algunos consejos:
</p>

<ol class="org-ol">
<li><b>No</b> usar <i>PCA</i> como herramienta para reducir sobreajuste. Puede funcionar, pero al usar <i>PCA</i> no estamos teniendo en cuenta las etiquetas de los datos de entrada, y quizÃ¡s estamos desechando informaciÃ³n importante, o grupos enteros de datos. La regulrizaciÃ³n es el mÃ©todo que deberÃ­amos usar en su lugar.</li>
<li>No usar <i>PCA</i> de entrada, por que sÃ­. DeberÃ­amos siempre probar con los datos crudos, y usar <i>PCA</i> si queremos acelerar el aprendizaje o usar menos espacio, por ejemplo.</li>
</ol>
</div>
</li>
</ol>
</div>

<div id="outline-container-orgc387e07" class="outline-4">
<h4 id="orgc387e07"><span class="section-number-4">10.3.4</span> Review</h4>
<div class="outline-text-4" id="text-10-3-4">
</div>
<ol class="org-ol">
<li><a id="org10ee7c3"></a>Quiz: principal component analysis<br /></li>

<li><a id="orgcc0b299"></a>Programming assignment: K-means clustering and PCA<br /></li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org2cd401c" class="outline-2">
<h2 id="org2cd401c"><span class="section-number-2">11</span> Semana 9: Anomaly detection &amp; Recommender systems</h2>
<div class="outline-text-2" id="text-11">
</div>
<div id="outline-container-org0efb50a" class="outline-3">
<h3 id="org0efb50a"><span class="section-number-3">11.1</span> Anomaly detection</h3>
<div class="outline-text-3" id="text-11-1">
</div>
<div id="outline-container-org909db7b" class="outline-4">
<h4 id="org909db7b"><span class="section-number-4">11.1.1</span> Density estimation</h4>
<div class="outline-text-4" id="text-11-1-1">
</div>
<ol class="org-ol">
<li><a id="orge0c2849"></a>Problem motivation<br />
<div class="outline-text-5" id="text-11-1-1-1">
<p>
En la detecciÃ³n de anomalÃ­as intentamos construir un modelo a partir de casos que consideramos comunes, para luego usarlo para detectar eventos no comunes.
</p>
</div>
</li>

<li><a id="org0a20335"></a>Gaussian distribution<br /></li>

<li><a id="orgc83e026"></a>Algorithm<br />
<div class="outline-text-5" id="text-11-1-1-3">
<p>
Suposiciones:
</p>

<ul class="org-ul">
<li>Todos los descriptores estÃ¡n distribuidos normalmente.</li>
<li>Los descriptores son independientes entre sÃ­.</li>
</ul>

<p>
Para cada descriptor \(x_j\) podemos estimar una distribuciÃ³n normal, calculando \(\mu_j\) y \(\sigma_j\):
</p>

<p>
\[ x_j \sim \mathcal{N}(\mu_j , \sigma_j) \]
</p>

<p>
La probabilidad de que un evento \(x\) estÃ© en cierto punto serÃ¡ el producto de todas las probabilidades individuales:
</p>

<p>
\[ P(x) = \prod_{j=1}^{m} P(x_j, \mu_j, \sigma_j)  \]
</p>

<p>
Esto nos define una densidad de probabilidad en el hiperespacio \(\mathbb{R}^n\). Definimos un umbral \(\epsilon\) global (define un hiperplano) que clasificarÃ¡ entre anomalÃ­as o no anomalÃ­as; esto es, usamos el mismo umbral \(\epsilon\) para todos los descriptores.
</p>

<p>
\[ x \ \text{es anomalÃ­a si} \  P(x_j) < \epsilon \ \text{para cualquier} \  j \]
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-orge655b13" class="outline-4">
<h4 id="orge655b13"><span class="section-number-4">11.1.2</span> Building an anomaly detection system</h4>
<div class="outline-text-4" id="text-11-1-2">
</div>
<ol class="org-ol">
<li><a id="orgd0ae9e3"></a>Developing and evaluating an anomaly detection system<br />
<div class="outline-text-5" id="text-11-1-2-1">
<p>
Usamos datos etiquetados para entrenar un clasificador.
</p>
<ul class="org-ul">
<li>"Entrenamos"/definimos las funciones de densidad de probabilidad a partir de ejemplos normales, no problemÃ¡ticos.</li>
<li>Ajustamos hiperparÃ¡metros (quÃ© descriptores usamos, \(\epsilon\), &#x2026;) en el conjunto de validaciÃ³n cruzada, que sÃ­ tiene datos anÃ³malos.</li>
<li>Evaluamos en el conjunto de prueba, que sÃ­ tiene datos anÃ³malos.</li>
</ul>

<p>
Como los datos suelen estar muy sesgados, no podemos usar la precisiÃ³n como mÃ©trica.
</p>

<p>
Â¿Por quÃ© es esto distinto a una clasificaciÃ³n normal?
</p>
</div>
</li>

<li><a id="orge0fae3e"></a>Anomaly detection vs supervised learning<br />
<div class="outline-text-5" id="text-11-1-2-2">
<p>
La diferencia entre un algoritmo de detecciÃ³n de anomalÃ­as y un algoritmo clasificador de aprendizaje supervisado es que en los primeros sÃ³lo modelamos un caso (el normal), mientras en que en los segundos estamos modelando todo el universo, todas nuestras clases.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">DetecciÃ³n de anomalÃ­as</th>
<th scope="col" class="org-left">Aprendizaje supervisado</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">- Tenemos muy pocos datos de anomalÃ­as. Andrew habla de 1 a 20 ejemplos.</td>
<td class="org-left">- Tenemos bastantes ejemplos de las anomalÃ­as.</td>
</tr>

<tr>
<td class="org-left">- Las anomalÃ­as futuras que nuestro algoritmo quizÃ¡s ni siquiera estaban en nuestros datos de entrenamiento.</td>
<td class="org-left">- Los ejemplos que encontremos y queremos clasificar serÃ¡n similares a aquellos con los que entrenamos.</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">- DetecciÃ³n de fraude.</td>
<td class="org-left">- ClasificaciÃ³n de email en spam y no spam.</td>
</tr>

<tr>
<td class="org-left">- Defectos de fabricaciÃ³n.</td>
<td class="org-left">- DetecciÃ³n de cÃ¡ncer.</td>
</tr>

<tr>
<td class="org-left">- Defectos de funcionamiento.</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>
</div>
</li>


<li><a id="org2352335"></a>Choosing what features to use<br />
<ol class="org-ol">
<li><a id="org7dedb5a"></a>Aproximar a gaussiana<br />
<div class="outline-text-6" id="text-11-1-2-3-1">
<p>
Estamos modelando distribuciones gaussianas. Debemos observar cuÃ¡l es la distribuciÃ³n real de nuestros descriptores, y si alguna no es gaussiana, es recomendable que la aproximemos, aplicando alguna transformaciÃ³n a ese descriptor. Si no lo hacemos es probable que igualmente funcione, pero es mejor si todo es gaussiano.
</p>
<ul class="org-ul">
<li>Â¿SerÃ¡ equivalente modelar con las distribuciones que mÃ¡s se aproximen a cada descriptor?</li>
</ul>
</div>
</li>

<li><a id="org4c90cf1"></a>AnÃ¡lisis de errores<br />
<div class="outline-text-6" id="text-11-1-2-3-2">
<p>
Podemos analizar los errores de clasificaciÃ³n para idear o buscar nuevos descriptores que nos permitan discriminar esos casos.
</p>
</div>
</li>

<li><a id="orgbef4870"></a>DiseÃ±o de descriptores<br />
<div class="outline-text-6" id="text-11-1-2-3-3">
<p>
Podemos crear nuevos descriptores que relacionen otros que ya tenemos; por ejemplo, productos o divisiones entre descriptores. DeberÃ­amos pensar en quÃ© cosas se vuelven extremas en los posibles casos anÃ³malos.
</p>

<ul class="org-ul">
<li>Esto no es necesario si usamos una distribuciÃ³n gaussiana multivariable.</li>
</ul>
</div>
</li>
</ol>
</li>
</ol>
</div>

<div id="outline-container-org6f1ed60" class="outline-4">
<h4 id="org6f1ed60"><span class="section-number-4">11.1.3</span> Multivariate gaussian distribution</h4>
<div class="outline-text-4" id="text-11-1-3">
</div>
<ol class="org-ol">
<li><a id="org370f275"></a>Multivariate gaussian distribution<br />
<div class="outline-text-5" id="text-11-1-3-1">
<p>
Nuestra suposiciÃ³n en los modelos anteriores era que los descriptores estaban distribuidos normalmente y ademÃ¡s eran independientes. Estos modelos son limitados y fallan en capturar anomalÃ­as, por ejemplo cuando los descriptores estÃ¡n correlacionados.
</p>

<p>
Podemos construir un modelo mÃ¡s complejo con una gaussiana multivariable, con todos los descriptores. Seguimos asumiendo que las distribuciones originales son gaussianas.
</p>
</div>
</li>

<li><a id="org485eb5b"></a>Anomaly detection using the multivariate gaussian distribution<br />
<ol class="org-ol">
<li><a id="orgb746d2a"></a>EstimaciÃ³n y uso<br />
<div class="outline-text-6" id="text-11-1-3-2-1">
<p>
Ahora tenemos un vector de medias y una matriz de covarianza:
</p>

<p>
\[ \vec{\mu} = \frac{1}{m} \sum_{i=1}^m \vec{x}^{(i)}  \]
</p>

<p>
\[ \Sigma =  \frac{1}{m} \sum_{i=1}^{m} (\vec{x}^{(i)} - \vec{\mu})^T  ( \vec{x}^{(i)} - \vec{\mu})  \]
</p>

<p>
La estimaciÃ³n es:
</p>

<p>
\[ P(\vec{x}, \vec{\mu}, \Sigma) = \frac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} \exp\left( -\frac{1}{2} ( \vec{x}- \vec{\mu})^T \Sigma^{-1} ( \vec{x}- \vec{\mu})  \right) \]
</p>
</div>
</li>

<li><a id="org7ff2c76"></a>Comentarios<br />
<div class="outline-text-6" id="text-11-1-3-2-2">
<p>
El modelo original (producto de gaussianas) es un caso especial de una distribuciÃ³n gaussiana multivariable, cuando las variables no estÃ¡n correlacionadas. Esto implica que la matriz de covarianza es diagonal y que la distribuciÃ³n resultante se desarrolla a lo largo de los ejes, no estÃ¡ rotada.
</p>

<p>
Si usamos una distribuciÃ³n gaussiana multivariable no es necesario que construyamos descriptores que capturen relaciones entre lso descriptores, porque ya estÃ¡n implÃ­citas en el modelo.
</p>

<p>
Dice Andrew que el modelo original es computacionalmente mÃ¡s barato y que escala mejor cuando tenemos muchos datos, especialmente porque hay que invertir una matriz. Yo digo que lo de la matriz es una excusa, porque se puede precalcular, no es necesario andar invirtiÃ©ndola para cada predicciÃ³n.
</p>

<p>
En el modelo original tenÃ­amos \(2n\) parÃ¡metros a estimar, mientras que en este tenemos \(n^2 + n\). Por lo tanto necesitamos mÃ¡s datos para una buena regresiÃ³n.
</p>
</div>
</li>
</ol>
</li>
</ol>
</div>


<div id="outline-container-orgef590fc" class="outline-4">
<h4 id="orgef590fc"><span class="section-number-4">11.1.4</span> Review</h4>
<div class="outline-text-4" id="text-11-1-4">
</div>
<ol class="org-ol">
<li><a id="org42685a8"></a>Quiz: anomaly detection<br /></li>
</ol>
</div>
</div>

<div id="outline-container-org59e37a1" class="outline-3">
<h3 id="org59e37a1"><span class="section-number-3">11.2</span> Recommender systems</h3>
<div class="outline-text-3" id="text-11-2">
</div>
<div id="outline-container-orgc515c35" class="outline-4">
<h4 id="orgc515c35"><span class="section-number-4">11.2.1</span> Predicting movie ratings</h4>
<div class="outline-text-4" id="text-11-2-1">
</div>
<ol class="org-ol">
<li><a id="orgff9689f"></a>Problem formulation<br /></li>

<li><a id="org75cb725"></a>Content based recommendations<br /></li>
</ol>
</div>

<div id="outline-container-org65f9fe1" class="outline-4">
<h4 id="org65f9fe1"><span class="section-number-4">11.2.2</span> Collaborative filtering</h4>
<div class="outline-text-4" id="text-11-2-2">
</div>
<ol class="org-ol">
<li><a id="orge181de5"></a>Collaborative filtering<br /></li>

<li><a id="orgd62e6d9"></a>Collaborative filtering algorithm<br /></li>
</ol>
</div>

<div id="outline-container-org9be2c6d" class="outline-4">
<h4 id="org9be2c6d"><span class="section-number-4">11.2.3</span> Low rank matrix factorization</h4>
<div class="outline-text-4" id="text-11-2-3">
</div>
<ol class="org-ol">
<li><a id="org796b6f8"></a>Vectorization: low rank matrix factorization<br /></li>

<li><a id="org0064765"></a>Implementational detail: mean normalization<br /></li>
</ol>
</div>

<div id="outline-container-orgb0905ea" class="outline-4">
<h4 id="orgb0905ea"><span class="section-number-4">11.2.4</span> Review</h4>
<div class="outline-text-4" id="text-11-2-4">
</div>
<ol class="org-ol">
<li><a id="org085dc72"></a>Quiz: recommender systems<br /></li>

<li><a id="org5bb29ea"></a>Programming assignment: anomaly detection and recommender systems<br /></li>
</ol>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Pablo Aguado</p>
<p class="date">Created: 2020-05-27 miÃ© 22:43</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
