<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2020-05-27 mié 22:43 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Notas del curso Machine Learning de Andrew Ng en Coursera</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Pablo Aguado" />
<meta name="description" content="Mis notas."
 />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Notas del curso Machine Learning de Andrew Ng en Coursera</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org6b46073">1. Info</a></li>
<li><a href="#org6460034">2. Ideas</a>
<ul>
<li><a href="#orge6fa82c">2.1. Enlaces</a></li>
</ul>
</li>
<li><a href="#orgfac42e4">3. Semana 1</a>
<ul>
<li><a href="#org818b3ba">3.1. Introduction</a>
<ul>
<li><a href="#org9a1f52a">3.1.1. Video: Welcome</a></li>
<li><a href="#org25c8b66">3.1.2. Video: What is Machine Learning</a></li>
<li><a href="#orgc27371e">3.1.3. Reading: What is Machine Learning?</a></li>
<li><a href="#orgbc40ee3">3.1.4. Video: Supervised Learning</a></li>
<li><a href="#orgd4fff1f">3.1.5. Video: Unsupervised Learning</a></li>
</ul>
</li>
<li><a href="#org1c763e4">3.2. Model and cost function</a>
<ul>
<li><a href="#orgfad501a">3.2.1. Video: Model representation</a></li>
<li><a href="#org1efd2e7">3.2.2. Reading: Model representation</a></li>
<li><a href="#orgc8783f8">3.2.3. Video: Cost function</a></li>
<li><a href="#org1c8cbb0">3.2.4. Reading: Cost function</a></li>
<li><a href="#org3bc2d13">3.2.5. Video: Cost function intuition I</a></li>
<li><a href="#org1047348">3.2.6. Reading: Cost function intuition I</a></li>
<li><a href="#org84553b9">3.2.7. Video: Cost function intuition II</a></li>
<li><a href="#orgd7fc1d7">3.2.8. Reading: Cost function intuition II</a></li>
</ul>
</li>
<li><a href="#orga09c680">3.3. Parameter learning</a>
<ul>
<li><a href="#org7e160d4">3.3.1. Video: Gradient descent</a></li>
<li><a href="#orgce8029c">3.3.2. Reading: Gradient descent</a></li>
<li><a href="#org9613d23">3.3.3. Video: Gradient descent intuition</a></li>
<li><a href="#orge769493">3.3.4. Reading: Gradient descent intuition</a></li>
<li><a href="#org0bde613">3.3.5. Video: Gradient descent for linear regression</a></li>
<li><a href="#orgacbc2f4">3.3.6. Reading: Gradient descent for linear regression</a></li>
</ul>
</li>
<li><a href="#org81f0f33">3.4. Linear Algebra review</a>
<ul>
<li><a href="#orgd94fd3f">3.4.1. Video: Matrix vector multiplication</a></li>
<li><a href="#orgbe22c08">3.4.2. Video: Matrix matrix multiplication</a></li>
<li><a href="#org7569932">3.4.3. Video: Inverse and transpose</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge3390a5">4. Semana 2</a>
<ul>
<li><a href="#org679e75c">4.1. Environment setup instructions</a></li>
<li><a href="#orgb8eebb4">4.2. Multivariate linear regression</a>
<ul>
<li><a href="#org26b13c6">4.2.1. Video: Multivariate linear regression</a></li>
<li><a href="#org97a975c">4.2.2. Reading: multiple features</a></li>
<li><a href="#org8eb1064">4.2.3. Video: Gradient descent for multiple features</a></li>
<li><a href="#orga263964">4.2.4. Reading: Gradient descent for multiple features</a></li>
<li><a href="#org7ed21f6">4.2.5. Video: Gradient descent in practice I - Feature scaling</a></li>
<li><a href="#orgf793a1d">4.2.6. Reading: Gradient descent in practice I - Feature scaling</a></li>
<li><a href="#org68572af">4.2.7. Video: Gradient descent in practice II - Learning rate</a></li>
<li><a href="#orgd9eb9c2">4.2.8. Reading: Gradient descent in practice II - Learning rate</a></li>
<li><a href="#org4552c44">4.2.9. Video: Features and polynomial regression</a></li>
<li><a href="#org110d4fe">4.2.10. Reading: Features and polynomial regression</a></li>
</ul>
</li>
<li><a href="#orgf9618e0">4.3. Computing parameters analitically</a>
<ul>
<li><a href="#org0b30f7b">4.3.1. Video: Normal equation</a></li>
<li><a href="#org262d9aa">4.3.2. Reading: Normal equation</a></li>
<li><a href="#org33a7014">4.3.3. Video: Normal equation noninvertibility</a></li>
<li><a href="#org5237118">4.3.4. Reading: Normal equation noninvertibility</a></li>
</ul>
</li>
<li><a href="#org161fb92">4.4. Submitting programming assignments</a></li>
<li><a href="#orga9d7624">4.5. Review</a></li>
<li><a href="#org3c6a88e">4.6. Octave/Matlab tutorial</a></li>
<li><a href="#org640dfea">4.7. Review</a>
<ul>
<li><a href="#orgc2a60d4">4.7.1. Programming assignment 1: linear regression</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgbcde6a2">5. Semana 3</a>
<ul>
<li><a href="#orgc9e6775">5.1. Classification and representation</a>
<ul>
<li><a href="#org0087473">5.1.1. Classification</a></li>
<li><a href="#org32cd098">5.1.2. Hypothesis representation</a></li>
<li><a href="#org4d283af">5.1.3. Decision boundary</a></li>
</ul>
</li>
<li><a href="#org572f93e">5.2. Logistic regression model</a>
<ul>
<li><a href="#org1b4cd15">5.2.1. Cost function</a></li>
<li><a href="#org3c462cb">5.2.2. Simplified cost function and gradient descent</a></li>
<li><a href="#orgd697528">5.2.3. Advanced optimization</a></li>
</ul>
</li>
<li><a href="#org1a3cca7">5.3. Multiclass classification</a>
<ul>
<li><a href="#org47bae88">5.3.1. Multiclass classification: one vs all</a></li>
</ul>
</li>
<li><a href="#orgbc2e9f5">5.4. Solving the problem of overfitting</a>
<ul>
<li><a href="#org091891b">5.4.1. The problem of overfitting</a></li>
<li><a href="#org6d3f387">5.4.2. Cost function</a></li>
<li><a href="#orgbe740ec">5.4.3. Regularized linear regression</a></li>
<li><a href="#orga2d872a">5.4.4. Regularized logistic regression</a></li>
</ul>
</li>
<li><a href="#org25a1562">5.5. Review</a>
<ul>
<li><a href="#orgd26e682">5.5.1. Quiz: Regularization</a></li>
<li><a href="#orga9205d9">5.5.2. Programming assignment: logistic regression</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge749bd3">6. Semana 4</a>
<ul>
<li><a href="#orgcbd0f4a">6.1. Motivations</a>
<ul>
<li><a href="#orgab3f764">6.1.1. Non-linear hypotheses</a></li>
<li><a href="#org5d86b8d">6.1.2. Neurons and the brain</a></li>
</ul>
</li>
<li><a href="#orgd595f01">6.2. Neural networks</a>
<ul>
<li><a href="#org0fed566">6.2.1. Model representation I</a></li>
<li><a href="#orgac1da62">6.2.2. Model representation II</a></li>
</ul>
</li>
<li><a href="#org8c0109e">6.3. Applications</a>
<ul>
<li><a href="#org0050235">6.3.1. Examples and intuitions I</a></li>
<li><a href="#org986da8f">6.3.2. Examples and intuitions II</a></li>
<li><a href="#org3c9ffd6">6.3.3. Multiclass classification</a></li>
</ul>
</li>
<li><a href="#orgd8c0e55">6.4. Review</a>
<ul>
<li><a href="#org859fb74">6.4.1. Quiz: Neural networks: representation</a></li>
<li><a href="#orga585301">6.4.2. Programming assignment: multi-class classificatin and neural networks</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org496b1f6">7. Semana 5</a>
<ul>
<li><a href="#org61722f1">7.1. Cost function and backpropagation</a>
<ul>
<li><a href="#org0c6d257">7.1.1. Cost function</a></li>
<li><a href="#orgcb137ed">7.1.2. Backpropagation algorithm</a></li>
<li><a href="#org7e9bf57">7.1.3. Backpropagation intuition</a></li>
</ul>
</li>
<li><a href="#org049ca9d">7.2. Backpropagation in practice</a>
<ul>
<li><a href="#org9263c15">7.2.1. Implementation note: unrolling parameters</a></li>
<li><a href="#org2579f0d">7.2.2. Gradient checking</a></li>
<li><a href="#org2e91635">7.2.3. Random initialization</a></li>
<li><a href="#org7ece90e">7.2.4. Putting it together</a></li>
</ul>
</li>
<li><a href="#org136d323">7.3. Applications of neural networks</a>
<ul>
<li><a href="#orgb311726">7.3.1. Autonomous driving</a></li>
</ul>
</li>
<li><a href="#org8610a77">7.4. Review</a>
<ul>
<li><a href="#orgd8fcdd9">7.4.1. Quiz: Neural networks: learning</a></li>
<li><a href="#org4200daf">7.4.2. Programming assignment: neural network learning</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgbf2cf34">8. Semana 6</a>
<ul>
<li><a href="#orgb10c038">8.1. Evaluating a learning algorithm</a>
<ul>
<li><a href="#orgc223c92">8.1.1. Deciding what to try next</a></li>
<li><a href="#org22e10ad">8.1.2. Evaluating a hypothesis</a></li>
<li><a href="#orga5432e0">8.1.3. Model selection and train/validation/test sets</a></li>
</ul>
</li>
<li><a href="#org32fd80a">8.2. Bias vs variance</a>
<ul>
<li><a href="#orgc5a5813">8.2.1. Diagnosing bias vs variance</a></li>
<li><a href="#org2d8df98">8.2.2. Regularization and bias/variance</a></li>
<li><a href="#orgef2b313">8.2.3. Learning curves</a></li>
<li><a href="#orgb77e221">8.2.4. Deciding what to do next revisited</a></li>
</ul>
</li>
<li><a href="#orgf0045ec">8.3. Review</a>
<ul>
<li><a href="#org7679efd">8.3.1. Quiz: advice for applying machine learning</a></li>
<li><a href="#orgdd50455">8.3.2. Programming assignment: regularized linear regression and bias/variance</a></li>
</ul>
</li>
<li><a href="#orge3732d5">8.4. Building a spam classifier</a>
<ul>
<li><a href="#orga105ce9">8.4.1. Prioritizing what to work on</a></li>
<li><a href="#org8b908ac">8.4.2. Error analysis</a></li>
</ul>
</li>
<li><a href="#org431b8d4">8.5. Handling skewed data</a>
<ul>
<li><a href="#org0f90152">8.5.1. Error metrics for skewed classes</a></li>
<li><a href="#org4a20065">8.5.2. Trading off precision and recall</a></li>
</ul>
</li>
<li><a href="#orga2dc170">8.6. Using large datasets</a>
<ul>
<li><a href="#org896ffb7">8.6.1. Data for machine learning</a></li>
</ul>
</li>
<li><a href="#org6f8aac5">8.7. Review</a>
<ul>
<li><a href="#org04ec7a3">8.7.1. Quiz: machine learning system design</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgc0cdcad">9. Semana 7</a>
<ul>
<li><a href="#orgbb9512e">9.1. Large margin classification</a>
<ul>
<li><a href="#org7526418">9.1.1. Optimization objective</a></li>
<li><a href="#org68506cc">9.1.2. Large margin intuition</a></li>
<li><a href="#org5bc82bd">9.1.3. Mathematics behind large margin classification</a></li>
</ul>
</li>
<li><a href="#orgbd55267">9.2. Kernels</a>
<ul>
<li><a href="#orgc3c8683">9.2.1. Kernels I</a></li>
<li><a href="#orge1ea950">9.2.2. Kernels II</a></li>
</ul>
</li>
<li><a href="#orgcdd4443">9.3. SVMs in practice</a>
<ul>
<li><a href="#orgc764302">9.3.1. Using an SVM</a></li>
</ul>
</li>
<li><a href="#orgb25f6cf">9.4. Review</a>
<ul>
<li><a href="#org75f0d27">9.4.1. Quiz: support vector machines</a></li>
<li><a href="#orgfb4a2d6">9.4.2. Programming assignment SVMs</a></li>
</ul>
</li>
<li><a href="#org76fc964">9.5. Otras cosas</a>
<ul>
<li><a href="#org84c670d">9.5.1. https://www.youtube.com/watch?v=3liCbRZPrZA SVM with polynomial kernel visualization</a></li>
<li><a href="#orgd4ace66">9.5.2. https://ranvir.xyz/blog/svm-support-vector-machines-in-machine-learning/</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org88fd031">10. Semana 8: Unsupervised learning</a>
<ul>
<li><a href="#org04dd254">10.1. Clustering</a>
<ul>
<li><a href="#org731ba36">10.1.1. Unsupervised learning: introduction</a></li>
<li><a href="#org53a9d8b">10.1.2. K-means algorithm</a></li>
<li><a href="#org7cf27bf">10.1.3. Optimization objective</a></li>
<li><a href="#org7140df5">10.1.4. Random initialization</a></li>
<li><a href="#org2e77757">10.1.5. Choosing the number of clusters</a></li>
</ul>
</li>
<li><a href="#org195f42b">10.2. Review</a>
<ul>
<li><a href="#org6c5e15d">10.2.1. Quiz: Unsuperised learning</a></li>
</ul>
</li>
<li><a href="#org67dba36">10.3. Dimensionality reduction</a>
<ul>
<li><a href="#orgf3a26c1">10.3.1. Motivation</a></li>
<li><a href="#org72089d7">10.3.2. Principal component analysis</a></li>
<li><a href="#org04565fd">10.3.3. Appliying PCA</a></li>
<li><a href="#orgc387e07">10.3.4. Review</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org2cd401c">11. Semana 9: Anomaly detection &amp; Recommender systems</a>
<ul>
<li><a href="#org0efb50a">11.1. Anomaly detection</a>
<ul>
<li><a href="#org909db7b">11.1.1. Density estimation</a></li>
<li><a href="#orge655b13">11.1.2. Building an anomaly detection system</a></li>
<li><a href="#org6f1ed60">11.1.3. Multivariate gaussian distribution</a></li>
<li><a href="#orgef590fc">11.1.4. Review</a></li>
</ul>
</li>
<li><a href="#org59e37a1">11.2. Recommender systems</a>
<ul>
<li><a href="#orgc515c35">11.2.1. Predicting movie ratings</a></li>
<li><a href="#org65f9fe1">11.2.2. Collaborative filtering</a></li>
<li><a href="#org9be2c6d">11.2.3. Low rank matrix factorization</a></li>
<li><a href="#orgb0905ea">11.2.4. Review</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>


<div id="outline-container-org6b46073" class="outline-2">
<h2 id="org6b46073"><span class="section-number-2">1</span> Info</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li><a href="https://www.coursera.org/learn/machine-learning">https://www.coursera.org/learn/machine-learning</a></li>
<li><a href="https://www.coursera.org/learn/machine-learning/discussions/all/threads/v2YppY8FEeWIeBJxvl1elQ">Important notes for new ML students</a>
<ul class="org-ul">
<li>Hay más <i>test cases</i> en los Recursos del curso.</li>
<li><b>Hay que usar Octave &gt; 4.0.0</b></li>
<li><a href="https://learner.coursera.help/hc/en-us/articles/209818863-Coursera-Honor-Code">Cousera Honor Code</a></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org6460034" class="outline-2">
<h2 id="org6460034"><span class="section-number-2">2</span> Ideas</h2>
<div class="outline-text-2" id="text-2">
<p>
Ideas mías a lo largo del curso.
</p>

<ol class="org-ol">
<li>Probar <a href="https://github.com/google-research/google-research/blob/master/automl_zero/README.md">AutoML-Zero</a>.</li>
<li>Buscar clusters en espacios transformados y muy transformados. Ej: Fourier, Fourier de Fourier, Cepstrum&#x2026;</li>
</ol>
</div>

<div id="outline-container-orge6fa82c" class="outline-3">
<h3 id="orge6fa82c"><span class="section-number-3">2.1</span> Enlaces</h3>
<div class="outline-text-3" id="text-2-1">
<ol class="org-ol">
<li><a href="http://www.deeplearningbook.org/">http://www.deeplearningbook.org/</a></li>
<li><a href="http://ufldl.stanford.edu/tutorial/">http://ufldl.stanford.edu/tutorial/</a>  Deep Learning Tutorial</li>
<li><a href="https://developers.google.com/machine-learning/crash-course">https://developers.google.com/machine-learning/crash-course</a></li>
<li><a href="https://deeplearning.mit.edu/">https://deeplearning.mit.edu/</a></li>
<li><a href="http://cs229.stanford.edu">http://cs229.stanford.edu</a></li>
</ol>
</div>
</div>
</div>


<div id="outline-container-orgfac42e4" class="outline-2">
<h2 id="orgfac42e4"><span class="section-number-2">3</span> Semana 1</h2>
<div class="outline-text-2" id="text-3">
<p>
Intro, regresión lineal, repaso de Álgebra.
</p>


<ul class="org-ul">
<li><a href="https://www.coursera.org/learn/machine-learning/discussions/weeks/1/threads/hAp4LT1SEeaL_xIEq4QdBw">FAQ de la semana 1</a></li>
</ul>
</div>

<div id="outline-container-org818b3ba" class="outline-3">
<h3 id="org818b3ba"><span class="section-number-3">3.1</span> Introduction</h3>
<div class="outline-text-3" id="text-3-1">
</div>
<div id="outline-container-org9a1f52a" class="outline-4">
<h4 id="org9a1f52a"><span class="section-number-4">3.1.1</span> Video: Welcome</h4>
</div>

<div id="outline-container-org25c8b66" class="outline-4">
<h4 id="org25c8b66"><span class="section-number-4">3.1.2</span> Video: What is Machine Learning</h4>
<div class="outline-text-4" id="text-3-1-2">
<ul class="org-ul">
<li>Los algoritmos más importantes son el aprendizaje supervisado y el aprendizaje no supervisado. Es esta además la clasificación más general de algoritmos.
<ul class="org-ul">
<li>Otros son el aprendizaje por refuerzo y los sistemas de recomendación.</li>
</ul></li>
<li>Hay que aprender las herramientas, pero <b>es muy importante saber cómo y cuándo usarlas</b>.</li>
<li>Sea una máquina que debe hacer una tarea T, con un desempeño P y que la exponemos a experiencias (instancias) E de esa tarea T. Se dice que la computadora aprende si su desempeño P en la tarea T <i>aumenta proporcionalmente a la cantidad de experiencias E</i>.</li>
<li>Otra definición de aprendizaje automático es la capacidad (de la computadora) de aprender a resolver problemas para los que no fue programada. ~</li>
</ul>
</div>
</div>

<div id="outline-container-orgc27371e" class="outline-4">
<h4 id="orgc27371e"><span class="section-number-4">3.1.3</span> Reading: What is Machine Learning?</h4>
</div>

<div id="outline-container-orgbc40ee3" class="outline-4">
<h4 id="orgbc40ee3"><span class="section-number-4">3.1.4</span> Video: Supervised Learning</h4>
<div class="outline-text-4" id="text-3-1-4">
<ul class="org-ul">
<li>En el aprendizaje supervisado, le mostramos al programa ejemplos de entradas y sus correspondientes salidas/respuestas correctas. Ya sabemos cómo son las respuestas corectas; tenemos la idea de que hay una relación entre las entradas y las salidas. Dado un conjunto de entradas y salidas, intentamos obtener un modelo que permita predecir/inferir las salidas a nuevos datos de entrada.</li>
<li>Los problemas de aprendizaje supervisado se clasifican en problemas de regresión y de clasificación:
<ul class="org-ul">
<li>Problema de <b>regresión</b> si el conjunto imagen es continuo. La salida es una variable numérica.</li>
<li>Problema de <b>clasificación</b> si el conjunto imagen es discreto. La salida es una variable categórica.</li>
</ul></li>
<li>Los algoritmos de Máquinas de Vector Soporte permiten <i><b>infinitos</b></i> valores de entrada.</li>
</ul>
</div>

<ol class="org-ol">
<li><a id="orgccf2857"></a><span class="todo TODO">TODO</span> Leer <a href="https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression">https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression</a><br /></li>

<li><a id="org2e5faa0"></a><span class="todo TODO">TODO</span> Leer <a href="https://datascience.stackexchange.com/questions/25298/how-to-know-when-to-treat-a-problem-as-a-classification-task-or-a-regression-tas">https://datascience.stackexchange.com/questions/25298/how-to-know-when-to-treat-a-problem-as-a-classification-task-or-a-regression-tas</a><br /></li>
</ol>
</div>

<div id="outline-container-orgd4fff1f" class="outline-4">
<h4 id="orgd4fff1f"><span class="section-number-4">3.1.5</span> Video: Unsupervised Learning</h4>
<div class="outline-text-4" id="text-3-1-5">
<ul class="org-ul">
<li>En el aprendizaje no supervisado, le damos datos al programa con la intención de encontrar estructuras subyacentes, patrones.</li>
<li>Un ejemplo típico es el <i>clustering</i> o agrupamiento de datos.</li>
<li>En el ejemplo de sonido Cocktail Party, según <a href="https://www.coursera.org/learn/machine-learning/discussions/weeks/1/threads/hAp4LT1SEeaL_xIEq4QdBw">FAQ de la semana 1</a>, lo que usan es <i>Principal Component Analysis, PCA, a mathematical trick that takes two sets of correlated data, and returns two new sets of data that are not correlated.</i> No lo había visto así antes, creo&#x2026;</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org1c763e4" class="outline-3">
<h3 id="org1c763e4"><span class="section-number-3">3.2</span> Model and cost function</h3>
<div class="outline-text-3" id="text-3-2">
<p>
Vemos la regresión lineal como primer algoritmo de aprendizaje supervisado.
</p>
</div>

<div id="outline-container-orgfad501a" class="outline-4">
<h4 id="orgfad501a"><span class="section-number-4">3.2.1</span> Video: Model representation</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
Un poco de nomenclatura:
</p>

<ul class="org-ul">
<li>\(m\): cantidad de ejemplos de entrenamiento.</li>
<li>\(\vec{x}\): entradas / descriptores / <i>features</i></li>
<li>\(\vec{y}\): salidas. \(\hat{\vec{y}}\) son las salidas estimadas.</li>
<li>\(h_\theta\): función de hipótesis, de estimación. Tiene parámetros \(\vec{\theta}\). Entonces tenemos que \( \hat{y}^{(i)} = h_\theta(x^{(i)}) = h(x,\theta) \)</li>
<li>\(x^{(i)}\): entrada $i$-ésima del vector de entradas, con índices empezando en 1.
<ul class="org-ul">
<li>\((x^{(i)},y^{(i)})\) es un ejemplo de entrenamiento.</li>
</ul></li>
<li>Para regresión lineal de una variable tenemos entonces</li>
</ul>
<p>
\[ \hat{y}^{(i)} = h_\theta(x^{(i)}) = \theta_0 + \theta_1 * x^{(i)} \]
</p>
</div>
</div>

<div id="outline-container-org1efd2e7" class="outline-4">
<h4 id="org1efd2e7"><span class="section-number-4">3.2.2</span> Reading: Model representation</h4>
<div class="outline-text-4" id="text-3-2-2">
<ul class="org-ul">
<li>\(X\): el espacio de los valores de entrada.</li>
<li>\(Y\): el espacio de los valores de salida.</li>
<li>El objetivo del aprendizaje supervisado es encontrar una función \(h: X \rightarrow Y\) que sea buena prediciendo salidas a partir de entradas.</li>
</ul>
</div>
</div>

<div id="outline-container-orgc8783f8" class="outline-4">
<h4 id="orgc8783f8"><span class="section-number-4">3.2.3</span> Video: Cost function</h4>
<div class="outline-text-4" id="text-3-2-3">
<p>
Formalizamos el problema del aprendizaje como la minimización de una función de costo \(J(\vec{\theta})\). La función de costo habitual y recomendada para problemas de regresión lineal es el <b>error cuadrático medio</b> (<a href="https://en.wikipedia.org/wiki/Mean_squared_error"><i>Mean Squared Error</i></a> o <i>Mean Squared Deviation</i>).
</p>

<p>
Para un predictor como lo es \(h_\theta\), el MSE se define como
\[ MSE = \frac{1}{N} (\sum_{1}^{N}Y_i - \hat{Y}_i )^2\]
</p>

<p>
En nuestro caso vamos a definir a la función de costo para este problema de regresión lineal univariable como
</p>

<p>
\[ J(\theta_0 , \theta_1) = \frac{1}{2m} \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} )^2  \]
\[ J(\theta_0 , \theta_1) =  \frac{1}{2m} \sum_{i=1}^m( \theta_0 + \theta_1 * x^{(i)} - y^{(i)} )^2 \]
</p>

<ul class="org-ul">
<li>El factor \(1/2\) es para ahorrar cálculos, puesto que en redes neuronales al hacer <i>backpropagation</i> o <i>gradient descent</i> hay que derivar esta función de error y entonces con este \(1/2\) simplificamos el \(2\) de la derivada del cuadrado.</li>
</ul>

<p>
La optimización es entonces encontrar los parámetros \(\theta\) que minimizan la función de costo:
\[ \underset{\theta_0 , \theta_1}{\text{min}}  J(\theta_0 , \theta_1)\]
</p>

<hr />

<p>
<i>En las notas del curso encontramos la forma matricial, que luego usamos para hacer descenso por el gradiente de forma matricial. Lo pongo acá por completitud</i>.
</p>

<p>
MSE: \[ J(\theta) = \frac{1}{2m} (X\times\theta-Y)^T(X\times\theta-Y)  \]
</p>

<p>
El producto implica la sumatoria y el cuadrado elemento a elemento.
</p>

<hr />
</div>
</div>

<div id="outline-container-org1c8cbb0" class="outline-4">
<h4 id="org1c8cbb0"><span class="section-number-4">3.2.4</span> Reading: Cost function</h4>
</div>

<div id="outline-container-org3bc2d13" class="outline-4">
<h4 id="org3bc2d13"><span class="section-number-4">3.2.5</span> Video: Cost function intuition I</h4>
</div>

<div id="outline-container-org1047348" class="outline-4">
<h4 id="org1047348"><span class="section-number-4">3.2.6</span> Reading: Cost function intuition I</h4>
</div>

<div id="outline-container-org84553b9" class="outline-4">
<h4 id="org84553b9"><span class="section-number-4">3.2.7</span> Video: Cost function intuition II</h4>
</div>

<div id="outline-container-orgd7fc1d7" class="outline-4">
<h4 id="orgd7fc1d7"><span class="section-number-4">3.2.8</span> Reading: Cost function intuition II</h4>
<div class="outline-text-4" id="text-3-2-8">
<p>
De <a href="https://es.wikipedia.org/wiki/Isol%C3%ADnea">isolíneas / curvas de nivel</a>.
</p>
</div>
</div>
</div>


<div id="outline-container-orga09c680" class="outline-3">
<h3 id="orga09c680"><span class="section-number-3">3.3</span> Parameter learning</h3>
<div class="outline-text-3" id="text-3-3">
</div>
<div id="outline-container-org7e160d4" class="outline-4">
<h4 id="org7e160d4"><span class="section-number-4">3.3.1</span> Video: Gradient descent</h4>
<div class="outline-text-4" id="text-3-3-1">
<p>
El descenso por el gradiente es un algoritmo de optimización que vamos a usar (entre otras cosas) para minimizar la función de costo.
</p>

<p>
Hacer \[ \vec{\theta}[n+1] := \vec{\theta}[n] - \alpha \frac{\partial J(\vec{\theta})}{\partial\theta}  \]
</p>

<p>
(expresado de otra manera)
</p>

<p>
\[ {\theta}_j[n+1] := {\theta}_j[n] - \alpha \frac{\partial J(\vec{\theta})}{\partial\theta}  \]
</p>

<p>
Hasta la convergencia de \(\vec{\theta}\), equivalente a la convergencia de \(J(\vec{\theta})\):
</p>

<p>
\[  \vec{\theta}[n] - \vec{\theta}[n-1] < \vec{\epsilon} \]
\[ J(\vec{\theta}[n]) - J(\vec{\theta}[n-1])  < \epsilon  \]
</p>

<ul class="org-ul">
<li>Nomenclatura: usamos \(:=\) como operador de asignación.</li>
<li>\(\alpha\) es la tasa de aprendizaje o <i>learning rate</i> del algoritmo.</li>
</ul>

<p>
Para calcular la derivada hacemos derivadas parciales. Actualizamos los parámetros simultáneamente en cada paso. Si actualizamos de a uno y recalculamos estamos haciendo otro algoritmo, que probablemente también converja pero es distinto.
</p>

<p>
Cuando la función de costo es el error cuadrático medio (<i>MSE</i>), la fórmula de actualización queda:
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n] - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)}  \]
</p>

<ul class="org-ul">
<li>El primer termino de la sumatoria es la magnitud y dirección del error.</li>
<li>El segundo término de la sumatoria es la sensibilidad de J respecto al parámetro, y resulta ser igual a la magnitud del descriptor asociado a ese parámetro.</li>
</ul>

<hr />

<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=WnqQrPNYz5Q">Un video de <i>gradient descent</i> sugerido en las notas del curso</a>.</li>
</ul>
</div>
</div>

<div id="outline-container-orgce8029c" class="outline-4">
<h4 id="orgce8029c"><span class="section-number-4">3.3.2</span> Reading: Gradient descent</h4>
</div>

<div id="outline-container-org9613d23" class="outline-4">
<h4 id="org9613d23"><span class="section-number-4">3.3.3</span> Video: Gradient descent intuition</h4>
<div class="outline-text-4" id="text-3-3-3">
<ul class="org-ul">
<li>Si \(\alpha\) es muy grande, el algoritmo puede oscilar o incluso diverger.</li>
<li>Si \(\alpha\) es muy chica, puede tardar mucho en converger.</li>
<li>Con \(\alpha\) fija, los "pasos" que da el algoritmo son cada vez más chicos a medida que la función de costo se aproxima a un mínimo local.</li>
</ul>
</div>
</div>

<div id="outline-container-orge769493" class="outline-4">
<h4 id="orge769493"><span class="section-number-4">3.3.4</span> Reading: Gradient descent intuition</h4>
</div>

<div id="outline-container-org0bde613" class="outline-4">
<h4 id="org0bde613"><span class="section-number-4">3.3.5</span> Video: Gradient descent for linear regression</h4>
<div class="outline-text-4" id="text-3-3-5">
<p>
Dice Andrew cerca del minuto 4:40:
</p>

<blockquote>
<p>
But, it turns out that that the cost function for
linear regression is always going to be a bow shaped function like this.
The technical term for this is that this is called a convex function.
</p>
</blockquote>

<p>
¿Por qué?
</p>

<ul class="org-ul">
<li>La función de costo \(J(\vec{\theta})\) es el error cuadrático medio (MSE).</li>
<li>El MSE es cuadrático respecto a los parámetros siempre y cuando estos sean lineales, de grado 1. <b>La función de hipótesis debe ser lineal respecto a los parámetros para que la función de costo sea cuadrática</b>.
<ul class="org-ul">
<li>Sea por ejemplo \[ h(x,y) =  a.x^2 + b.y^2 - c.x^2 y^2 \]. Esta función tiene más de un mínimo.</li>
</ul></li>
</ul>


<div class="figure">
<p><img src="imgs/001-01-nolineal.gif" alt="001-01-nolineal.gif" />
</p>
</div>

<ul class="org-ul">
<li>Su MSE quedaría algo como \[ x^4 + 2 x^2 y^2 - 2 x^4 y^2 + y^4 - 2 x^2 y^4 + x^4 y^4  \] (sólo <a href="https://www.wolframalpha.com/input/?i=%28x%5E2+%2B+y%5E2+-+x%5E2y%5E2%29%5E2">la elevé al cuadrado</a>)</li>
</ul>


<div class="figure">
<p><img src="imgs/001-02-nolineal-cuadrado.gif" alt="001-02-nolineal-cuadrado.gif" />
</p>
</div>

<hr />

<p>
Hay otras formas de estimar los parámetros (regresores). Una de ellas es el método de los mínimos cuadrados (<a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">/Ordinary Least Squares</a>/). El descenso por el gradiente es más fácil de computar que OLS, en el caso de datasets grandes.
</p>

<p>
En realidad todo lo que vimos es descenso por el gradiente por lotes, o <b><i>batch gradient descent</i></b>, que es cuando la función de costo se optimiza usando todas las entradas disponibles. Esto es costoso.
</p>
</div>



<ol class="org-ol">
<li><a id="org7339f46"></a><span class="todo TODO">TODO</span> Leer más de <a href="https://en.wikipedia.org/wiki/Linear_regression">regresión lineal</a><br /></li>
</ol>



<li><a id="orge68266d"></a>Regresión lineal<br /></li>
</ol>
</div>



<div id="outline-container-orgacbc2f4" class="outline-4">
<h4 id="orgacbc2f4"><span class="section-number-4">3.3.6</span> Reading: Gradient descent for linear regression</h4>
</div>
</div>

<div id="outline-container-org81f0f33" class="outline-3">
<h3 id="org81f0f33"><span class="section-number-3">3.4</span> Linear Algebra review</h3>
<div class="outline-text-3" id="text-3-4">
</div>
<div id="outline-container-orgd94fd3f" class="outline-4">
<h4 id="orgd94fd3f"><span class="section-number-4">3.4.1</span> Video: Matrix vector multiplication</h4>
<div class="outline-text-4" id="text-3-4-1">
<ul class="org-ul">
<li>Más adelante vamos a ver por qué es mejor vectorizar calculos en lugar de iterar.</li>
<li>Hace un truco interesante que es incluir a la ordenada al origen dentro del vector de parámetros &#x2014;en realidad está bien, es un parámetr calculado&#x2014;, y luego introduce una columna de \(1\)s en la matriz de entradas.
<ul class="org-ul">
<li>La alternativa es sumar la columna aparte. \(A*X + B\)</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgbe22c08" class="outline-4">
<h4 id="orgbe22c08"><span class="section-number-4">3.4.2</span> Video: Matrix matrix multiplication</h4>
<div class="outline-text-4" id="text-3-4-2">
<ul class="org-ul">
<li>Acá hace el mismo truco pero para hacer varias predicciones a la vez: usa varios modelos y varias entradas.</li>
</ul>
</div>
</div>

<div id="outline-container-org7569932" class="outline-4">
<h4 id="org7569932"><span class="section-number-4">3.4.3</span> Video: Inverse and transpose</h4>
<div class="outline-text-4" id="text-3-4-3">
<p>
Interesante:
</p>
<blockquote>
<p>
But the intuition if you want is that you can think of matrices as not have an inverse that is somehow too close to zero in some sense.
</p>
</blockquote>

<ul class="org-ul">
<li>Las matrices que no tienen inversa son matrices <i>singulares</i> o <i>degeneradas</i>.
<ul class="org-ul">
<li>Asumo que se refiere a matrices cuadradas, que podrían tener inversa.</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-orge3390a5" class="outline-2">
<h2 id="orge3390a5"><span class="section-number-2">4</span> Semana 2</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org679e75c" class="outline-3">
<h3 id="org679e75c"><span class="section-number-3">4.1</span> Environment setup instructions</h3>
</div>

<div id="outline-container-orgb8eebb4" class="outline-3">
<h3 id="orgb8eebb4"><span class="section-number-3">4.2</span> Multivariate linear regression</h3>
<div class="outline-text-3" id="text-4-2">
</div>
<div id="outline-container-org26b13c6" class="outline-4">
<h4 id="org26b13c6"><span class="section-number-4">4.2.1</span> Video: Multivariate linear regression</h4>
<div class="outline-text-4" id="text-4-2-1">
<p>
En la regresión lineal multivariable o regresión lineal múltiple, tenemos varios valores de entrada o descriptores. Para tener una notación más compacta y conveniente, vamos a definir:
</p>
<ul class="org-ul">
<li>\(\theta_0=1\) ;</li>
<li>\(n\) es la cantidad de entradas, descriptores;</li>
<li>vamos a usar \(\vec{\theta}\) con índice \(0\);</li>
<li>y \(\vec{\theta}_j^{(i)}\) es el elemento j-ésimo del ejemplo i-ésimo.</li>
</ul>

<p>
Entonces \(\vec{\theta}\) tiene \(n+1\) elementos y  \[ \vec{\theta} = 1 + \theta_1 + \theta_2 + \dots + \theta_n  \]
</p>


<p>
Y luego \[ \vec{h_\theta}(\vec{x}) = \vec{\theta}^T \cdot \vec{x}  = \vec{x}^T \cdot \vec{\theta}  \]
</p>

<ul class="org-ul">
<li>Intuición para el ejemplo de estimar el precio de un inmueble: \(\theta_0\) es el precio base.</li>
</ul>

<hr />

<p>
<i>En <a href="#org0b30f7b">4.3.1</a> se introduce notación matricial que luego en el ejercicio 1 usamos para expresar todo de forma vectorizada. Dejo todo acá para más completitud</i>.
</p>

<p>
\[ \hat{Y}(&theta;,X) = X &theta;  ]\
</p>

<hr />
</div>
</div>

<div id="outline-container-org97a975c" class="outline-4">
<h4 id="org97a975c"><span class="section-number-4">4.2.2</span> Reading: multiple features</h4>
</div>

<div id="outline-container-org8eb1064" class="outline-4">
<h4 id="org8eb1064"><span class="section-number-4">4.2.3</span> Video: Gradient descent for multiple features</h4>
<div class="outline-text-4" id="text-4-2-3">
<p>
La regla de actualización era:
</p>

<p>
\[ \vec{\theta}[n+1] := \vec{\theta}[n] - \alpha \frac{\partial J(\vec{\theta})}{\partial\theta}  \]
</p>

<p>
Y para cuando la función de costo es el error cuadrático medio (MSE), queda (para actualización con <b>todos los \(m\) ejemplos</b>):
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n] - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)}  \]
</p>

<ul class="org-ul">
<li>Puedo ver el factor de avance luego de \(\alpha\) como el aporte al error medio que hizo el descriptor \(x_j\) .
<ul class="org-ul">
<li>El producto vectorial y la resta son el error medio para ese vector de entrada.</li>
<li>El factor \(x_j\) es el aporte de ese elemento, en esa dirección.
<ul class="org-ul">
<li>La dirección final es la suma vectorial de los elementos.</li>
</ul></li>
</ul></li>
</ul>

<hr />

<p>
<i>La versión vectorizada/matricial del algoritmo está en las notas del curso y después la usamos en el ejercicio de programación 1. La dejo acá por completitud</i>.
</p>

<p>
\[ \theta_{n \times 1}[i+1] = \theta_{n \times 1}[i] - \frac{\alpha}{m} X_{m \times n}^T (X_{m \times n} \theta_{n \times 1} - Y_{m \times 1} )_{m \times 1} \]
\[ \theta_{}[i+1] = \theta[i] - \frac{\alpha}{m} X^T (X \theta - Y) \]
</p>

<hr />
</div>

<ol class="org-ol">
<li><a id="orgb844e62"></a><span class="todo TODO">TODO</span> EL ERROR ES MAYPR CUANDO HAY CORRELACIÓN ENTRE DESCRIPTORES Y PARÁMETROS.<br /></li>
</ol>
</div>

<div id="outline-container-orga263964" class="outline-4">
<h4 id="orga263964"><span class="section-number-4">4.2.4</span> Reading: Gradient descent for multiple features</h4>
</div>

<div id="outline-container-org7ed21f6" class="outline-4">
<h4 id="org7ed21f6"><span class="section-number-4">4.2.5</span> Video: Gradient descent in practice I - Feature scaling</h4>
<div class="outline-text-4" id="text-4-2-5">
<ul class="org-ul">
<li>Al parecer, el algoritmo de descenso por el gradiente converge <b>bastante más rápidamente</b> si los descriptores están en el mismo orden de magnitud.
<ul class="org-ul">
<li>Andrew propone que estén <i>más o menos</i> en el rango \(-3 < x_j < 3\) y duda si \(-\frac{1}{3} < x < \frac{1}{3}\)</li>
</ul></li>
<li>Para esto se suele normalizar cada descriptor respecto al rango de sí mismo en la muestra (los m ejemplos de entrada) o respecto a la desviación estándar. Esto se llama <b><i>feature scaling</i></b>.</li>
<li>Otra práctica habitual es centrar en cero los valores, para lo cual se resta la media de la muestra. Esto se llama <b><i>mean normalization</i></b>.</li>
</ul>
</div>

<ol class="org-ol">
<li><a id="orgd3eec07"></a>Más de feature scaling y mean normalization<br />
<div class="outline-text-5" id="text-4-2-5-1">
<p>
De la ecuación de actualización de los parámetros de la ecuación de hipótesis
infiero que el vector se mueve <span class="underline">más rápidamente</span> en dirección de los parámetros
más grandes. Sin embargo en <a href="#orgf793a1d">4.2.6</a> dice:
</p>

<blockquote>
<p>
This is because θ will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.
</p>
</blockquote>
</div>

<ol class="org-ol">
<li><a id="org1366fdd"></a><span class="done DONE">DONE</span> Averiguar más de esto. ¿Por qué se hace? ¿Tienen que ser de la misma magnitud o ser chicos?<br />
<div class="outline-text-7" id="text-4-2-5-1-0-1">
<ul class="org-ul">
<li>Ver <a href="https://www.robertoreif.com/blog/2017/12/21/importance-of-feature-scaling-in-data-modeling-part-2">https://www.robertoreif.com/blog/2017/12/21/importance-of-feature-scaling-in-data-modeling-part-2</a></li>
<li>Ver <a href="https://math.stackexchange.com/questions/2341704/feature-scalings-effect-on-gradient-descent">https://math.stackexchange.com/questions/2341704/feature-scalings-effect-on-gradient-descent</a></li>
</ul>

<p>
Estaba entendiendo mal las curvas de nivel. El eje corto de las elipses es el asociado a los descriptores más grandes, con más rango. Son curvas de nivel de \(J(\theta)\), no de \(J(x)\).  Ahora si estoy de acuerdo.
</p>

<p>
En regresión lineal (quizás puedo generalizarlo a cualquiera) <b>los parámetros tienen rangos "inversos" a los de los descriptores que multiplican</b>. Si un descriptor tiene un rango grande, entonces su parámetro asociado va a tener un rango chico.
</p>

<p>
<span class="underline">Se podría solucionar también con learning rates diferenciados: más grandes para los descriptores de más rango, más chicos para los de menos rango.</span>
</p>

<p>
¡Lo que dice en <a href="#orgf793a1d">4.2.6</a> está mal expresado entonces!
</p>
</div>
</li>

<li><a id="org4309aa0"></a><span class="todo TODO">TODO</span> Corregir <a href="https://math.stackexchange.com/questions/2341704/feature-scalings-effect-on-gradient-descent">https://math.stackexchange.com/questions/2341704/feature-scalings-effect-on-gradient-descent</a><br /></li>
</ol>
</li>
</ol>
</div>

<div id="outline-container-orgf793a1d" class="outline-4">
<h4 id="orgf793a1d"><span class="section-number-4">4.2.6</span> Reading: Gradient descent in practice I - Feature scaling</h4>
</div>


<div id="outline-container-org68572af" class="outline-4">
<h4 id="org68572af"><span class="section-number-4">4.2.7</span> Video: Gradient descent in practice II - Learning rate</h4>
<div class="outline-text-4" id="text-4-2-7">
<ul class="org-ul">
<li>Si la función de costo \(J(\vec{\theta})\) diverge u oscila, entonces mi tasa de aprendizaje \(\alpha\) es muy grande. Si es muy chica, converge lentamente.</li>
<li>Puedo verlo graficando la función de costo.</li>
<li>Elegir el valor de \(\alpha\) es, a priori, por prueba y error. <b><i>¿Habrá heurísticas para determinar un buen valor inicial?</i></b></li>
<li>La condición de convergencia también suele depender del problema. Andrew habla de valores absolutos&#x2026; <b><i>¿por qué no usar un \(\epsilon\) relativo?</i></b></li>
</ul>
</div>
</div>

<div id="outline-container-orgd9eb9c2" class="outline-4">
<h4 id="orgd9eb9c2"><span class="section-number-4">4.2.8</span> Reading: Gradient descent in practice II - Learning rate</h4>
</div>


<div id="outline-container-org4552c44" class="outline-4">
<h4 id="org4552c44"><span class="section-number-4">4.2.9</span> Video: Features and polynomial regression</h4>
</div>

<div id="outline-container-org110d4fe" class="outline-4">
<h4 id="org110d4fe"><span class="section-number-4">4.2.10</span> Reading: Features and polynomial regression</h4>
<div class="outline-text-4" id="text-4-2-10">
<ul class="org-ul">
<li>La regresión lineal es ajustar un modelo lineal, de grado 1, una combinación lineal entre las entradas y parámetros.</li>
<li>Podemos ajustar modelos no lineales como hipótesis si codificamos estas no linealidades dentro de los descriptores. Por ejemplo, para el caso de la estimación de precios de casas, un posible descriptor podría ser el cuadrado del área, y ahí estamos incluyendo algo cuadrático en el modelo.</li>
<li>Al incluir las no linealidades en los descriptores, pero todavía usando los parámetros como multiplicadores de orden 1, podemos seguir usando el descenso por el gradiente para optimizar.</li>
<li>Andrew habla también de usar relaciones entre entradas básicas para construir otras entradas. Por ejemplo, el producto de dos descriptores hace un nuevo descriptor que codifica otra relación.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgf9618e0" class="outline-3">
<h3 id="orgf9618e0"><span class="section-number-3">4.3</span> Computing parameters analitically</h3>
<div class="outline-text-3" id="text-4-3">
</div>
<div id="outline-container-org0b30f7b" class="outline-4">
<h4 id="org0b30f7b"><span class="section-number-4">4.3.1</span> Video: Normal equation</h4>
<div class="outline-text-4" id="text-4-3-1">
<ul class="org-ul">
<li>Otra forma de optimizar la regresión lineal es resolverla analíticamente con el método de los <a href="https://en.wikipedia.org/wiki/Least_squares">mínimos cuadrados</a> <a href="https://en.wikipedia.org/wiki/Linear_least_squares">lineales</a> / ecuación normal. Esto da la solución óptima (que existe porque hemos dicho que para regresión lineal es un espacio de búsqueda cónvexo con un solo mínimo).</li>
</ul>

<p>
\[  \vec{\theta} = ( X^T \times X )^{-1} \times X^T \times \vec{y}   \]
</p>

<p>
\[ X = \left[  x^{(i)}  \right]  \]
</p>

<ul class="org-ul">
<li>A \(X\) la llamamos <b><i>matriz de diseño</i></b>. Cada fila es un ejemplo, y tiene tamaño $m &times; n+1 $</li>

<li>La complejidad de invertir una matriz es \(O(n^3)\) y esto se pone lento para \(n > 10^5\). La complejidad del descenso por el gradiente, en cambio, es de \(O(k \cdot n^2)\).</li>

<li>\(( X^T \times X )^{-1} \times X^T = X^{+}\) es la <span class="underline"><a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">pseudoinversa</a></span> de \(X\), y el método de mínimos cuadrados no es más que una solución (óptima en el sentido del error cuadrático) de un sistema de ecuaciones sobredeterminado.

<ul class="org-ul">
<li>La pseudoinversa se puede calcular con <i>Singular Value Decomposition</i> o Descomposición QR, por ejemplo.</li>

<li>La regresión por mínimos cuadrados asume muchas cosas que no necesariamente siempre se cumplen. Ver la <a href="https://en.wikipedia.org/wiki/Robust_regression">regresión robusta</a> como alternativa.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org262d9aa" class="outline-4">
<h4 id="org262d9aa"><span class="section-number-4">4.3.2</span> Reading: Normal equation</h4>
</div>

<div id="outline-container-org33a7014" class="outline-4">
<h4 id="org33a7014"><span class="section-number-4">4.3.3</span> Video: Normal equation noninvertibility</h4>
<div class="outline-text-4" id="text-4-3-3">
<p>
Si \(( X^T \times X )\) no es invertible, entonces puede haber 2 problemas:
</p>

<ol class="org-ol">
<li>El sistema esta subdeterminado. Faltan ejemplos, \(m < n\) / tenemos muchos descriptores.
<ul class="org-ul">
<li>Después vamos a ver que se soluciona con <i>regularización</i>.</li>
</ul></li>
<li>Algunos descriptores están muy correlacionados / son linealmente dependientes.</li>
</ol>

<p>
Si no es invertible naturalmente (es singular o degenerada) igual se puede invertir con la pseudoinversa. Igual esto no sería problema si hubiésemos usado la pseudoinversa desde un principio en lugar de estar haciéndolo manualmente. Y, nuevamente, seguro hay métodos más robustos (aunque no hay que dejar de hacer análisis de la información con la que contamos).
</p>
</div>
</div>

<div id="outline-container-org5237118" class="outline-4">
<h4 id="org5237118"><span class="section-number-4">4.3.4</span> Reading: Normal equation noninvertibility</h4>
</div>
</div>


<div id="outline-container-org161fb92" class="outline-3">
<h3 id="org161fb92"><span class="section-number-3">4.4</span> Submitting programming assignments</h3>
</div>

<div id="outline-container-orga9d7624" class="outline-3">
<h3 id="orga9d7624"><span class="section-number-3">4.5</span> Review</h3>
</div>

<div id="outline-container-org3c6a88e" class="outline-3">
<h3 id="org3c6a88e"><span class="section-number-3">4.6</span> Octave/Matlab tutorial</h3>
<div class="outline-text-3" id="text-4-6">
<div class="org-src-container">
<pre class="src src-octave"><span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Para ver una matriz/vector como p&#237;xeles con color</span>
A <span style="color: #4f97d7;">=</span> magic<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">9</span><span style="color: #4f97d7;">)</span>
figure
imagesc<span style="color: #4f97d7;">(</span>A<span style="color: #4f97d7;">)</span>
colorbar
colormap gray
</pre>
</div>
</div>
</div>


<div id="outline-container-org640dfea" class="outline-3">
<h3 id="org640dfea"><span class="section-number-3">4.7</span> Review</h3>
<div class="outline-text-3" id="text-4-7">
</div>
<div id="outline-container-orgc2a60d4" class="outline-4">
<h4 id="orgc2a60d4"><span class="section-number-4">4.7.1</span> Programming assignment 1: linear regression</h4>
<div class="outline-text-4" id="text-4-7-1">
<ul class="org-ul">
<li>Mi gradient descent convergía pero no al mismo resultado exacto, y más rápida o lentamente. Me faltaba el factor \(1/m\).</li>
<li>Armé una versión vectorizada del gradient descent pero es distinta a la propuesta:</li>
</ul>

<p>
La mía:
</p>

<ul class="org-ul">
<li>usé \(n\) como la longitud de \(\theta\), incluyendo los \(1\)s.</li>
</ul>

<div class="org-src-container">
<pre class="src src-octave">M <span style="color: #4f97d7;">=</span> length<span style="color: #4f97d7;">(</span>y<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span> <span style="color: #2aa1ae; background-color: #292e34;">% number of training examples</span>
N <span style="color: #4f97d7;">=</span> length<span style="color: #4f97d7;">(</span>theta<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
error <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span>X <span style="color: #4f97d7;">*</span> theta<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">-</span> y<span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% Mx1</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">ponderated_error = repmat(error, [1, N]) .* X;  % MxN</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">ponderated_error = error * ones(1,n) * X  % MxN, equivale al broadcasting</span>
ponderated_error <span style="color: #4f97d7;">=</span> error <span style="color: #4f97d7;">.*</span> X<span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% Broadcasting. MxN</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">gradient = sum(ponderated_error,1);  % 1xN</span>
gradient <span style="color: #4f97d7;">=</span> ones<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">,</span>M<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> ponderated_error<span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% 1xN, equivalente a la sumatoria</span>
theta <span style="color: #4f97d7;">=</span> theta <span style="color: #4f97d7;">-</span> <span style="color: #4f97d7;">(</span>alpha<span style="color: #4f97d7;">/</span>M<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> gradient<span style="color: #4f97d7;">';</span>  <span style="color: #2aa1ae; background-color: #292e34;">% Nx1</span>
</pre>
</div>

<p>
\[ \theta_{n \times 1}[i+1] = \theta_{n \times 1}[i] - \frac{\alpha}{m} \left[ 1_{1 \times m} \left( X_{m \times n} \theta_{n \times 1} - Y_{m \times 1} \right)_{m \times 1} 1_{1 \times n} X_{m \times n} \right]^T  \]
</p>

<p>
La original es más compacta:
</p>

<p>
\[ \theta_{n \times 1}[i+1] = \theta_{n \times 1}[i] - \frac{\alpha}{m} X_{m \times n}^T (X_{m \times n} \theta_{n \times 1} - Y_{m \times 1} )_{m \times 1} \]
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgbcde6a2" class="outline-2">
<h2 id="orgbcde6a2"><span class="section-number-2">5</span> Semana 3</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-orgc9e6775" class="outline-3">
<h3 id="orgc9e6775"><span class="section-number-3">5.1</span> Classification and representation</h3>
<div class="outline-text-3" id="text-5-1">
</div>
<div id="outline-container-org0087473" class="outline-4">
<h4 id="org0087473"><span class="section-number-4">5.1.1</span> Classification</h4>
<div class="outline-text-4" id="text-5-1-1">
<p>
Vamos a ver la <b>regresión logística</b> que es un algoritmo de clasificación (aunque su nombre diga <i>regresión</i>).
</p>

<p>
La regresión lineal no es un buen método para la clasificación en variables discretas. Acá necesitamos algo más no lineal. Una opción es usar regresión lineal + un umbral arbitrario de separación, pero aún no es suficiente.
</p>

<p>
Vamos a ver clasificación binaria. Definimos como \(0\) y \(1\) a las clases. También usamos <b>etiqueta</b> para denominar a la salida \(h_\theta(x)\).
</p>
</div>
</div>

<div id="outline-container-org32cd098" class="outline-4">
<h4 id="org32cd098"><span class="section-number-4">5.1.2</span> Hypothesis representation</h4>
<div class="outline-text-4" id="text-5-1-2">
<p>
En clasificación binaria, los resultados observados sólo pueden tomar los valores \(0\) y \(1\), y por tanto nuestra función de hipótesis debería también sólo tomar esos valores.
</p>

<p>
Para empezar elegimos una función que esté acotada a ese rango. Una opción es la <b>función logística</b> o <b>sigmoidea</b>:
</p>

<p>
\[ h(z) = \frac{1}{1+e^z} \]
</p>

<p>
\[ h(\theta,x) = h_\theta(x) = \frac{1}{1+e^{\theta^T  x}}\]
</p>

<ul class="org-ul">
<li>Mapea los reales al intervalo \([0, 1]\).</li>
</ul>

<p>
Podemos interpretar los resultados como la probabilidad de que la hipótesis tome un valor, dada determinada entrada.
</p>

<ul class="org-ul">
<li>La suma de las probabilidades debe ser \(1\).</li>
</ul>
</div>


<ol class="org-ol">
<li><a id="orgf4d8da0"></a>La función logística o sigmoidea<br />
<div class="outline-text-5" id="text-5-1-2-1">
<ul class="org-ul">
<li>Se parece a la función cumulativa o función de distribución acumulada de una distribución normal/gaussiana.
<ul class="org-ul">
<li>Pero esta tiene una función explícita, mientras que la FDA de la gaussiana no tiene forma cerrada.</li>
<li>La función de densidad de probabilidad asociada "Se parece a la distribución normal en su forma, pero tiene colas más pesadas (y, por lo tanto, menor curtosis)". <a href="https://es.wikipedia.org/wiki/Distribuci%C3%B3n_log%C3%ADstica">Wikipedia: Distribución logística</a></li>
</ul></li>
<li>Puedo pensar que la FDP de la distribución logística me indica la cantidad de información que me da el valor de un descriptor. En el pico es donde más aporta; luego mientras más me alejo del centro, más claro es que es de una clase o de la otra.</li>
<li>Es una aproximación suave de la función escalón.</li>
</ul>


<div class="figure">
<p><img src="imgs/002-320px-Logistic-curve.svg.png" alt="002-320px-Logistic-curve.svg.png" />
</p>
</div>

<p>
\[ f(x) = \frac{L}{1+e^{-k(x-x_0)}}  \]
</p>

<ul class="org-ul">
<li>\(L\) es el valor máximo.</li>
<li>\(k\) es la tasa de crecimiento o pendiente de la curva.</li>
<li>\(x_0\) es el centro</li>
</ul>
</div>
</li>
</ol>
</div>

<div id="outline-container-org4d283af" class="outline-4">
<h4 id="org4d283af"><span class="section-number-4">5.1.3</span> Decision boundary</h4>
<div class="outline-text-4" id="text-5-1-3">
<p>
La clasificación es discreta; para hacerla discreta necesitamos agregar un umbral a nuestra función de hipótesis. <i>No entiendo por qué pone el umbral como si fuese una cosa aparte de la función de hipótesis</i>. Entonces, para la regresión logística hacemos:
</p>

<p>
\[ y = 0 \quad \text{si} \quad h(z) = h(z(\theta, x)) = h(\theta^T x) \lt 0,5 \]
\[ y = 0 \quad \text{si} \quad h(z) = h(z(\theta, x)) = h(\theta^T x) \geq 0,5 \]
</p>

<p>
Lo que equivale a
</p>

<p>
\[ y = 0 \quad \text{si} \quad  \theta^T x < 0,5 \]
\[ y = 1 \quad \text{si} \quad \theta^T x \ge 0,5 \]
</p>

<p>
La función de entrada a la sigmoidea, \(z(\theta,x)\) define el umbral de decisión. Al igual que vimos para regresión lineal, esta función no tiene por qué ser lineal con respecto a los descriptores (<i>¿mas sí lineal respecto a los parámetros?</i>), y es la que va a separar las clases en su espacio. Por ejemplo, para dos variables podría ser un elipsoide: \( z(\theta,x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1^2 + \theta_4 x_2^2 \).
</p>
</div>
</div>
</div>

<div id="outline-container-org572f93e" class="outline-3">
<h3 id="org572f93e"><span class="section-number-3">5.2</span> Logistic regression model</h3>
<div class="outline-text-3" id="text-5-2">
</div>
<div id="outline-container-org1b4cd15" class="outline-4">
<h4 id="org1b4cd15"><span class="section-number-4">5.2.1</span> Cost function</h4>
<div class="outline-text-4" id="text-5-2-1">
<p>
Sea la función de costo \(J\) la media de una función de error:
</p>

<p>
\[ J(\theta) = \frac{1}{m} \sum_1^m  error(\hat{y}, y) \]
</p>

<p>
Si usamos el error cuadrático medio como función de error para optimizar con el descenso por el gradiente, vamos a tener que derivar una función no lineal. Esto es porque la función logística/sigmoidea \(h(z)\) no es lineal con respecto a los parámetros &theta;, y por tanto el error cuadrático medio no es una función convexa; esto implica que tiene (¿o puede tener?) más de un mínimo.
</p>

<p>
Lo que hacemos entonces es proponer otra función de error que sea convexa y diferenciable. Por supuesto, tiene que penalizar las predicciones/hipótesis erróneas. La que se propone es
</p>

<p>
\[ error(h_\theta(x)) = error(h(\theta,x) = \quad -\log(h_\theta(x)) \quad \text{si} \quad y = 1   \]
\[ error(h_\theta(x)) = error(h(\theta,x) = \quad -\log(1-h_\theta(x)) \quad \text{si} \quad y = 0   \]
</p>


<div class="figure">
<p><img src="./imgs/003-01-logcost1.png" alt="003-01-logcost1.png" />
</p>
</div>




<div class="figure">
<p><img src="./imgs/003-02-logcost2.png" alt="003-02-logcost2.png" />
</p>
</div>

<ul class="org-ul">
<li>Nótese que tienden a infinito en \(0\) y \(1\) respectivamente.</li>
<li>Usamos el <b>logaritmo natural</b>, base \(e\).</li>
</ul>

<hr />

<p>
En la sección siguiente Andrew dice que esta función de costo (en realidad su forma simplificada) se puede derivar estadísticamente a partir del principio de estimación de máxima verisimilitud.
</p>
</div>
</div>

<div id="outline-container-org3c462cb" class="outline-4">
<h4 id="org3c462cb"><span class="section-number-4">5.2.2</span> Simplified cost function and gradient descent</h4>
<div class="outline-text-4" id="text-5-2-2">
</div>
<ol class="org-ol">
<li><a id="org543c7b5"></a>Forma simplificada<br />
<div class="outline-text-5" id="text-5-2-2-1">
<p>
Teníamos a la función de error para la regresión logística como:
</p>

<p>
\[ error(h_\theta(x)) = error(h(\theta,x)) = \quad -\log(h_\theta(x)) \quad \text{si} \quad y = 1   \]
\[ error(h_\theta(x)) = error(h(\theta,x)) = \quad -\log(1-h_\theta(x)) \quad \text{si} \quad y = 0   \]
</p>

<p>
La forma simplificada es:
</p>

<p>
\[ error(h(\theta,x)) = y (-\log(h_\theta(x))) + (1-y) (-\log(1-h_\theta(x)))   \]
</p>

<p>
\[ error(h(\theta,x)) = -y \log(\hat{y}) - (1-y) \log(\hat{y})  \]
</p>

<p>
Esta función es convexa (si \(h\) es la sigmoidea, al menos).
</p>

<p>
Luego la función de costo queda:
</p>

<p>
\[  J(h_\theta(x)) = J(h(\theta,x)) =  \frac{1}{m} \sum_{i=1}^m \left[ -y^{(i)} \log(h_\theta(x^{(i)})) - (1-y^{(i)}) \log(1-h_\theta(x^{(i)}))  \right]  \]
</p>

<p>
La forma vectorizada/matricial es:
</p>

<p>
\[ J(h(\theta,X)) = \frac{1}{m} \left[ - Y^T \log(h(X\theta)) - (1-Y)^T \log(1-h(X\theta)) \right]  \]
</p>
</div>
</li>

<li><a id="org0c142cd"></a>Descenso por el gradiente<br />
<div class="outline-text-5" id="text-5-2-2-2">
<p>
Resulta que la derivada \(\delta J(\theta,x)/\delta \theta\), es la misma que la que obtuvimos usando el error cuadrático medio (<i>MSE</i>) como función de costo para regresión lineal, y entonces la formula de actualización de parámetros es la misma:
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n] - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)}  \]
</p>

<p>
En forma vectorizada/matricial:
</p>

<p>
\[ \theta_{}[i+1] = \theta[i] - \frac{\alpha}{m} X^T (h(X \theta) - Y) \]
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-orgd697528" class="outline-4">
<h4 id="orgd697528"><span class="section-number-4">5.2.3</span> Advanced optimization</h4>
<div class="outline-text-4" id="text-5-2-3">
<p>
Hay algoritmos generales de optimización mejores (pero más complejos) que el descenso por el gradiente. Andrew nombra:
</p>
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">Gradientes conjugados</a></li>
<li>BFGS (<a href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm"><i>Broyden–Fletcher–Goldfarb–Shanno algorithm</i></a>)</li>
<li>L-BFGS (<a href="https://en.wikipedia.org/wiki/Limited-memory_BFGS"><i>Limited memory BFGS</i></a>)</li>
</ul>

<p>
En Octave tenemos la función <code>fminunc</code> (de <i>function minimize unconstrained</i>) que nos permite optimizar usando una función de costo arbitraria. Le tenemos que proveer esa función de costo, que calcula la función de costo y el gradiente en cada iteración. En el ejemplo de Andrew, la función de costo calcula el gradiente de forma analítica, pero asumo que podrías también tener una memoria y usar diferencias.
</p>
</div>
</div>
</div>

<div id="outline-container-org1a3cca7" class="outline-3">
<h3 id="org1a3cca7"><span class="section-number-3">5.3</span> Multiclass classification</h3>
<div class="outline-text-3" id="text-5-3">
</div>
<div id="outline-container-org47bae88" class="outline-4">
<h4 id="org47bae88"><span class="section-number-4">5.3.1</span> Multiclass classification: one vs all</h4>
<div class="outline-text-4" id="text-5-3-1">
<p>
Si tenemos \(n\) salidas discretas posibles, podemos modelar el problema con \(n\) clasificadores binarios, que toman una salida como caso positivo y el resto como negativo.
</p>

<p>
Una vez que clasificamos con todos los clasificadores, elegimos la salida definitiva como aquella que haya tenido la mayor confianza; y entonces tenemos que ver la probabilidad predicha antes de discretizarla.
</p>

<p>
Nótese que esto también se cumple en los binarios cuando \(n=2\): podemos verlo como que ambos clasificadores definen la misma frontera de decisión.
</p>
</div>
</div>
</div>

<div id="outline-container-orgbc2e9f5" class="outline-3">
<h3 id="orgbc2e9f5"><span class="section-number-3">5.4</span> Solving the problem of overfitting</h3>
<div class="outline-text-3" id="text-5-4">
</div>
<div id="outline-container-org091891b" class="outline-4">
<h4 id="org091891b"><span class="section-number-4">5.4.1</span> The problem of overfitting</h4>
<div class="outline-text-4" id="text-5-4-1">
<p>
Empezamos a evaluar la bondad de ajuste de nuestros modelos.
</p>

<ul class="org-ul">
<li>Un modelo subajustado (<i>underfitted</i>) o de alto sesgo (<i>high bias</i>) tiene mucho error para los datos con los que se entrenó, y por ende muy probablemente tenga mucho error con entradas nuevas. El modelo no captura las características del espacio del problema.
<ul class="org-ul">
<li>El sesgo se asocia con prejuicio. El modelo prejuzga incorrectamente cómo deberían ser las entradas.</li>
</ul></li>
<li>Un modelo sobreajustado (<i>overfitted</i>) predice <i>demasiado</i> correctamente los datos con los que se ajustó, pero no predice correctamente entradas que sean un poco distintas; <b>no generaliza</b>. También se habla de que es un modelo con alta varianza (<i>high variance</i>), porque el espacio de funciones de hipótesis (de la complejidad propuesta) que predicen bien es muy grande; hay muchos grados de libertad.</li>
</ul>

<p>
En los ejemplos mostrados, el ajuste se incrementa con el grado de las funciones de hipótesis, para regresión lineal. Entonces complejizar las funciones de hipótesis implica agregar más descriptores &#x2014;reales o sintéticos&#x2014;.
</p>
</div>

<ol class="org-ol">
<li><a id="orgc19a0ea"></a>Opciones para reducir el sobreajuste<br />
<div class="outline-text-5" id="text-5-4-1-1">
<p>
Las principales formas de reducir el sobreajuste:
</p>

<ol class="org-ol">
<li>Reducir la cantidad de descriptores.
<ul class="org-ul">
<li>Manualmente o con métodos automáticos de selección de modelo.</li>
<li>Perdemos información codificada en los descriptores que eliminamos.</li>
</ul></li>
<li>Usar <b>regularización</b>.
<ul class="org-ul">
<li>Mantenemos todos los descriptores pero los ponderamos.</li>
</ul></li>
</ol>
</div>
</li>
</ol>
</div>

<div id="outline-container-org6d3f387" class="outline-4">
<h4 id="org6d3f387"><span class="section-number-4">5.4.2</span> Cost function</h4>
<div class="outline-text-4" id="text-5-4-2">
<p>
Introducimos un parámetro de regularización \(\lambda\) en la función de costo, que pondera la suma de los cuadrados de los parámetros \(\theta\).
</p>

<ul class="org-ul">
<li><i>Creo que este tipo de regularización tiene un nombre</i>.</li>
<li><i>Usamos el cuadrado para que no se cancelen entre sí y porque es derivable supongo</i>.</li>
</ul>

<p>
Por ejemplo, para <i>MSE</i>:
</p>

<p>
\[ J(\theta,x,h(x),\lambda) =  \frac{1}{2m} \left( \sum_{i=1}^{m} \left[ h(\theta,x^{(i)}) - y^{(i)} \right]^2 + \lambda \sum_{j=1}^{n} \theta_j^2 \right)  \]
</p>

<ul class="org-ul">
<li>Se suele omitir la ordenada al origen, término de sesgo o <b>intercepto</b> \(\theta_0\) porque no afecta mucho a los resultados.
<ul class="org-ul">
<li><i>Me parece que debe haber una razón más interesante, porque esta decisión hace que tengamos que calcular las funciones de costo de forma separada para \(\theta_0\)</i>.
<ul class="org-ul">
<li>En verdad es incorrecto pretender que el intercepto sea pequeño. Ver abajo en <a href="#org1c34648">5.4.2.0.0.1</a>.</li>
</ul></li>
</ul></li>
</ul>


<p>
Lo que buscamos es tener parámetros pequeños, lo que hace que la función de hipótesis sea suave, simple.
</p>

<p>
Más adelante vamos a ver formas de determinar el valor del parámetro de regularización \(\lambda\) para que funcione. Si es muy grande, hay subajuste, y si es muy chico seguimos con sobreajuste.
</p>
</div>

<ol class="org-ol">
<li><a id="org1c34648"></a><span class="done DONE">DONE</span> Buscar por qué no usamos \(\theta_0\)<br />
<div class="outline-text-7" id="text-5-4-2-0-0-1">
<p>
El intercepto es nuestro factor de prejuicio que es independente de los descriptores. Es nuestra respuesta por defecto cuando no tenemos información, y no tiene por qué ser un valor chico. Por tanto no lo introducimos en el algoritmo de regularización.
</p>

<p>
Recordemos que el intercepto es una variable independiente, la ordenada al origen. Lo introducimos dentro del vector de parámetros solo por conveniencia, para simplificar los cálculos.
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-orgbe740ec" class="outline-4">
<h4 id="orgbe740ec"><span class="section-number-4">5.4.3</span> Regularized linear regression</h4>
<div class="outline-text-4" id="text-5-4-3">
<p>
La función de costo usando error cuadrático medio y regresión lineal nos queda
</p>

<p>
\[ J(\theta,x,h(x),\lambda) =  \frac{1}{2m} \left( \sum_{i=1}^{m} \left[ h(\theta,x^{(i)}) - y^{(i)} \right]^2 + \lambda \sum_{j=1}^{n} \theta_j^2 \right)  \]
</p>

<p>
Nótese que \(j\) empieza en \(1\). La regla de actualización derivada es:
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n] - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)} \quad \text{si} \quad j=0 \]
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n] - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)} + \frac{\lambda}{m} \theta_j \quad \text{si} \quad j>0 \]
</p>

<p>
Factorizando \(\theta_j\) de esta última ecuación nos queda
</p>

<p>
\[ \theta_j[n+1] := {\theta}_j[n](1 - \frac{\alpha\lambda}{m}) - \frac{\alpha}{m}  \sum_{i=1}^m( h_\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)}  \quad \text{si} \quad j>0 \]
</p>

<p>
El factor \((1 - \frac{\alpha\lambda}{m})\) nos indica que en todas las actualizaciones se comienza reduciendo el valor anterior de los parámetros.
</p>
</div>

<ol class="org-ol">
<li><a id="orgd126b3e"></a>Forma matricial/vectorizada<br />
<div class="outline-text-5" id="text-5-4-3-1">
<p>
La forma matricial/vectorizada queda
</p>

<p>
\[ J(\theta, X, \lambda) = \frac{1}{2m} \sum (X\theta - Y)^2 + \frac{\lambda}{2m} \theta(1:n)^T \theta(1:n) \]
</p>


<p>
La actualización necesita 2 etapas: la primera es el cálculo normal sin regularización, y de aquí guardamos \(\theta_0\); en la segunda sumamos el termino de regularización; y finalmente reemplazamos con el \(\theta_0\) encontrado anteriormente.
</p>

<p>
\[ \theta[i+1]^{(a)} := \theta[i] - \frac{\alpha}{m} X^T (h(X \theta) - Y) \]
\[ \theta_0[i+1]^{} := \theta[i+1]^{(a)}(0) \]
\[ \theta[i+1]^{} := \theta[i+1]^{(a)} + \frac{\lambda}{2m} \theta[i] \]
\[ \theta[i+1](0) := \theta_0[i+1]  \]
</p>


<hr />
</div>
</li>

<li><a id="org00b1b4d"></a>La ecuación normal con regularización<br />
<div class="outline-text-5" id="text-5-4-3-2">
<p>
La ecuación normal era
</p>

<p>
\[  \theta = [ ( X^T \times X)^{-1} \times X^T ] \times Y  \]
</p>

<p>
Agregamos un término de regularización:
</p>

<p>
\[  \theta = [ ( X^T \times X \times \lambda L)^{-1} \times X^T ] \times Y  \]
</p>

<p>
Donde L es una matriz diagonal cuyo primer elemento de la diagonal principal es \(0\) e indica que no queremos que la regularización afecte al parámetro &theta;<sub>0</sub> .
</p>

<p>
Este termino de regularización <b>hace que esa matriz sea invertible aunque se trate de un sistema subdeterminado</b> (siempre que \(\lambda>0\)).
</p>
<ul class="org-ul">
<li>En las <a href="https://www.coursera.org/learn/machine-learning/discussions/weeks/3/threads/poUNvD1-EeakuhJbRt69hQ">preguntas frecuentes de la semana 3</a> dicen que <a href="http://web.mit.edu/zoya/www/linearRegression.pdf">acá hay un "boceto de demonstración"</a>.</li>
</ul>
</div>
</li>
</ol>
</div>

<div id="outline-container-orga2d872a" class="outline-4">
<h4 id="orga2d872a"><span class="section-number-4">5.4.4</span> Regularized logistic regression</h4>
<div class="outline-text-4" id="text-5-4-4">
<p>
La función de costo de la regresión logística con regularización queda:
</p>

<p>
\[  J(h_\theta(x), \lambda) = J(h(\theta,x)) = \frac{1}{m} \sum_{i=1}^m \left[-y^{(i)} \log(h_\theta(x^{(i)})) - (1-y^{(i)}) \log(1-h_\theta(x^{(i)}))  \right] + \frac{\lambda}{2m} \sum_{j=1}^n \theta_j^2 \]
</p>

<p>
La forma vectorizada/matricial:
</p>

<p>
\[ J(h(\theta,X), \lambda) = \frac{1}{m} \left[ -Y^T \log(h(X\theta)) - (1-Y)^T \log(1-h(X\theta)) \right] + \frac{\lambda}{2m} \theta(1:n)^T \theta(1:n) \]
</p>

<p>
La regla de actualización es igual que para regresión lineal con <i>MSE</i>, calculando por separado \(\theta_0\).
</p>
</div>
</div>
</div>





<div id="outline-container-org25a1562" class="outline-3">
<h3 id="org25a1562"><span class="section-number-3">5.5</span> Review</h3>
<div class="outline-text-3" id="text-5-5">
</div>
<div id="outline-container-orgd26e682" class="outline-4">
<h4 id="orgd26e682"><span class="section-number-4">5.5.1</span> Quiz: Regularization</h4>
<div class="outline-text-4" id="text-5-5-1">
<ul class="org-ul">
<li>Agregar nuevos descriptores nos da una hipótesis igual o mejor a la que tenemos antes de agregarlos, en los datos de entrenamiento/modelado.
<ul class="org-ul">
<li>Asumo que asume convergencia.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orga9205d9" class="outline-4">
<h4 id="orga9205d9"><span class="section-number-4">5.5.2</span> Programming assignment: logistic regression</h4>
<div class="outline-text-4" id="text-5-5-2">
<ul class="org-ul">
<li>Corregí algunas funciones vectorizadas de mis notas.</li>
<li>El logaritmo es logaritmo natural, no base 10. Por tanto debería escribir \(ln\) en lugar de \(log\), aunque en Octave la función es <code>log</code>.</li>
<li><i>Cross entropy</i></li>
<li>Usamos <i>feature mapping</i> para crear nuevos descriptores a partir de los 2 que teníamos. Los nuevos son todas las combinaciones lineales posibles de descriptores, hasta cierto grado.</li>
</ul>

<div class="org-src-container">
<pre class="src src-octave"><span style="color: #4f97d7; font-weight: bold;">function</span> out <span style="color: #4f97d7;">=</span> <span style="color: #bc6ec5; font-weight: bold;">mapFeature</span><span style="color: #4f97d7;">(</span>X1<span style="color: #4f97d7;">,</span> X2<span style="color: #4f97d7;">)</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">MAPFEATURE Feature mapping function to polynomial features</span>
<span style="color: #2aa1ae; background-color: #292e34;">%</span>
<span style="color: #2aa1ae; background-color: #292e34;">%   </span><span style="color: #2aa1ae; background-color: #292e34;">MAPFEATURE(X1, X2) maps the two input features</span>
<span style="color: #2aa1ae; background-color: #292e34;">%   </span><span style="color: #2aa1ae; background-color: #292e34;">to quadratic features used in the regularization exercise.</span>
<span style="color: #2aa1ae; background-color: #292e34;">%</span>
<span style="color: #2aa1ae; background-color: #292e34;">%   </span><span style="color: #2aa1ae; background-color: #292e34;">Returns a new feature array with more features, comprising of </span>
<span style="color: #2aa1ae; background-color: #292e34;">%   </span><span style="color: #2aa1ae; background-color: #292e34;">X1, X2, X1.^2, X2.^2, X1*X2, X1*X2.^2, etc..</span>
<span style="color: #2aa1ae; background-color: #292e34;">%</span>
<span style="color: #2aa1ae; background-color: #292e34;">%   </span><span style="color: #2aa1ae; background-color: #292e34;">Inputs X1, X2 must be the same size</span>
<span style="color: #2aa1ae; background-color: #292e34;">%</span>

  degree <span style="color: #4f97d7;">=</span> <span style="color: #a45bad;">6</span><span style="color: #4f97d7;">;</span>
  out <span style="color: #4f97d7;">=</span> ones<span style="color: #4f97d7;">(</span>size<span style="color: #bc6ec5;">(</span>X1<span style="color: #2d9574;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">1</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
  <span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7;">=</span> <span style="color: #a45bad;">1</span><span style="color: #4f97d7;">:</span>degree
    <span style="color: #4f97d7; font-weight: bold;">for</span> j <span style="color: #4f97d7;">=</span> <span style="color: #a45bad;">0</span><span style="color: #4f97d7;">:</span>i
      out<span style="color: #4f97d7;">(</span><span style="color: #4f97d7;">:,</span> end<span style="color: #4f97d7;">+</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span>X1<span style="color: #4f97d7;">.^</span><span style="color: #bc6ec5;">(</span>i<span style="color: #4f97d7;">-</span>j<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">.*</span><span style="color: #4f97d7;">(</span>X2<span style="color: #4f97d7;">.^</span>j<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
    <span style="color: #4f97d7; font-weight: bold;">end</span>
  <span style="color: #4f97d7; font-weight: bold;">end</span>

<span style="color: #4f97d7; font-weight: bold;">end</span>

<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">---------</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Add Polynomial Features</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Note that mapFeature also adds a column of ones for us, so the intercept</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">term is handled</span>
X <span style="color: #4f97d7;">=</span> mapFeature<span style="color: #4f97d7;">(</span>X<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">,</span> X<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">2</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>

</pre>
</div>

<ul class="org-ul">
<li>\(\theta_0\): manejé los distintos gradientes así:</li>
</ul>

<div class="org-src-container">
<pre class="src src-octave">grad <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> X<span style="color: #4f97d7;">'*</span><span style="color: #4f97d7;">(</span>sigmoid<span style="color: #bc6ec5;">(</span>X<span style="color: #4f97d7;">*</span>theta<span style="color: #bc6ec5;">)</span> <span style="color: #4f97d7;">-</span> y<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
grad0 <span style="color: #4f97d7;">=</span> grad<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
grad <span style="color: #4f97d7;">=</span> grad <span style="color: #4f97d7;">+</span> <span style="color: #4f97d7;">(</span>lambda<span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">.*</span>theta<span style="color: #4f97d7;">;</span>
grad<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">=</span> grad0<span style="color: #4f97d7;">;</span>
</pre>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-orge749bd3" class="outline-2">
<h2 id="orge749bd3"><span class="section-number-2">6</span> Semana 4</h2>
<div class="outline-text-2" id="text-6">
<p>
Empezamos a ver redes neuronales.
</p>
</div>

<div id="outline-container-orgcbd0f4a" class="outline-3">
<h3 id="orgcbd0f4a"><span class="section-number-3">6.1</span> Motivations</h3>
<div class="outline-text-3" id="text-6-1">
</div>
<div id="outline-container-orgab3f764" class="outline-4">
<h4 id="orgab3f764"><span class="section-number-4">6.1.1</span> Non-linear hypotheses</h4>
<div class="outline-text-4" id="text-6-1-1">
<p>
Las redes neuronales son de los clasificadores más avanzados y usados hoy en día.
</p>

<p>
Para problemas poco lineales, la regresión logística empieza a necesitar muchos descriptores. Demasiados. Sea por ejemplo un problema con dos descriptores \(x_1\) y \(x_2\). Si queremos más expresividad de clasificación y añadimos como descriptores sintéticos todos los productos de segundo orden, tenemos \(x_1^2 , x_2^2, x_1 x_2\), y tendríamos un total de 5 descriptores. Este total crece como \(O(\frac{n^2}{2})\). Los de tercer orden crecen como \(O(n^3)\).
</p>

<p>
Hay muchos problemas que de entrada ya están definidos por muchos descriptores. Un ejemplo: las imágenes digitales. Por ejemplo, una imagen de 100&times;100px requeriría aproximadamente 50 millones de descriptores de segundo grado.
</p>
</div>
</div>


<div id="outline-container-org5d86b8d" class="outline-4">
<h4 id="org5d86b8d"><span class="section-number-4">6.1.2</span> Neurons and the brain</h4>
<div class="outline-text-4" id="text-6-1-2">
<ul class="org-ul">
<li><i>The "one learning algorithm" hypotesis</i>: el cerebro tiene el mismo algoritmo de aprendizaje siempre, y se adapta a cualquier entrada.</li>
</ul>
</div>

<ol class="org-ol">
<li><a id="org929591b"></a><span class="todo TODO">TODO</span> <a href="https://www.lesswrong.com/posts/9Yc7Pp7szcjPgPsjf/the-brain-as-a-universal-learning-machine">https://www.lesswrong.com/posts/9Yc7Pp7szcjPgPsjf/the-brain-as-a-universal-learning-machine</a><br /></li>

<li><a id="org48d8f6c"></a><span class="todo TODO">TODO</span> <a href="https://www.youtube.com/watch?v=AY4ajbu_G3k">https://www.youtube.com/watch?v=AY4ajbu_G3k</a><br /></li>

<li><a id="org93a2d9d"></a><span class="todo TODO">TODO</span> <a href="https://www.youtube.com/watch?v=NKpuX_yzdYs">https://www.youtube.com/watch?v=NKpuX_yzdYs</a><br /></li>

<li><a id="org7e4687c"></a><span class="todo TODO">TODO</span> <a href="https://www.youtube.com/watch?v=zIwLWfaAg-8">https://www.youtube.com/watch?v=zIwLWfaAg-8</a><br /></li>

<li><a id="org3f165ba"></a><span class="todo TODO">TODO</span> <a href="https://www.wired.com/2013/05/neuro-artificial-intelligence/">https://www.wired.com/2013/05/neuro-artificial-intelligence/</a><br /></li>
</ol>
</div>
</div>

<div id="outline-container-orgd595f01" class="outline-3">
<h3 id="orgd595f01"><span class="section-number-3">6.2</span> Neural networks</h3>
<div class="outline-text-3" id="text-6-2">
</div>
<div id="outline-container-org0fed566" class="outline-4">
<h4 id="org0fed566"><span class="section-number-4">6.2.1</span> Model representation I</h4>
<div class="outline-text-4" id="text-6-2-1">
<p>
Está largo de escribir así que copio la imagen:
</p>


<div class="figure">
<p><img src="./imgs/004-neural-network-model.png" alt="004-neural-network-model.png" />
</p>
</div>

<p>
Algo de nomenclatura y convenciones:
</p>

<ul class="org-ul">
<li>Es equivalente hablar de una <b>unidad</b>, una <b>neurona</b>, la salida de una neurona o la <b>activación</b> de una neurona. Siempre hablamos del resultado de la función de activación ante ciertas entradas y parámetros o pesos: \(g(\theta,x)\). La neurona en sí no tiene significado en el modelo, aunque lo tiene en el diagrama.
<ul class="org-ul">
<li>La unidad 1 de la capa 2 es \(a_1^{(2)}\).</li>
<li>Se suele omitir la unidad de sesgo de cada capa, \(a_0^{(j)}\), porque vale siempre 1. Esta es la que se multiplica por \(\theta_0\). <i>DISCREPO</i>.</li>
</ul></li>
<li>\(h_{\Theta}^{}(\vec{x}^{})\) es la salida final de la red neuronal, en función de las entradas.</li>
<li>La función de activación típica es la función logística/sigmoidea.</li>
<li>A los parámetros de la función también les decimos <b>pesos</b>.
<ul class="org-ul">
<li>&Theta;<sup>(j)</sup> es la matriz de pesos que relaciona la capa \(j\) con la siguiente \(j+1\). Si una capa \(j\) tiene \(s_j\) unidades y la siguiente es \(j+1\) con \(s_{j+1}\) unidades, la dimensión de \(\Theta^{(j)}\) será \((s_{j+1})\times(s_j+1)\) (entradas &times; (salidas + entradas independientes)); el \(+1\) es por la unidad de sesgo.</li>
</ul></li>
<li>En los diagramas se funden axones y dendritas de capas conectadas, adyacentes. Entonces los únicos axones son los de la capa de salida.</li>
<li>A las capas que no son de salida o entrada se les suele llamar <b>capas ocultas</b>.</li>
</ul>
</div>
</div>

<div id="outline-container-orgac1da62" class="outline-4">
<h4 id="orgac1da62"><span class="section-number-4">6.2.2</span> Model representation II</h4>
<div class="outline-text-4" id="text-6-2-2">
<p>
Este modelo básico de red neuronal es un conjunto de funciones logísticas encadenadas. La forma de conectar las neuronas (arquitectura) le va a permitir aprender funciones no lineales complejas.
</p>

<p>
En forma vectorizada y asumiendo la misma función de activación \(g^{(j)}\) para todas las neuronas:
</p>

<p>
\[ h_{\Theta}^{}(\vec{x}^{}) = h(g, \vec{x}, \Theta) \]
\[ \vec{a}^{(j) }= g_{}^{}(\vec{z}^{(j)}) = g(\Theta^{(j-1)} \vec{a}^{(j-1)})  \]
</p>
</div>
</div>
</div>

<div id="outline-container-org8c0109e" class="outline-3">
<h3 id="org8c0109e"><span class="section-number-3">6.3</span> Applications</h3>
<div class="outline-text-3" id="text-6-3">
</div>
<div id="outline-container-org0050235" class="outline-4">
<h4 id="org0050235"><span class="section-number-4">6.3.1</span> Examples and intuitions I</h4>
<div class="outline-text-4" id="text-6-3-1">
<p>
Con una neurona de 3 entradas puedo calcular las funciones AND y OR.
</p>
</div>
</div>

<div id="outline-container-org986da8f" class="outline-4">
<h4 id="org986da8f"><span class="section-number-4">6.3.2</span> Examples and intuitions II</h4>
<div class="outline-text-4" id="text-6-3-2">
<p>
Ejemplo de XNOR.
</p>
</div>
</div>

<div id="outline-container-org3c9ffd6" class="outline-4">
<h4 id="org3c9ffd6"><span class="section-number-4">6.3.3</span> Multiclass classification</h4>
<div class="outline-text-4" id="text-6-3-3">
<p>
Para clasificación multiclase solo tenemos que tener tantas salidas como clases. Luego, codificamos la salida como un vector "<i>one hot</i>", donde todos los elementos son \(0\) menos el de la salida correcta, que es \(1\).
</p>

<p>
Las salidas de la red \(\vec{\hat{y}} = h_\Theta(\vec{x})\) no son una distribución de probabilidad, no necesariamente suman 1. Son la salida de distintas sigmoideas, y cada una representa la confianza que tiene ese clasificador.
</p>
</div>
</div>
</div>

<div id="outline-container-orgd8c0e55" class="outline-3">
<h3 id="orgd8c0e55"><span class="section-number-3">6.4</span> Review</h3>
<div class="outline-text-3" id="text-6-4">
</div>
<div id="outline-container-org859fb74" class="outline-4">
<h4 id="org859fb74"><span class="section-number-4">6.4.1</span> Quiz: Neural networks: representation</h4>
</div>

<div id="outline-container-orga585301" class="outline-4">
<h4 id="orga585301"><span class="section-number-4">6.4.2</span> Programming assignment: multi-class classificatin and neural networks</h4>
</div>
</div>
</div>

<div id="outline-container-org496b1f6" class="outline-2">
<h2 id="org496b1f6"><span class="section-number-2">7</span> Semana 5</h2>
<div class="outline-text-2" id="text-7">
<p>
Vamos a ver el algoritmo de retropropagación o propagación hacia atrás (<i>backpropagation</i>) para el aprendizaje de redes neuronales.
</p>
</div>

<div id="outline-container-org61722f1" class="outline-3">
<h3 id="org61722f1"><span class="section-number-3">7.1</span> Cost function and backpropagation</h3>
<div class="outline-text-3" id="text-7-1">
</div>
<div id="outline-container-org0c6d257" class="outline-4">
<h4 id="org0c6d257"><span class="section-number-4">7.1.1</span> Cost function</h4>
<div class="outline-text-4" id="text-7-1-1">
<p>
Para optimizar un conjunto de parámetros \(\Theta\) necesitamos primero definir una función de costo a minimizar.
</p>

<p>
Algunas definiciones:
</p>

<ul class="org-ul">
<li>\(K\) es la cantidad de salidas de la red.
<ul class="org-ul">
<li>Usamos \(k\) para indizarlas.</li>
</ul></li>
<li>\(L\) es la cantidad de capas de nuestra red.
<ul class="org-ul">
<li>Usamos \(l\) para indizarlas.</li>
</ul></li>
<li>\(s_l\) es la cantidad de neuronas/unidades de la capa \(l\), <b>sin contar la unidad de sesgo \(a_0^{(l)}\)</b>.</li>
</ul>

<p>
La función de costo es una extensión de la regularizada que usábamos para regresión logística.
</p>

<ul class="org-ul">
<li>Sumamos los errores de todas las salidas.</li>
<li>Regularizamos todos los parámetros \(\theta\) de las matrices \(\Theta\), excepto aquellos que relacionan unidades de sesgo. Estos son corresponden a <del>la primera fila y</del> la primera columna de cada \(\Theta\).</li>
</ul>

<p>
\[  J(\Theta, \lambda) = \frac{1}{m} \sum_{k=1}^K \sum_{i=1}^m \left[-y_k^{(i)} \log(h_\Theta(x^{(i)})_k) - (1-y_k^{(i)}) \log(1-h_\Theta(x^{(i)})_k)  \right] + \frac{\lambda}{2m} \sum_{l=1}^L \sum_{v=0}^{s_{l+1}} \sum_{j=1}^{s_l} (\Theta_{v,j}^{(l)})^2 \]
</p>

<ul class="org-ul">
<li><i>Yo voy a usar \(v\) donde él usa OTRA \(i\)</i>.</li>
</ul>
</div>
</div>


<div id="outline-container-orgcb137ed" class="outline-4">
<h4 id="orgcb137ed"><span class="section-number-4">7.1.2</span> Backpropagation algorithm</h4>
<div class="outline-text-4" id="text-7-1-2">
<p>
Esto está complicado así que nos lo dan sin demostraciones.
</p>

<p>
El algoritmo de retropropagación o propagación hacia atrás sirve para calcular el gradiente de la función de costo en función de los parámetros. Luego usamos este gradiente <b>en algún algoritmo de optimización</b> como el descenso por el gradiente, para encontrar los parámetros que minimizan la función de costo.
</p>

<p>
\[  \frac{\partial J(\Theta)}{\partial \Theta_{v,j}^{(l)} } = D_{v,j}^{(l)}  \]
</p>

<p>
\[ D_{v,j}^{(l)} = \frac{1}{m} \Delta_{v,j}^{(l)} + \lambda \Theta_{v,j}^{(l)} \quad \text{si} \quad j=0  \]
</p>

<p>
\[ D_{v,j}^{(l)} = \frac{1}{m} \Delta_{v,j}^{(l)} \quad \text{si} \quad j\ne0  \]
</p>

<p>
\(\Delta_{v,j}^{(l)}\) son matrices en las que vamos acumulando los errores de cada unidad de cada capa, para cada ejemplo de entrada. El proceso es:
</p>

<ol class="org-ol">
<li>Para cada ejemplo \(x{(i)}\):
<ol class="org-ol">
<li>Calculamos las salidas de la red, propagando hacia adelante.</li>
<li>Calculamos los errores, propagando hacia atrás.</li>
</ol></li>
</ol>

<p>
\[  \Delta_{v,j}^{(l)} [n+1] := \Delta_{v,j}^{(l)} [n] + \vec{a}_j^{(l)} \vec{\delta}_{v}^{(l+1)} \]
</p>

<p>
De forma vectorizada/matricial:
</p>

<p>
\[ \Delta^{(l)}[n+1] := \Delta^{(l)}[n] + \delta^{(l+1)} (a^{(l)})^T   \]
</p>


<p>
\(\vec{\delta}^{(l)}\) es un vector de los errores para cada capa. Si no entiendo mal, es la derivada de \(g\) en el punto determinado por sus entradas, multiplicado por el avance del error retropropagado.
</p>

<p>
\[  \vec{\delta}^{(l=L)} :=  \vec{a}^{(l)} - \vec{y}^{}  \]
</p>

<p>
\[  \vec{\delta}^{( 1 \lt l \lt L )} := (\Theta^{(l)})^T \vec{\delta}^{(l+1)} * \vec{g'}(z^{(l)})  \]
</p>

<p>
\[ \vec{g'} (z^{(l)}) = \vec{a}^{(l)} .* (\vec{1} - \vec{a}^{(l)} )  \]
</p>
</div>
</div>





<div id="outline-container-org7e9bf57" class="outline-4">
<h4 id="org7e9bf57"><span class="section-number-4">7.1.3</span> Backpropagation intuition</h4>
<div class="outline-text-4" id="text-7-1-3">
<p>
Los términos \(\delta\) son los "errores" de predicción de cada unidad. Más técnicamente:
</p>

<p>
\[  \delta_j^{(l)} = \frac{\partial costo(h_\Theta, x^{(i)})}{\partial z_j^{(l)}}   \]
</p>

<p>
Así como cada \(z^{(l)}\) es una suma pesada de las entradas a esa unidad, cada \(\delta^{(l)}\) es una suma pesada de las entradas a esa unidad, recorriendo el grafo al revés, desde las salidas a hacia las entradas.
</p>
</div>
</div>
</div>

<div id="outline-container-org049ca9d" class="outline-3">
<h3 id="org049ca9d"><span class="section-number-3">7.2</span> Backpropagation in practice</h3>
<div class="outline-text-3" id="text-7-2">
</div>
<div id="outline-container-org9263c15" class="outline-4">
<h4 id="org9263c15"><span class="section-number-4">7.2.1</span> Implementation note: unrolling parameters</h4>
<div class="outline-text-4" id="text-7-2-1">
<p>
Muchos algoritmos de optimización esperan vectores. Para trabajar con nuestras matrices \(\Theta\) de parámetros y \(D\) de gradientes, lo que hacemos es juntar todos los elementos y expresarlos como vector. Luego las reconstruimos en donde sea necesario.
</p>

<p>
En Octave:
</p>

<div class="org-src-container">
<pre class="src src-octave">Theta1 <span style="color: #4f97d7;">=</span> rand<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">4</span><span style="color: #4f97d7;">,</span><span style="color: #a45bad;">3</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% 4x3</span>
Theta2 <span style="color: #4f97d7;">=</span> rand<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">,</span><span style="color: #a45bad;">4</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% 2x4</span>
ThetaVec <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">[</span>Theta1<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">;</span> Theta2<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">]</span><span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% 20x1</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">[J, DVec]  = costFunction(ThetaVec, X, Y)  % Adentro reconstruimos ThetaVec</span>
ThetaVecOptimized <span style="color: #4f97d7;">=</span> fminunc<span style="color: #4f97d7;">(</span><span style="color: #4f97d7;">...</span><span style="color: #4f97d7;">)</span>
Theta1 <span style="color: #4f97d7;">=</span> reshape<span style="color: #4f97d7;">(</span>ThetaVecOptimized<span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">:</span><span style="color: #a45bad;">11</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">,</span> <span style="color: #a45bad;">4</span><span style="color: #4f97d7;">,</span><span style="color: #a45bad;">3</span><span style="color: #4f97d7;">)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org2579f0d" class="outline-4">
<h4 id="org2579f0d"><span class="section-number-4">7.2.2</span> Gradient checking</h4>
<div class="outline-text-4" id="text-7-2-2">
<p>
Para verificar que nuestro algoritmo de retropropagación esté funcionando bien, podemos comparar los gradientes \(D\) calculados con unos calculados manualmente usando una aproximación de la derivada en el punto. Andrew sugiere usar una aproximación de doble lado:
</p>

<p>
\[  \frac{\partial J(\Theta)}{\partial \Theta}   \approx  \frac{J(\Theta + \epsilon) - J(\Theta - \epsilon)}{2 \epsilon}\]
</p>

<p>
Calculamos esto para cada uno de los parámetros \(\theta\) del vector desenrollado a partir de las matrices \(\Theta\). Calculamos para cada parámetro, manteniendo el resto fijos; es la derivada parcial.
</p>

<p>
<b>¡Nótese que podríamos optimizar con esto!</b> El problema es que es computacionalmente mucho más costoso que el algoritmo de retropropagación. Implica recalcular la función de costo 2 veces para cada parámetro de las matrices. Por lo tanto, solo lo deberíamos usar para depurar nuestro código, pero luego desactivarlo.
</p>
</div>
</div>

<div id="outline-container-org2e91635" class="outline-4">
<h4 id="org2e91635"><span class="section-number-4">7.2.3</span> Random initialization</h4>
<div class="outline-text-4" id="text-7-2-3">
<p>
Si inicializamos los parámetros \(\theta\) de las matrices \(\Theta\) todos con el mismo valor, en cada iteración de propagación hacia adelante terminamos con las mismas activaciones en cada unidad de una misma capa; y en cada iteración de propagación hacia atrás terminamos con los mismos errores \(\delta\). Esto implica que todas las unidades de una capa terminan calculando los mismos descriptores. Esto se llama el <b>problema de los caminos simétricos</b>. <i>Supongo que se da porque todas las unidades están conectadas de la misma manera, quizás no sería necesario si las unidades se conectaran de forma distinta</i>.
</p>

<p>
La forma de solucionar el problema es romper la simetría (<i>simmetry breaking</i>). Para esto debemos inicializar los parámetros con valores distintos. Andrew propone inicializarlos con valores aleatorios (distribución uniforme) en un intervalo \([-\epsilon, \epsilon]\) para un valor \(\epsilon\) pequeño cualquiera (propone un \(\epsilon<1\)).
</p>
</div>
</div>

<div id="outline-container-org7ece90e" class="outline-4">
<h4 id="org7ece90e"><span class="section-number-4">7.2.4</span> Putting it together</h4>
<div class="outline-text-4" id="text-7-2-4">
<ul class="org-ul">
<li>La arquitectura es el patrón de conexión entre las neuronas.
<ul class="org-ul">
<li>Lo más básico es tener una capa oculta (pero no dice de cuántas unidades).</li>
<li>Una buena heurística es tener tantas capas ocultas como unidades de entrada.</li>
</ul></li>
<li>Recordamos que el algoritmo de retropropagación es un algoritmo para calcular el gradiente de la función de costo respecto a la variación de los parámetros; la optimización se hace con un algoritmo genérico de optimización, como el descenso por el gradiente.</li>
<li>\(J(\Theta)\) no es un espacio convexo en las redes neuronales. Esto implica que quizás no alcanzamos el mínimo global, pero dice Andrew que esto no suele ser un problema en la realidad.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org136d323" class="outline-3">
<h3 id="org136d323"><span class="section-number-3">7.3</span> Applications of neural networks</h3>
<div class="outline-text-3" id="text-7-3">
</div>
<div id="outline-container-orgb311726" class="outline-4">
<h4 id="orgb311726"><span class="section-number-4">7.3.1</span> Autonomous driving</h4>
<div class="outline-text-4" id="text-7-3-1">
<p>
Jeep automanejado en 1992.
</p>
</div>
</div>
</div>

<div id="outline-container-org8610a77" class="outline-3">
<h3 id="org8610a77"><span class="section-number-3">7.4</span> Review</h3>
<div class="outline-text-3" id="text-7-4">
</div>
<div id="outline-container-orgd8fcdd9" class="outline-4">
<h4 id="orgd8fcdd9"><span class="section-number-4">7.4.1</span> Quiz: Neural networks: learning</h4>
</div>

<div id="outline-container-org4200daf" class="outline-4">
<h4 id="org4200daf"><span class="section-number-4">7.4.2</span> Programming assignment: neural network learning</h4>
<div class="outline-text-4" id="text-7-4-2">
<ul class="org-ul">
<li>Usé una forma vectorizada de la función de costo, según algunas pistas que encontré en las notas del curso. En ellas usé la <i>traza</i> de una matriz, para trabajar con muchas salidas.</li>
</ul>

<div class="org-src-container">
<pre class="src src-octave"><span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">C&#225;lculo de la funci&#243;n de costo</span>
y_onehot <span style="color: #4f97d7;">=</span> zeros<span style="color: #4f97d7;">(</span>num_labels<span style="color: #4f97d7;">,</span> m<span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>  <span style="color: #2aa1ae; background-color: #292e34;">% s3xm</span>
<span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7;">=</span> <span style="color: #a45bad;">1</span><span style="color: #4f97d7;">:</span>m  <span style="color: #2aa1ae; background-color: #292e34;">% cada columna</span>
  y_onehot<span style="color: #4f97d7;">(</span>y<span style="color: #bc6ec5;">(</span>i<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">,</span>i<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">=</span> <span style="color: #a45bad;">1</span><span style="color: #4f97d7;">;</span>
<span style="color: #4f97d7; font-weight: bold;">endfor</span>

<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">C&#225;lculo totalmente vectorizado:</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Uso la traza (suma de la diagonal principal), pero tambi&#233;n podr&#237;a ser la suma de</span>
<span style="color: #2aa1ae; background-color: #292e34;">%  </span><span style="color: #2aa1ae; background-color: #292e34;">todos los elementos del producto elemento a elemento.</span>
J <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> <span style="color: #4f97d7;">(</span>trace<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">-</span>y_onehot <span style="color: #4f97d7;">*</span> log<span style="color: #2d9574;">(</span>a3<span style="color: #4f97d7;">'</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span> <span style="color: #4f97d7;">-</span> trace<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">(</span><span style="color: #a45bad;">1</span>.<span style="color: #4f97d7;">-</span>y_onehot<span style="color: #2d9574;">)</span> <span style="color: #4f97d7;">*</span> log<span style="color: #2d9574;">(</span><span style="color: #a45bad;">1</span>.<span style="color: #4f97d7;">-</span>a3<span style="color: #4f97d7;">'</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span> <span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>

<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Agrego regularizaci&#243;n</span>
J <span style="color: #4f97d7;">=</span> J <span style="color: #4f97d7;">+</span> <span style="color: #4f97d7;">(</span>lambda<span style="color: #4f97d7;">/</span><span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">*</span>m<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> <span style="color: #4f97d7;">(</span>sum<span style="color: #bc6ec5;">(</span>sum<span style="color: #2d9574;">(</span>Theta1<span style="color: #67b11d;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">:</span>end<span style="color: #67b11d;">)</span><span style="color: #4f97d7;">.^</span><span style="color: #a45bad;">2</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span> <span style="color: #4f97d7;">+</span>  sum<span style="color: #bc6ec5;">(</span>sum<span style="color: #2d9574;">(</span>Theta2<span style="color: #67b11d;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">:</span>end<span style="color: #67b11d;">)</span><span style="color: #4f97d7;">.^</span><span style="color: #a45bad;">2</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
</pre>
</div>

<p>
Sin regularización:
</p>

<p>
\[ J = \frac{1}{m} \times \left( tr( Y \times -log(\hat{Y}) ) - tr(  (1-Y) \times -log(1-\hat{Y})  ) \right)  \]
</p>

<p>
\[ J = \frac{1}{m} \times \left(  \sum \left[ Y \odot -log(\hat{Y})  \right] - \sum \left[ (1-Y) \odot -log(1 - \hat{Y})  \right] \right)   \]
</p>

<ul class="org-ul">
<li>One hot.</li>
<li>Implementé una forma vectorizada de la retropropagación, basada en lo que encontré <a href="https://medium.com/secure-and-private-ai-math-blogging-competition/https-medium-com-fadymorris-understanding-vectorized-implementation-of-neural-networks-dae4115ca185">acá</a>.</li>
</ul>

<div class="org-src-container">
<pre class="src src-octave"><span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">Retropropagaci&#243;n</span>
<span style="color: #2aa1ae; background-color: #292e34;">% </span><span style="color: #2aa1ae; background-color: #292e34;">https://medium.com/secure-and-private-ai-math-blogging-competition/https-medium-com-fadymorris-understanding-vectorized-implementation-of-neural-networks-dae4115ca185</span>
delta3 <span style="color: #4f97d7;">=</span> a3 <span style="color: #4f97d7;">-</span> y_onehot<span style="color: #4f97d7;">;</span>
delta2 <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span>Theta2<span style="color: #4f97d7;">'</span> <span style="color: #4f97d7;">*</span> delta3<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">.*</span> sigmoidGradient<span style="color: #4f97d7;">(</span><span style="color: #bc6ec5;">[</span>ones<span style="color: #2d9574;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">,</span>size<span style="color: #67b11d;">(</span>z2<span style="color: #4f97d7;">,</span><span style="color: #a45bad;">2</span><span style="color: #67b11d;">)</span><span style="color: #2d9574;">)</span><span style="color: #4f97d7;">;</span>z2<span style="color: #bc6ec5;">]</span><span style="color: #4f97d7;">)</span><span style="color: #4f97d7;">;</span>
Delta2 <span style="color: #4f97d7;">=</span> delta3 <span style="color: #4f97d7;">*</span> a2<span style="color: #4f97d7;">';</span>
Delta1 <span style="color: #4f97d7;">=</span> delta2<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">:</span>end<span style="color: #4f97d7;">,</span> <span style="color: #4f97d7;">:</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> a1<span style="color: #4f97d7;">';</span>
D2 <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> Delta2 <span style="color: #4f97d7;">+</span> <span style="color: #4f97d7;">(</span>lambda<span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> <span style="color: #4f97d7;">[</span>zeros<span style="color: #bc6ec5;">(</span>size<span style="color: #2d9574;">(</span>Theta2<span style="color: #4f97d7;">,</span><span style="color: #a45bad;">1</span><span style="color: #2d9574;">)</span><span style="color: #4f97d7;">,</span><span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span> <span style="color: #4f97d7;">,</span> Theta2<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">:</span>end<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">]</span><span style="color: #4f97d7;">;</span>
D1 <span style="color: #4f97d7;">=</span> <span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> Delta1 <span style="color: #4f97d7;">+</span> <span style="color: #4f97d7;">(</span>lambda<span style="color: #4f97d7;">/</span>m<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">*</span> <span style="color: #4f97d7;">[</span>zeros<span style="color: #bc6ec5;">(</span>size<span style="color: #2d9574;">(</span>Theta1<span style="color: #4f97d7;">,</span><span style="color: #a45bad;">1</span><span style="color: #2d9574;">)</span><span style="color: #4f97d7;">,</span><span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">,</span> Theta1<span style="color: #bc6ec5;">(</span><span style="color: #4f97d7;">:,</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">:</span>end<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">]</span><span style="color: #4f97d7;">;</span>
</pre>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-orgbf2cf34" class="outline-2">
<h2 id="orgbf2cf34"><span class="section-number-2">8</span> Semana 6</h2>
<div class="outline-text-2" id="text-8">
<p>
En esta semana vamos a ver cómo evaluar nuestros modelos.
</p>

<ul class="org-ul">
<li>Advice for applying machine learning</li>
<li>Machine learning system design</li>
</ul>

<blockquote>
<p>
To optimize a machine learning algorithm, you’ll need to first understand where the biggest improvements can be made. [&#x2026;]
</p>

<p>
When you're applying machine learning to real problems, a solid grasp of this week's content will easily save you a large amount of work.
</p>
</blockquote>
</div>

<div id="outline-container-orgb10c038" class="outline-3">
<h3 id="orgb10c038"><span class="section-number-3">8.1</span> Evaluating a learning algorithm</h3>
<div class="outline-text-3" id="text-8-1">
</div>
<div id="outline-container-orgc223c92" class="outline-4">
<h4 id="orgc223c92"><span class="section-number-4">8.1.1</span> Deciding what to try next</h4>
<div class="outline-text-4" id="text-8-1-1">
<p>
Algunas cosas que podemos cambiar para intentar mejorar nuestros algoritmos si no estamos satisfechos con los resultados:
</p>
<ul class="org-ul">
<li>Obtener más ejemplos</li>
<li>Generar más descriptores / proponer un modelo más complejo.
<ul class="org-ul">
<li>Sintéticos (modelos más complejos, descriptores polinomiales)</li>
<li>Reales</li>
</ul></li>
<li>Usar menos descriptores / proponer un modelo más simple.</li>
<li>Variar el factor de regularización \(\lambda\).</li>
<li>Aumentar las iteraciones buscando la convergencia.</li>
</ul>

<p>
Algunas de esas decisiones pueden ser muy costosas o largas. Vamos a ver herramientas de diagnóstico que nos pueden dar pista sobre qué es mejor probar.
</p>
</div>
</div>

<div id="outline-container-org22e10ad" class="outline-4">
<h4 id="org22e10ad"><span class="section-number-4">8.1.2</span> Evaluating a hypothesis</h4>
<div class="outline-text-4" id="text-8-1-2">
<p>
Dividimos el conjunto de datos en 2 subconjuntos de muestras aleatorias:
</p>

<ol class="org-ol">
<li>Conjunto de entrenamiento. Sobre estos datos optimizamos nuestros parámetros.</li>
<li>Conjunto de evaluación/prueba. Sobre estos datos evaluamos el desempeño de nuestro modelo.</li>
</ol>

<p>
Para evaluar el desempeño Andrew propone:
</p>

<ul class="org-ul">
<li>En regresión:
<ul class="org-ul">
<li>MSE</li>
</ul></li>
<li>En clasificación:
<ul class="org-ul">
<li>La misma función de costo que usamos para optimizar.</li>
<li>Error medio de predicción / error de clasificación 0/1. Es el error usando las salidas <i>one-hot</i>.</li>
</ul></li>
</ul>

<p>
Tanto en la función de costo \(J_{validation}\) como en la \(J_{test}\) <span class="underline">no incluímos los términos de regularización</span>.
</p>
</div>
</div>


<div id="outline-container-orga5432e0" class="outline-4">
<h4 id="orga5432e0"><span class="section-number-4">8.1.3</span> Model selection and train/validation/test sets</h4>
<div class="outline-text-4" id="text-8-1-3">
<p>
Andrew propone usar usar un tercer subconjunto, intermedio, sobre el cuál podemos evaluar <b>hiperparámetros</b> o parámetros de más alto nivel. Entonces:
</p>

<ol class="org-ol">
<li>Conjunto de entrenamiento
<ul class="org-ul">
<li>60%</li>
<li>Aquí ajustamos los parámetros básicos de nuestro modelo, \(\theta\).</li>
</ul></li>
<li>Conjunto de validación (cruzada)
<ul class="org-ul">
<li>20%</li>
<li>Acá ajustamos parámetros que definen la estructura de nuestro modelo. Por ejemplo, el grado del polinomio de ajuste. O sea que ajustamos los \(\theta\) de modelos con distintos grados \(d\) y elegimos un \(d\) según su desempeño en este conjunto.</li>
</ul></li>
<li>Conjunto de evaluación
<ul class="org-ul">
<li>20%</li>
<li>Acá estimamos el desempeño real de nuestro modelo.</li>
</ul></li>
</ol>
</div>

<ol class="org-ol">
<li><a id="org086589a"></a>Discusión<br />
<div class="outline-text-5" id="text-8-1-3-1">
<p>
No me queda claro por qué no podríamos ajustar parámetros e hiperparámetros en simultáneo. ¿Y con qué criterio distinguimos los unos de los otros?
</p>

<ul class="org-ul">
<li>Otro hiperparámetro podría ser un umbral de clasificación.</li>
</ul>
</div>
</li>
</ol>
</div>
</div>


<div id="outline-container-org32fd80a" class="outline-3">
<h3 id="org32fd80a"><span class="section-number-3">8.2</span> Bias vs variance</h3>
<div class="outline-text-3" id="text-8-2">
</div>
<div id="outline-container-orgc5a5813" class="outline-4">
<h4 id="orgc5a5813"><span class="section-number-4">8.2.1</span> Diagnosing bias vs variance</h4>
<div class="outline-text-4" id="text-8-2-1">
<p>
Cuando tenemos mucho error en el conjunto de validación, hay una forma de saber si es error de sesgo alto o error de varianza alta:
</p>
<ul class="org-ul">
<li>Si \(J_{train} \approx J_{val}\) y ambos son altos, entonces el modelo tiene sesgo alto y está subajustando.</li>
<li>Si \(J_{val} \gg J_{train}\) (suponiendo que estamos minimizando el error), entonces el modelo tiene varianza alta y está sobreajustando.</li>
</ul>


<div class="figure">
<p><img src="./imgs/005-high-bias-vs-high-variance.png" alt="005-high-bias-vs-high-variance.png" />
</p>
</div>
</div>
</div>


<div id="outline-container-org2d8df98" class="outline-4">
<h4 id="org2d8df98"><span class="section-number-4">8.2.2</span> Regularization and bias/variance</h4>
<div class="outline-text-4" id="text-8-2-2">
<p>
El comportamiento de las funciones de costo respecto a \(\lambda\) es espejado al que se observa según el grado del polinomio; esto es, \(J_train\) crece proporcionalmente a \(\lambda\).
</p>

<p>
Andrew propone elegir un conjunto de valores posibles de \(\lambda\) y evaluarlos para cada uno de los posibles valores de \(d\).
</p>

<p>
Algo interesante comentado en <a href="https://www.coursera.org/learn/machine-learning/discussions/weeks/6/threads/P3Cp9j_ZEeaDRA5SxbW7qQ">las preguntas frecuentes de la semana 6</a>, respecto a hacerlo de forma secuencial:
</p>

<blockquote>
<p>
Q5) What does Prof Ng mean when he says we're "fitting another parameter 'd' to the CV set"?
</p>

<p>
We use the CV set to make adjustments to the model. Prof Ng is referring to adjusting both the regularization and the polynomial degree.
</p>

<p>
But there is a problem.
</p>

<p>
Each subset of data can only be used for one purpose. If you have one CV set and use it to adjust the regularization, then you cannot continue using the same CV set to select the best polynomial degree. This would result in overfitting the CV set.
</p>

<p>
One solution is to further split the data set so you have two CV sets, and use one to adjust the regularization, and the second to select the best polynomial degree. But this increases the amount of labeled data that is needed.
</p>

<p>
A second solution is possible. You can create all possible combinations of the parameters 'd' and lambda, and evaluate each combination using only one validation set. You then select the combination that gives the lowest validation set error. Only one CV set is needed.
</p>
</blockquote>
</div>
</div>

<div id="outline-container-orgef2b313" class="outline-4">
<h4 id="orgef2b313"><span class="section-number-4">8.2.3</span> Learning curves</h4>
<div class="outline-text-4" id="text-8-2-3">
<p>
Las gráficas de aprendizaje muestran la variación de los errores de entrenamiento y validación ante el cambio de cantidad de muestras de entrenamiento, para una complejidad de modelo fija.
</p>

<p>
Cuando nuestro modelo sufre de alto sesgo, vemos que \(J_{train}\) y \(J_{CV}\) pronto se estancan en un valor. El modelo no puede explicar más variación.
</p>


<div class="figure">
<p><img src="./imgs/006-1-learning-curves.png" alt="006-1-learning-curves.png" />
</p>
</div>

<p>
Para un modelo con alta varianza, las curvas varían lentamente y tienden a converger, pero van a necesitar de muchos ejemplos para poder encontrar la generalización.
</p>


<div class="figure">
<p><img src="./imgs/006-2-learning-curves.png" alt="006-2-learning-curves.png" />
</p>
</div>

<p>
Estaría bueno tener una gráfica de como varían esas curvas al cambiar la complejidad del modelo&#x2026;
</p>
</div>
</div>

<div id="outline-container-orgb77e221" class="outline-4">
<h4 id="orgb77e221"><span class="section-number-4">8.2.4</span> Deciding what to do next revisited</h4>
<div class="outline-text-4" id="text-8-2-4">
<hr />

<p>
La regularización sirve para forzar la exploración de todo el espacio de parámetros, y bajo la suposición de que los descriptores están normalizados. La regularización intenta que todos los descriptores afecten en la decisión, y esto puede ser mentira. Me parece que sería mejor atacar el problema con la complejidad del modelo, no con regularización.
</p>
</div>
</div>
</div>

<div id="outline-container-orgf0045ec" class="outline-3">
<h3 id="orgf0045ec"><span class="section-number-3">8.3</span> Review</h3>
<div class="outline-text-3" id="text-8-3">
</div>
<div id="outline-container-org7679efd" class="outline-4">
<h4 id="org7679efd"><span class="section-number-4">8.3.1</span> Quiz: advice for applying machine learning</h4>
</div>

<div id="outline-container-orgdd50455" class="outline-4">
<h4 id="orgdd50455"><span class="section-number-4">8.3.2</span> Programming assignment: regularized linear regression and bias/variance</h4>
</div>
</div>

<div id="outline-container-orge3732d5" class="outline-3">
<h3 id="orge3732d5"><span class="section-number-3">8.4</span> Building a spam classifier</h3>
<div class="outline-text-3" id="text-8-4">
</div>
<div id="outline-container-orga105ce9" class="outline-4">
<h4 id="orga105ce9"><span class="section-number-4">8.4.1</span> Prioritizing what to work on</h4>
</div>

<div id="outline-container-org8b908ac" class="outline-4">
<h4 id="org8b908ac"><span class="section-number-4">8.4.2</span> Error analysis</h4>
<div class="outline-text-4" id="text-8-4-2">
<ul class="org-ul">
<li>Hacer una implementación rápida de un clasificador y sus pruebas, para tener información de en qué paso gastar tiempo a continuación. Esto es importante.</li>
<li>Podemos construir curvas de aprendizaje para ver si necesitamos más o menos ejemplos, modelos más complejos, etcétera.</li>
<li>Podemos analizar manualmente los casos mal clasificados (o con mucho error en caso de regresión, supongo), para intentar observar patrones.</li>
<li>Siempre es bueno tener una única métrica de evaluación. Esta nos va a permitir discernir si una estrategia es buena o no.</li>
<li>Es muy recomendable evaluar las cosas en los conjuntos de validación cruzada, no en el conjunto de evaluación. Nunca ajustamos nada en el conjunto de evaluación.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org431b8d4" class="outline-3">
<h3 id="org431b8d4"><span class="section-number-3">8.5</span> Handling skewed data</h3>
<div class="outline-text-3" id="text-8-5">
</div>
<div id="outline-container-org0f90152" class="outline-4">
<h4 id="org0f90152"><span class="section-number-4">8.5.1</span> Error metrics for skewed classes</h4>
<div class="outline-text-4" id="text-8-5-1">
<p>
En clasificación (¿binaria?) en la distribución de las clases está muy sesgada (una de las clases es muy rara, tiene poca frecuencia), no es apropiado usar la precisión como métrica. Aquí corresponde analizar la precisión y la exhaustividad (<i>recall</i>).
</p>


<div class="figure">
<p><img src="./imgs/007- precisionrecall.svg.png" alt="007- precisionrecall.svg.png" />
</p>
</div>

<p>
Podemos variar el comportamiento del modelo al modificar el umbral de decisión a la salida (esto es un hiperparámetro, y lo evaluamos en el conjunto de validación).
</p>
</div>
</div>

<div id="outline-container-org4a20065" class="outline-4">
<h4 id="org4a20065"><span class="section-number-4">8.5.2</span> Trading off precision and recall</h4>
<div class="outline-text-4" id="text-8-5-2">
<p>
Una métrica que incluye la precisión y la exhaustividad es el Valor F (<i>F score</i>), que se define como la media armónica (ponderada) de la precisión y exhaustividad.
</p>

<p>
\[ F_\beta = (1 + \beta^2) \frac{precision \cdot recall}{(\beta^2 \cdot precision) + recall}  \]
</p>

<p>
\(\beta\) es cuántas veces es la exhaustividad más importante que la precisión. Normalmente se usa \(\beta = 1\), obteniendo la métrica \(F_1\) que pondera de igual manera la precisión y la exhaustividad.
</p>

<p>
\[ F_\beta \in [0, 1] \]
</p>
</div>
</div>
</div>


<div id="outline-container-orga2dc170" class="outline-3">
<h3 id="orga2dc170"><span class="section-number-3">8.6</span> Using large datasets</h3>
<div class="outline-text-3" id="text-8-6">
</div>
<div id="outline-container-org896ffb7" class="outline-4">
<h4 id="org896ffb7"><span class="section-number-4">8.6.1</span> Data for machine learning</h4>
<div class="outline-text-4" id="text-8-6-1">
<p>
Si tenemos
</p>

<ul class="org-ul">
<li>un conjunto de descriptores suficientemente expresivo como para determinar correctamente la salida a partir de ellos (si un humano experto puede hacerlo a partir de esas entradas, el sistema también podrá);</li>
<li>un modelo complejo, de poco sesgo, que no se va a sobreajustar;</li>
</ul>

<p>
entonces la forma de mejorar los resultados es con más y más datos de entrenamiento.
</p>

<p>
En la publicación <a href="https://www.microsoft.com/en-us/research/publication/mitigating-the-paucity-of-data-problem-exploring-the-effect-of-training-corpus-size-on-classifier-performance-for-natural-language-processing/">"Mitigating the Paucity-of-Data Problem: Exploring the Effect of Training Corpus Size on Classifier Performance for Natural Language Processing" de Michele Banko y Eric Brill</a> se prueban varios modelos complejos y se observa que su desempeño tiende a ser el mismo, y además crece monotónicamente con la cantidad de ejemplos de entrenamiento.
</p>
</div>
</div>
</div>

<div id="outline-container-org6f8aac5" class="outline-3">
<h3 id="org6f8aac5"><span class="section-number-3">8.7</span> Review</h3>
<div class="outline-text-3" id="text-8-7">
</div>
<div id="outline-container-org04ec7a3" class="outline-4">
<h4 id="org04ec7a3"><span class="section-number-4">8.7.1</span> Quiz: machine learning system design</h4>
</div>
</div>
</div>

<div id="outline-container-orgc0cdcad" class="outline-2">
<h2 id="orgc0cdcad"><span class="section-number-2">9</span> Semana 7</h2>
<div class="outline-text-2" id="text-9">
<p>
Vamos a ver <i>SVMs</i>: máquinas de vector soporte / máquinas de soporte vectorial.
</p>
</div>

<div id="outline-container-orgbb9512e" class="outline-3">
<h3 id="orgbb9512e"><span class="section-number-3">9.1</span> Large margin classification</h3>
<div class="outline-text-3" id="text-9-1">
</div>
<div id="outline-container-org7526418" class="outline-4">
<h4 id="org7526418"><span class="section-number-4">9.1.1</span> Optimization objective</h4>
<div class="outline-text-4" id="text-9-1-1">
<p>
Vamos a ver un algoritmo de aprendizaje supervisado más: las máquinas de soporte vectorial. Primero definimos una función de costo a optimizar, que es similar a la que usamos para regresión logística.
</p>

<p>
\[  J(\theta) = C \sum_{i=1}^m \left[ y^{(i)} cost_1(\theta x^{(i)}) + (1-y^{(i)}) cost_0(1 - \theta x^{(i)}) \right]  + \frac{1}{2}  \sum_{v=1}^{n} \theta_v  \]
</p>

<ul class="org-ul">
<li><span class="underline">Este es un caso de clasificación binaria</span>.</li>
<li>\(C\) es equivalente a \(1/\lambda\), y es un factor que sirve para ponderar la optimización del primer término sobre el otro.</li>
<li>Las funciones \(cost_0\) y \(cost_1\) son muy similares al menos logaritmo de la función logística (lo que estaba ahí en la función de costo que usamos para regresión logística). Parecen funciones rampa, con base en \(0\) y crecimiento en \(1\) y \(-1\) respectivamente.</li>
</ul>

<p>
La función de hipótesis (que todavía no vemos) no emite probabilidades, sino una salida discreta, que definimos con un umbral en \(0\):
</p>

<p>
\[  h_\theta(x) = 1 \quad si \quad \theta^T x \ge 0   \]
\[  h_\theta(x) = 0 \quad si \quad \theta^T x \lt 0  \]
</p>

<hr />

<p>
Resulta que \(cost_0\) y \(cost_1\) se llaman funciónes de pérdida bisagra (<a href="https://en.wikipedia.org/wiki/Hinge_loss"><i>hinge loss</i></a>).
</p>

<p>
\[ l(\hat{y}) = \max(0, 1-t \cdot \hat{y}) \]
</p>

<p>
donde \( y = \pm  1 \) es la salida deseada.
</p>

<p>
Resulta además que la función de hipótesis es simplemente una combinación lineal de los descriptores de entrada, definida por los parámetros y a la que luego se le aplica un umbral en 0. Más tarde vamos a remplazar los descriptores, para lograr fronteras no lineales.
</p>
</div>
</div>

<div id="outline-container-org68506cc" class="outline-4">
<h4 id="org68506cc"><span class="section-number-4">9.1.2</span> Large margin intuition</h4>
<div class="outline-text-4" id="text-9-1-2">
<p>
La minimización nos da parámetros que definen una frontera óptima de separación entre clases. La frontera es óptima en términos de maximizar los márgenes, los espacios entre la frontera y los datos.
</p>

<ul class="org-ul">
<li>A menor C, más regularización y menos sobreajuste.</li>
</ul>
</div>

<ol class="org-ol">
<li><a id="orgb273234"></a><span class="done DONE">DONE</span> Revisar esto y abajo<br />
<div class="outline-text-7" id="text-9-1-2-0-0-1">
</div>
</li>
</ol>
</div>

<div id="outline-container-org5bc82bd" class="outline-4">
<h4 id="org5bc82bd"><span class="section-number-4">9.1.3</span> Mathematics behind large margin classification</h4>
<div class="outline-text-4" id="text-9-1-3">
<p>
No se entendió.
</p>

<p>
Ya lo entendí&#x2026; sirve para justificar la explicación del título anterior.
</p>
</div>
</div>
</div>

<div id="outline-container-orgbd55267" class="outline-3">
<h3 id="orgbd55267"><span class="section-number-3">9.2</span> Kernels</h3>
<div class="outline-text-3" id="text-9-2">
</div>
<div id="outline-container-orgc3c8683" class="outline-4">
<h4 id="orgc3c8683"><span class="section-number-4">9.2.1</span> Kernels I</h4>
</div>



<div id="outline-container-orge1ea950" class="outline-4">
<h4 id="orge1ea950"><span class="section-number-4">9.2.2</span> Kernels II</h4>
<div class="outline-text-4" id="text-9-2-2">
<p>
En estos videos entendí un poco más y voy a intentar explicar todo acá.
</p>

<p>
En las <i>SVMs</i> nuestra función de hipótesis define un hiperplano de decisión. La optimización maximiza el margen entre ese hiperplano y los ejemplos de entrenamiento, a ambos lados del hiperplano.
</p>

<p>
Una forma de hacerlo sería como lo hicimos en regresión lineal: agregando descriptores de mayor orden, a partir de los descriptores iniciales.
</p>

<p>
Acá hacemos otra cosa: mapeamos nuestro conjunto de descriptores a otro conjunto de descriptores (no necesariamente del mismo tamaño). Este nuevo conjunto son distancias definidas por funciones de similitud / funciones de distancia. ¿Distancia a dónde? La distancia es en el espacio de descriptores originales, entre las entradas y puntos de referencia (<i>landmarks</i>). Como puntos de referencia usamos <i>cada uno de los ejemplos de entrenamiento</i>.
</p>

<p>
A las funciones de distancia también se denomina <i>kernels</i> o núcleos. Ahora vimos un <i>kernel</i> gaussiano:
</p>

<p>
\[  f_i = similarity(x, l^{(i)} ) = e^{\frac{||x - l{(i)}||^2}{s\sigma^2}} = exp(\frac{||x - l{(i)}||^2}{s\sigma^2}) \]
</p>

<ul class="org-ul">
<li>Esta es una gaussiana de altura 1, y \(\sigma\) define su "anchura".
<ul class="org-ul">
<li>La similaridad será \(\approx1\) si la entrada está cerca de esa referencia, y \(0\) si está lejos.</li>
</ul></li>
<li>Mientras más grande \(\sigma\), la función es menos discriminativa, más suavizada. Entonces \(\sigma\) actúa como otro parámetro de regularización.</li>
</ul>

<p>
Nótese que luego deberemos mapear cada entrada al espacio de distancias, y ahí predecir la clase.
</p>

<p>
<b>Entonces al aplicar el <i>kernel</i> estamos convirtiendo un problema no lineal en uno lineal</b>. También hacíamos esto al agregar parámetros no lineales en regresión lineal o logística.
</p>

<p>
¿Por qué no usamos estas funciones de distancia en regresión lineal? En realidad si podemos, pero por cierta matemática de la implementación, esto es mucho más rápido en las SVMs. <span class="underline">Nótese que el espacio transformado de descriptores es de \(m\) dimensiones, donde \(m\) es el número de ejemplos de entrenamiento</span>.
</p>
</div>
</div>
</div>

<div id="outline-container-orgcdd4443" class="outline-3">
<h3 id="orgcdd4443"><span class="section-number-3">9.3</span> SVMs in practice</h3>
<div class="outline-text-3" id="text-9-3">
</div>
<div id="outline-container-orgc764302" class="outline-4">
<h4 id="orgc764302"><span class="section-number-4">9.3.1</span> Using an SVM</h4>
<div class="outline-text-4" id="text-9-3-1">
<p>
Si bien hay más funciones de distancia o <i>kernels</i> normalmente se usan dos:
</p>
<ul class="org-ul">
<li><i>kernel</i> lineal (en realidad, sin <i>kernel</i>) es cuando no usamos función de distancia (lo que hicimos al principio) y \(\hat{y}=1 \quad si \quad h(\theta^T x) \ge 0\). Esto es muy similar en resultados a una regresión logística.</li>
<li><i>kernel</i> gaussiano.</li>
</ul>

<p>
Las soluciones se encuentran con algoritmos especializados para <i>SVM</i>. Les tenemos que dar la función de distancia y listo.
</p>

<p>
<b>Es importante normalizar los descriptores (hacer <i>feature scaling</i>) antes de calcular nos nuevos descriptores de distancia</b>. Al normalizar hacemos comparables los distintos descriptores, <b>ponderamos su información de igual manera</b>.
</p>

<p>
La función de costo que optimizamos (definida anteriormente) es convexa, y por tanto siempre encontramos el mínimo global.
</p>

<p>
Los algoritmos pueden soportar multiclase. Si no, hacemos el clásico "uno contra todos".
</p>
<ul class="org-ul">
<li>Para \(K\) clases necesitamos \(K\) clasificadores.</li>
</ul>
</div>

<ol class="org-ol">
<li><a id="org2e01b82"></a>Cuándo usar<br />
<div class="outline-text-5" id="text-9-3-1-1">
<p>
Sean
</p>
<ul class="org-ul">
<li>\(n\) el número de descriptores/parámetros.</li>
<li>\(m\) el número de ejemplos de entrenamiento.</li>
</ul>


<p>
Entonces
</p>

<ol class="org-ol">
<li>Si \(\frac{n}{m} \ge 10\), el sistema está subdeterminado y es mejor intentar con un modelo simple. Tenemos pocos datos y con un modelo complejo nos arriesgamos a sobreajustar. Aquí podemos usar regresión logística o <i>SVM</i> con <i>kernel</i> lineal, que es equivalente.</li>

<li>Si \(\frac{m}{n} \ge 10\), el sistema está sobredeterminado. Acá deberíamos usar un modelo complejo que permita capturar la influencia de todos los descriptores. Aquí es donde brillan las <i>SVM</i> con <i>kernel</i> gaussiano.

<ul class="org-ul">
<li>Si \(m\) es muy grande (\(\gt10000\)), entonces una <i>SVM</i> con <i>kernel</i> gaussiano tarda mucho en entrenar. Entonces podemos usar regresión logística o un <i>kernel</i> lineal, junto con la adición de nuevos descriptores sintéticos. Esto es solo por una limitación de poder de cómputo.</li>
</ul></li>
</ol>

<p>
Dice Andrew que en ambos casos también podríamos usar redes neuronales, pero estas tardan más en entrenar.
</p>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-orgb25f6cf" class="outline-3">
<h3 id="orgb25f6cf"><span class="section-number-3">9.4</span> Review</h3>
<div class="outline-text-3" id="text-9-4">
</div>
<div id="outline-container-org75f0d27" class="outline-4">
<h4 id="org75f0d27"><span class="section-number-4">9.4.1</span> Quiz: support vector machines</h4>
</div>

<div id="outline-container-orgfb4a2d6" class="outline-4">
<h4 id="orgfb4a2d6"><span class="section-number-4">9.4.2</span> Programming assignment SVMs</h4>
<div class="outline-text-4" id="text-9-4-2">
<p>
Usé <code>containers.Map</code> para crear un mapeo, como los diccionarios de Python.
</p>
</div>
</div>
</div>

<div id="outline-container-org76fc964" class="outline-3">
<h3 id="org76fc964"><span class="section-number-3">9.5</span> Otras cosas</h3>
<div class="outline-text-3" id="text-9-5">
</div>
<div id="outline-container-org84c670d" class="outline-4">
<h4 id="org84c670d"><span class="section-number-4">9.5.1</span> <a href="https://www.youtube.com/watch?v=3liCbRZPrZA">https://www.youtube.com/watch?v=3liCbRZPrZA</a> SVM with polynomial kernel visualization</h4>
<div class="outline-text-4" id="text-9-5-1">
<blockquote>
<p>
Technically what is visualized here isn't "the kernel trick". This is the general idea of how nonlinearly projecting some points into a higher-dimensional feature space makes linear classifiers more powerful. You can do this with out SVMs. Just compute the high-dimensional features corresponding to your data, then use logistic regression or whatever. Trouble is, if the higher-dimensional space is really big, this could be expensive. The "kernel trick" is computational trick that SVMs use to compute the inner product between the high-dimensional features corresponding to two points with out explicitly computing the high-dimensional features. (For certain special feature spaces.)
</p>

<p>
But this is definitely a cool visualization of the value of feature spaces! 
</p>
</blockquote>
<p>
<a href="https://news.ycombinator.com/item?id=1299733">https://news.ycombinator.com/item?id=1299733</a>
</p>
</div>
</div>


<div id="outline-container-orgd4ace66" class="outline-4">
<h4 id="orgd4ace66"><span class="section-number-4">9.5.2</span> <a href="https://ranvir.xyz/blog/svm-support-vector-machines-in-machine-learning/">https://ranvir.xyz/blog/svm-support-vector-machines-in-machine-learning/</a></h4>
<div class="outline-text-4" id="text-9-5-2">
<p>
Discusión en <a href="https://news.ycombinator.com/item?id=23035120">https://news.ycombinator.com/item?id=23035120</a>
</p>

<ul class="org-ul">
<li><a href="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers">https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</a></li>
<li><a href="http://www.stat.columbia.edu/~gelman/book/">http://www.stat.columbia.edu/~gelman/book/</a></li>
<li>"Statistical Rethinking" by McElreath</li>
<li>Introduction to Statistical Learning <a href="https://faculty.marshall.usc.edu/gareth-james/ISL/">https://faculty.marshall.usc.edu/gareth-james/ISL/</a></li>
<li>Elements of Statistical Learning <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">https://web.stanford.edu/~hastie/ElemStatLearn/</a></li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-org88fd031" class="outline-2">
<h2 id="org88fd031"><span class="section-number-2">10</span> Semana 8: Unsupervised learning</h2>
<div class="outline-text-2" id="text-10">
<p>
Vamos a ver algo de aprendizaje no supervisado. Acá no tenemos entradas y salidas etiquetadas; solo un conjunto de datos de entrada de los cuáles queremos entender la estructura subyacente.
También vemos algo de reducción de la dimensionalidad del problema.
</p>
</div>

<div id="outline-container-org04dd254" class="outline-3">
<h3 id="org04dd254"><span class="section-number-3">10.1</span> Clustering</h3>
<div class="outline-text-3" id="text-10-1">
</div>
<div id="outline-container-org731ba36" class="outline-4">
<h4 id="org731ba36"><span class="section-number-4">10.1.1</span> Unsupervised learning: introduction</h4>
<div class="outline-text-4" id="text-10-1-1">
<p>
Buscamos ver si hay conjuntos de datos que presentan características similares, con las cuáles podríamos agruparlos.
</p>

<p>
También podemos usar algoritmos de agrupamiento cuando nosotros queremos agrupar los datos en un número arbitrario de grupos. Por ejemplo, podríamos querer tener K segmentos de mercado.
</p>
</div>
</div>

<div id="outline-container-org53a9d8b" class="outline-4">
<h4 id="org53a9d8b"><span class="section-number-4">10.1.2</span> K-means algorithm</h4>
<div class="outline-text-4" id="text-10-1-2">
<p>
<b>Acá trabajamos los ejemplos en sus \(n\) dimensiones originales; no agregamos el \(x_0=1\) que nos facilitaba trabajar con los interceptos.</b>
</p>

<p>
Sean:
</p>

<ul class="org-ul">
<li>\(K\): el número de grupos que queremos tener, indexado con \(k\).</li>
<li>\(\mu_k\): el centroide / centro de masa del grupo \(k\).</li>
<li>\(c^{(i)}\): el grupo asignado al ejemplo \(i\). Es el grupo que tiene la menor distancia entre su centroide y el ejemplo. Hay varias métricas de distancia; la más común es la euclidea.</li>
<li>\(\mu_{c^{(i)}}\): el centroide del grupo / <i>cluster</i> del ejemplo \(i\).</li>
</ul>


<p>
El algoritmo es:
</p>

<ul class="org-ul">
<li>Hasta la convergencia o llegar a un número de interaciones:
<ul class="org-ul">
<li>Etiquetar cada ejemplo \((i)\), asignándole un grupo \(c^{(i)}\).</li>
<li>Recalcular los centroides de cada grupo. El nuevo valor de un centroide \(\mu_k\) será el centro de masa de los ejemplos etiquetados con \(k\) (\(c^{(i)}=k\)).</li>
</ul></li>
</ul>

<p>
Si un grupo \(k\) no tiene ejemplos tras alguna iteración, lo podemos eliminar.
</p>
</div>
</div>


<div id="outline-container-org7cf27bf" class="outline-4">
<h4 id="org7cf27bf"><span class="section-number-4">10.1.3</span> Optimization objective</h4>
<div class="outline-text-4" id="text-10-1-3">
<p>
La función que estamos optimizando es:
</p>

<p>
\[ J(c^{(1)}, \dots, c^{(m)} , \mu_1, \dots, \mu_k ) = \frac{1}{m} \sum_1^m || x^{(i)} - \mu_{c^{(i)}} ||^2 \]
</p>

<p>
Es conocida como <i>distorsión</i> del algoritmo <i>K-means</i>.
</p>

<p>
El algoritmo primero optimiza \(c\), manteniendo \(\mu\) constante, y después lo hace a la inversa.
</p>

<p>
<b>No es una función convexa</b>, lo que implica que podemos tener más de un mínimo.
</p>

<p>
La función de costo <span class="underline">debe</span> disminuir en cada iteración.
</p>
</div>
</div>

<div id="outline-container-org7140df5" class="outline-4">
<h4 id="org7140df5"><span class="section-number-4">10.1.4</span> Random initialization</h4>
<div class="outline-text-4" id="text-10-1-4">
<p>
La configuración óptima que encontremos al minimizar se ve influenciada por cómo inicializamos los centroides. La forma recomendada es asignarles la posición de un ejemplo cualquiera (distinto a cada uno).
</p>

<p>
Para buscar la solución global, ejecutamos el algoritmo muchas veces y nos quedamos con aquella solución de menor distorsión.
</p>

<ul class="org-ul">
<li>Es importante hacer esto cuando K es chico (Andrew dice 2 a 10), pero no tan necesario cuando estamos buscando muchos grupos.</li>
</ul>
</div>
</div>

<div id="outline-container-org2e77757" class="outline-4">
<h4 id="org2e77757"><span class="section-number-4">10.1.5</span> Choosing the number of clusters</h4>
<div class="outline-text-4" id="text-10-1-5">
<p>
<b>La función de costo debe disminuir a medida que incrementamos K</b>, llegando al mínimo cuando \(K=m\). Si no ocurre para un cierto \(K\), es que tuvimos un resultado de un mínimo local no bueno.
</p>

<p>
El número se suele elegir a ojo, observando los datos, o está determinado por el problema en el cuál vamos a usar nuestro agrupamiento.
</p>

<p>
Una forma de elegir el número de grupos es con el "método del codo". Este consiste en graficar la función de costo según el valor de \(K\), y elegir el vértice de la gráfica descendente. Si no hay vértice claramente observable, entonces no nos sirve el método.
</p>
</div>
</div>
</div>

<div id="outline-container-org195f42b" class="outline-3">
<h3 id="org195f42b"><span class="section-number-3">10.2</span> Review</h3>
<div class="outline-text-3" id="text-10-2">
</div>
<div id="outline-container-org6c5e15d" class="outline-4">
<h4 id="org6c5e15d"><span class="section-number-4">10.2.1</span> Quiz: Unsuperised learning</h4>
</div>
</div>

<div id="outline-container-org67dba36" class="outline-3">
<h3 id="org67dba36"><span class="section-number-3">10.3</span> Dimensionality reduction</h3>
<div class="outline-text-3" id="text-10-3">
</div>
<div id="outline-container-orgf3a26c1" class="outline-4">
<h4 id="orgf3a26c1"><span class="section-number-4">10.3.1</span> Motivation</h4>
<div class="outline-text-4" id="text-10-3-1">
</div>
<ol class="org-ol">
<li><a id="org1d70967"></a>Motivation I: Data compression<br />
<div class="outline-text-5" id="text-10-3-1-1">
<p>
Otro tipo de aprendizaje no supervisado se usa para reducir la dimensionalidad de nuestro universo representado. Esto es, representar la misma información pero con menos descriptores. Esto nos va a permitir tener representaciones más compactas (menos memoria) y sobre todo, acelerar la búsqueda de soluciones.
</p>
</div>
</li>

<li><a id="org6397efb"></a>Motivation II Visualization<br />
<div class="outline-text-5" id="text-10-3-1-2">
<p>
Otro aplicación de la reducción de dimensionalidad es para intentar visualizar nuestros datos. La visualización suele ayudarnos a entender los datos y proponer mejores soluciones.
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-org72089d7" class="outline-4">
<h4 id="org72089d7"><span class="section-number-4">10.3.2</span> Principal component analysis</h4>
<div class="outline-text-4" id="text-10-3-2">
</div>
<ol class="org-ol">
<li><a id="orga67acff"></a>Principal component analysis formulation<br />
<div class="outline-text-5" id="text-10-3-2-1">
<p>
<b>Acá trabajamos los ejemplos en sus \(n\) dimensiones originales; no agregamos el \(x_0=1\) que nos facilitaba trabajar con los interceptos.</b>
</p>

<p>
El algoritmo más usado para reducción dimensional es el llamado "Análisis de componentes principales" (<i>Principal Component Analysis, PCA</i>). Para el (hiper)espacio de representación de nuestros descriptores, <i>PCA</i> busca determinar el hiperplano que minimice las distancias entre los puntos en el hiperespacio y sus proyecciones (ortogonales) en el hiperplano.
</p>
</div>
</li>

<li><a id="org2c27ecd"></a>Principal component analysis algorithm<br />
<div class="outline-text-5" id="text-10-3-2-2">
<p>
No vamos a ver demostraciones, pero la cosa es más o menos así.
</p>

<p>
Primero debemos normalizar/escalar los valores de entrada, para que estén en dimensiones comparables.
</p>

<p>
Luego construimos la matriz de covarianza, que tiene las covarianzas de las dimensiones. // La <a href="https://en.wikipedia.org/wiki/Covariance">covarianza</a> indica dependencia entre dimensiones. Si la covarianza es 0, las dimensiones son independientes.
</p>

<p>
\[ \Sigma = \frac{1}{m} \sum_{i=1}^m x^{(i)} (x^{(i)})^T = \frac{1}{m} X^T X \]
</p>

<p>
Ahora aplicamos la Descomposición en valores singulares (<i>SVD, Singular Value Decomposition</i>), que es una factorización que nos permite obtener los vectores propios o autovectores de la matriz de covarianza.
</p>

<p>
\[ U_{m \times k}, S, V = svd(\Sigma)  \]
</p>

<p>
Nos importa la matriz \(U\), que tiene autovectores. Cada columna es un autovector, y estos son las dimensiones (¿rotadas? distintas.) que ¿mejor? explican nuestros datos. De esta matriz \(U\) nos vamos a quedar con los primeros \(k\) vectores, que serán nuestro nuevo espacio de representación. Construimos entonces una matriz \(U_{reducción}\).
</p>

<p>
Para expresar los vectores en las nuevas dimensiones, hacemos
</p>

<p>
\[ z^{(i)} = U_{reducción}^T x^{(i)} \]
</p>

<p>
O para todos los ejemplos:
</p>

<p>
\[ Z = X U_{reducción} \]
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-org04565fd" class="outline-4">
<h4 id="org04565fd"><span class="section-number-4">10.3.3</span> Appliying PCA</h4>
<div class="outline-text-4" id="text-10-3-3">
</div>
<ol class="org-ol">
<li><a id="orgdc8623b"></a>Reconstruction from compressed representation<br />
<div class="outline-text-5" id="text-10-3-3-1">
<p>
Para volver del espacio \(R^k\) al \(R^n\), usamos la matriz \(U\) así:
</p>

<p>
\[  x_{aprox}^{(i)} = U_{reducción}  x^{(i)} \]
</p>

<p>
O para todos los ejemplos:
</p>

<p>
\[ X_aprox = X U_{reducción}^T \]
</p>

<ul class="org-ul">
<li>Nótese que lo que obtenemos es una aproximación de el dato original. Esta aproximación es la proyección del dato original en el hiperplano de menor dimensión calculado con <i>PCA</i>, pero expresado en las \(n\) dimensiones originales.
<ul class="org-ul">
<li>Perdemos información.</li>
</ul></li>
</ul>
</div>
</li>

<li><a id="orga97eac8"></a>Choosing the number of principal components<br />
<div class="outline-text-5" id="text-10-3-3-2">
<p>
Sean
</p>

<ul class="org-ul">
<li>Error medio de proyección: \( E_{p} = \frac{1}{m} \sum_{i=1}^{m} || x^{(i)} - x_{aprox}^{(i)} ||^2 \)</li>
<li>Varianza de los datos: \( V = \frac{1}{m} \sum_{i=1}^{m} ||x^{(i)}||^2  \)</li>
</ul>

<p>
Podemos definir la varianza no explicada / no retenida por nuestro modelo de dimensiones reducidas como
</p>

<p>
\[ V_{ne} = \frac{\frac{1}{m} \sum_{i=1}^{m} || x^{(i)} - x_{aprox}^{(i)} ||^2}{\frac{1}{m} \sum_{i=1}^{m} ||x^{(i)}||^2}  \]
</p>

<p>
\[ V_{ne} = \frac{\sum_{i=1}^{m} || x^{(i)} - x_{aprox}^{(i)} ||^2}{\sum_{i=1}^{m} ||x^{(i)}||^2}  \]
</p>

<ul class="org-ul">
<li>Normalmente buscamos que \(V_{ne}\) sea menor al \(5%\) o \(1%\), pero depende del caso.</li>
<li>En modelos de alta dimensionalidad es frecuente encontrar que muchas dimensiones están correlacionadas y por tanto podemos encontrar un \(k\ll n\).</li>
</ul>

<p>
Para calcular \(V_{ne}\) como lo definimos anteriormente, debemos hacer todo el proceso de <i>PCA</i> para un \(k\) dado, para luego calcular los errores de proyección. Esto es costoso.
</p>

<p>
Una mejor forma de hacerlo es con la matriz \(S\) obtenida al hacer <i>SVD</i>:
</p>

<p>
\[ U_{m \times k}, S, V = svd(\Sigma)  \]
</p>

<p>
Esta tiene (en su diagonal principal) los autovalores \(s_{ii}\) asociados con los autovectores de \(U\), y al igual que estos, están ordenados de mayor a menor importancia o influencia. Podemos hacer entonces:
</p>

<p>
\[ V_{ne} = 1 - \frac{ \sum_{i=1}^k s_{ii} }{ \sum_{i=1}^n s_{ii} } \]
</p>

<p>
y fácilmente definimos el \(k\) que queremos.
</p>
</div>
</li>


<li><a id="orgc4c8635"></a>Advice for appliying PCA<br />
<div class="outline-text-5" id="text-10-3-3-3">
<p>
Algunos consejos:
</p>

<ol class="org-ol">
<li><b>No</b> usar <i>PCA</i> como herramienta para reducir sobreajuste. Puede funcionar, pero al usar <i>PCA</i> no estamos teniendo en cuenta las etiquetas de los datos de entrada, y quizás estamos desechando información importante, o grupos enteros de datos. La regulrización es el método que deberíamos usar en su lugar.</li>
<li>No usar <i>PCA</i> de entrada, por que sí. Deberíamos siempre probar con los datos crudos, y usar <i>PCA</i> si queremos acelerar el aprendizaje o usar menos espacio, por ejemplo.</li>
</ol>
</div>
</li>
</ol>
</div>

<div id="outline-container-orgc387e07" class="outline-4">
<h4 id="orgc387e07"><span class="section-number-4">10.3.4</span> Review</h4>
<div class="outline-text-4" id="text-10-3-4">
</div>
<ol class="org-ol">
<li><a id="org10ee7c3"></a>Quiz: principal component analysis<br /></li>

<li><a id="orgcc0b299"></a>Programming assignment: K-means clustering and PCA<br /></li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org2cd401c" class="outline-2">
<h2 id="org2cd401c"><span class="section-number-2">11</span> Semana 9: Anomaly detection &amp; Recommender systems</h2>
<div class="outline-text-2" id="text-11">
</div>
<div id="outline-container-org0efb50a" class="outline-3">
<h3 id="org0efb50a"><span class="section-number-3">11.1</span> Anomaly detection</h3>
<div class="outline-text-3" id="text-11-1">
</div>
<div id="outline-container-org909db7b" class="outline-4">
<h4 id="org909db7b"><span class="section-number-4">11.1.1</span> Density estimation</h4>
<div class="outline-text-4" id="text-11-1-1">
</div>
<ol class="org-ol">
<li><a id="orge0c2849"></a>Problem motivation<br />
<div class="outline-text-5" id="text-11-1-1-1">
<p>
En la detección de anomalías intentamos construir un modelo a partir de casos que consideramos comunes, para luego usarlo para detectar eventos no comunes.
</p>
</div>
</li>

<li><a id="org0a20335"></a>Gaussian distribution<br /></li>

<li><a id="orgc83e026"></a>Algorithm<br />
<div class="outline-text-5" id="text-11-1-1-3">
<p>
Suposiciones:
</p>

<ul class="org-ul">
<li>Todos los descriptores están distribuidos normalmente.</li>
<li>Los descriptores son independientes entre sí.</li>
</ul>

<p>
Para cada descriptor \(x_j\) podemos estimar una distribución normal, calculando \(\mu_j\) y \(\sigma_j\):
</p>

<p>
\[ x_j \sim \mathcal{N}(\mu_j , \sigma_j) \]
</p>

<p>
La probabilidad de que un evento \(x\) esté en cierto punto será el producto de todas las probabilidades individuales:
</p>

<p>
\[ P(x) = \prod_{j=1}^{m} P(x_j, \mu_j, \sigma_j)  \]
</p>

<p>
Esto nos define una densidad de probabilidad en el hiperespacio \(\mathbb{R}^n\). Definimos un umbral \(\epsilon\) global (define un hiperplano) que clasificará entre anomalías o no anomalías; esto es, usamos el mismo umbral \(\epsilon\) para todos los descriptores.
</p>

<p>
\[ x \ \text{es anomalía si} \  P(x_j) < \epsilon \ \text{para cualquier} \  j \]
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-orge655b13" class="outline-4">
<h4 id="orge655b13"><span class="section-number-4">11.1.2</span> Building an anomaly detection system</h4>
<div class="outline-text-4" id="text-11-1-2">
</div>
<ol class="org-ol">
<li><a id="orgd0ae9e3"></a>Developing and evaluating an anomaly detection system<br />
<div class="outline-text-5" id="text-11-1-2-1">
<p>
Usamos datos etiquetados para entrenar un clasificador.
</p>
<ul class="org-ul">
<li>"Entrenamos"/definimos las funciones de densidad de probabilidad a partir de ejemplos normales, no problemáticos.</li>
<li>Ajustamos hiperparámetros (qué descriptores usamos, \(\epsilon\), &#x2026;) en el conjunto de validación cruzada, que sí tiene datos anómalos.</li>
<li>Evaluamos en el conjunto de prueba, que sí tiene datos anómalos.</li>
</ul>

<p>
Como los datos suelen estar muy sesgados, no podemos usar la precisión como métrica.
</p>

<p>
¿Por qué es esto distinto a una clasificación normal?
</p>
</div>
</li>

<li><a id="orge0fae3e"></a>Anomaly detection vs supervised learning<br />
<div class="outline-text-5" id="text-11-1-2-2">
<p>
La diferencia entre un algoritmo de detección de anomalías y un algoritmo clasificador de aprendizaje supervisado es que en los primeros sólo modelamos un caso (el normal), mientras en que en los segundos estamos modelando todo el universo, todas nuestras clases.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Detección de anomalías</th>
<th scope="col" class="org-left">Aprendizaje supervisado</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">- Tenemos muy pocos datos de anomalías. Andrew habla de 1 a 20 ejemplos.</td>
<td class="org-left">- Tenemos bastantes ejemplos de las anomalías.</td>
</tr>

<tr>
<td class="org-left">- Las anomalías futuras que nuestro algoritmo quizás ni siquiera estaban en nuestros datos de entrenamiento.</td>
<td class="org-left">- Los ejemplos que encontremos y queremos clasificar serán similares a aquellos con los que entrenamos.</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">- Detección de fraude.</td>
<td class="org-left">- Clasificación de email en spam y no spam.</td>
</tr>

<tr>
<td class="org-left">- Defectos de fabricación.</td>
<td class="org-left">- Detección de cáncer.</td>
</tr>

<tr>
<td class="org-left">- Defectos de funcionamiento.</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>
</div>
</li>


<li><a id="org2352335"></a>Choosing what features to use<br />
<ol class="org-ol">
<li><a id="org7dedb5a"></a>Aproximar a gaussiana<br />
<div class="outline-text-6" id="text-11-1-2-3-1">
<p>
Estamos modelando distribuciones gaussianas. Debemos observar cuál es la distribución real de nuestros descriptores, y si alguna no es gaussiana, es recomendable que la aproximemos, aplicando alguna transformación a ese descriptor. Si no lo hacemos es probable que igualmente funcione, pero es mejor si todo es gaussiano.
</p>
<ul class="org-ul">
<li>¿Será equivalente modelar con las distribuciones que más se aproximen a cada descriptor?</li>
</ul>
</div>
</li>

<li><a id="org4c90cf1"></a>Análisis de errores<br />
<div class="outline-text-6" id="text-11-1-2-3-2">
<p>
Podemos analizar los errores de clasificación para idear o buscar nuevos descriptores que nos permitan discriminar esos casos.
</p>
</div>
</li>

<li><a id="orgbef4870"></a>Diseño de descriptores<br />
<div class="outline-text-6" id="text-11-1-2-3-3">
<p>
Podemos crear nuevos descriptores que relacionen otros que ya tenemos; por ejemplo, productos o divisiones entre descriptores. Deberíamos pensar en qué cosas se vuelven extremas en los posibles casos anómalos.
</p>

<ul class="org-ul">
<li>Esto no es necesario si usamos una distribución gaussiana multivariable.</li>
</ul>
</div>
</li>
</ol>
</li>
</ol>
</div>

<div id="outline-container-org6f1ed60" class="outline-4">
<h4 id="org6f1ed60"><span class="section-number-4">11.1.3</span> Multivariate gaussian distribution</h4>
<div class="outline-text-4" id="text-11-1-3">
</div>
<ol class="org-ol">
<li><a id="org370f275"></a>Multivariate gaussian distribution<br />
<div class="outline-text-5" id="text-11-1-3-1">
<p>
Nuestra suposición en los modelos anteriores era que los descriptores estaban distribuidos normalmente y además eran independientes. Estos modelos son limitados y fallan en capturar anomalías, por ejemplo cuando los descriptores están correlacionados.
</p>

<p>
Podemos construir un modelo más complejo con una gaussiana multivariable, con todos los descriptores. Seguimos asumiendo que las distribuciones originales son gaussianas.
</p>
</div>
</li>

<li><a id="org485eb5b"></a>Anomaly detection using the multivariate gaussian distribution<br />
<ol class="org-ol">
<li><a id="orgb746d2a"></a>Estimación y uso<br />
<div class="outline-text-6" id="text-11-1-3-2-1">
<p>
Ahora tenemos un vector de medias y una matriz de covarianza:
</p>

<p>
\[ \vec{\mu} = \frac{1}{m} \sum_{i=1}^m \vec{x}^{(i)}  \]
</p>

<p>
\[ \Sigma =  \frac{1}{m} \sum_{i=1}^{m} (\vec{x}^{(i)} - \vec{\mu})^T  ( \vec{x}^{(i)} - \vec{\mu})  \]
</p>

<p>
La estimación es:
</p>

<p>
\[ P(\vec{x}, \vec{\mu}, \Sigma) = \frac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} \exp\left( -\frac{1}{2} ( \vec{x}- \vec{\mu})^T \Sigma^{-1} ( \vec{x}- \vec{\mu})  \right) \]
</p>
</div>
</li>

<li><a id="org7ff2c76"></a>Comentarios<br />
<div class="outline-text-6" id="text-11-1-3-2-2">
<p>
El modelo original (producto de gaussianas) es un caso especial de una distribución gaussiana multivariable, cuando las variables no están correlacionadas. Esto implica que la matriz de covarianza es diagonal y que la distribución resultante se desarrolla a lo largo de los ejes, no está rotada.
</p>

<p>
Si usamos una distribución gaussiana multivariable no es necesario que construyamos descriptores que capturen relaciones entre lso descriptores, porque ya están implícitas en el modelo.
</p>

<p>
Dice Andrew que el modelo original es computacionalmente más barato y que escala mejor cuando tenemos muchos datos, especialmente porque hay que invertir una matriz. Yo digo que lo de la matriz es una excusa, porque se puede precalcular, no es necesario andar invirtiéndola para cada predicción.
</p>

<p>
En el modelo original teníamos \(2n\) parámetros a estimar, mientras que en este tenemos \(n^2 + n\). Por lo tanto necesitamos más datos para una buena regresión.
</p>
</div>
</li>
</ol>
</li>
</ol>
</div>


<div id="outline-container-orgef590fc" class="outline-4">
<h4 id="orgef590fc"><span class="section-number-4">11.1.4</span> Review</h4>
<div class="outline-text-4" id="text-11-1-4">
</div>
<ol class="org-ol">
<li><a id="org42685a8"></a>Quiz: anomaly detection<br /></li>
</ol>
</div>
</div>

<div id="outline-container-org59e37a1" class="outline-3">
<h3 id="org59e37a1"><span class="section-number-3">11.2</span> Recommender systems</h3>
<div class="outline-text-3" id="text-11-2">
</div>
<div id="outline-container-orgc515c35" class="outline-4">
<h4 id="orgc515c35"><span class="section-number-4">11.2.1</span> Predicting movie ratings</h4>
<div class="outline-text-4" id="text-11-2-1">
</div>
<ol class="org-ol">
<li><a id="orgff9689f"></a>Problem formulation<br /></li>

<li><a id="org75cb725"></a>Content based recommendations<br /></li>
</ol>
</div>

<div id="outline-container-org65f9fe1" class="outline-4">
<h4 id="org65f9fe1"><span class="section-number-4">11.2.2</span> Collaborative filtering</h4>
<div class="outline-text-4" id="text-11-2-2">
</div>
<ol class="org-ol">
<li><a id="orge181de5"></a>Collaborative filtering<br /></li>

<li><a id="orgd62e6d9"></a>Collaborative filtering algorithm<br /></li>
</ol>
</div>

<div id="outline-container-org9be2c6d" class="outline-4">
<h4 id="org9be2c6d"><span class="section-number-4">11.2.3</span> Low rank matrix factorization</h4>
<div class="outline-text-4" id="text-11-2-3">
</div>
<ol class="org-ol">
<li><a id="org796b6f8"></a>Vectorization: low rank matrix factorization<br /></li>

<li><a id="org0064765"></a>Implementational detail: mean normalization<br /></li>
</ol>
</div>

<div id="outline-container-orgb0905ea" class="outline-4">
<h4 id="orgb0905ea"><span class="section-number-4">11.2.4</span> Review</h4>
<div class="outline-text-4" id="text-11-2-4">
</div>
<ol class="org-ol">
<li><a id="org085dc72"></a>Quiz: recommender systems<br /></li>

<li><a id="org5bb29ea"></a>Programming assignment: anomaly detection and recommender systems<br /></li>
</ol>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Pablo Aguado</p>
<p class="date">Created: 2020-05-27 mié 22:43</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
